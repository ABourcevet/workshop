{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "# Multi-task recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dk8QEc4sIPMi"
   },
   "source": [
    "In the [basic retrieval tutorial](basic_retrieval) we built a retrieval system using movie watches as positive interaction signals.\n",
    "\n",
    "In many applications, however, there are multiple rich sources of feedback to draw upon. For example, an e-commerce site may record user visits to product pages (abundant, but relatively low signal), image clicks, adding to cart, and, finally, purchases. It may even record post-purchase signals such as reviews and returns.\n",
    "\n",
    "Integrating all these different forms of feedback is critical to building systems that users love to use, and that do not optimize for any one metric at the expense of overall performance.\n",
    "\n",
    "In addition, building a joint model for multiple tasks may produce better results than building a number of task-specific models. This is especially true where some data is abundant (for example, clicks), and some data is sparse (purchases, returns, manual reviews). In those scenarios, a joint model may be able to use representations learned from the abundant task to improve its predictions on the sparse task via a phenomenon known as [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning). For example, [this paper](https://openreview.net/pdf?id=SJxPVcSonN) shows that a model predicting explicit user ratings from sparse user surveys can be substantially improved by adding an auxiliary task that uses abundant click log data.\n",
    "\n",
    "In this tutorial, we are going to build a multi-objective recommender for Movielens, using both implicit (movie watches) and explicit signals (ratings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwrcZeK7x7xI"
   },
   "source": [
    "## Imports\n",
    "\n",
    "\n",
    "Let's first get our imports out of the way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64\n",
      "drwx------ 13 root nogroup 6144 Nov  2 21:33 .\n",
      "drwxr-xr-x  1 root root      39 Nov  2 21:24 ..\n",
      "-rw-------  1 root root    2230 Nov  2 21:14 .bash_history\n",
      "drwxr-xr-x  7 root root    6144 Nov  2 20:59 .cache\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 15:44 .config\n",
      "-rw-r--r--  1 root root      54 Nov  2 15:39 .gitconfig\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:31 .ipynb_checkpoints\n",
      "drwxr-xr-x  5 root root    6144 Oct 10 23:13 .ipython\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:24 .jupyter\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:59 .keras\n",
      "drwxr-xr-x  3 root root    6144 Oct 10 22:41 .local\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:33 .ssh\n",
      "-rw-r--r--  1 root root     111 Oct 10 22:41 .yarnrc\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:12 exported_models\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:33 model\n",
      "-rw-r--r--  1 root root     764 Nov  2 21:33 model.tar.gz\n",
      "drwxr-xr-x 19 root root    6144 Nov  1 19:35 workshop\n"
     ]
    }
   ],
   "source": [
    "!ls -al ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:53:57.211577Z",
     "iopub.status.busy": "2020-10-27T16:53:57.210839Z",
     "iopub.status.idle": "2020-10-27T16:54:03.861808Z",
     "shell.execute_reply": "2020-10-27T16:54:03.862248Z"
    },
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:03.866729Z",
     "iopub.status.busy": "2020-10-27T16:54:03.865994Z",
     "iopub.status.idle": "2020-10-27T16:54:03.875176Z",
     "shell.execute_reply": "2020-10-27T16:54:03.874637Z"
    },
    "id": "BxQ_hy7xPH3N"
   },
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "We're going to use the Movielens 100K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 64\n",
      "drwx------ 13 root nogroup 6144 Nov  2 21:33 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x  1 root root      39 Nov  2 21:24 \u001b[01;34m..\u001b[0m/\n",
      "-rw-------  1 root root    2230 Nov  2 21:14 .bash_history\n",
      "drwxr-xr-x  7 root root    6144 Nov  2 20:59 \u001b[01;34m.cache\u001b[0m/\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 15:44 \u001b[01;34m.config\u001b[0m/\n",
      "-rw-r--r--  1 root root      54 Nov  2 15:39 .gitconfig\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:31 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\n",
      "drwxr-xr-x  5 root root    6144 Oct 10 23:13 \u001b[01;34m.ipython\u001b[0m/\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:24 \u001b[01;34m.jupyter\u001b[0m/\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:59 \u001b[01;34m.keras\u001b[0m/\n",
      "drwxr-xr-x  3 root root    6144 Oct 10 22:41 \u001b[01;34m.local\u001b[0m/\n",
      "drwxr-xr-x  2 root root    6144 Nov  1 19:33 \u001b[01;34m.ssh\u001b[0m/\n",
      "-rw-r--r--  1 root root     111 Oct 10 22:41 .yarnrc\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:12 \u001b[01;34mexported_models\u001b[0m/\n",
      "drwxr-xr-x  3 root root    6144 Nov  2 21:33 \u001b[01;34mmodel\u001b[0m/\n",
      "-rw-r--r--  1 root root     764 Nov  2 21:33 model.tar.gz\n",
      "drwxr-xr-x 19 root root    6144 Nov  1 19:35 \u001b[01;34mworkshop\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -al ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:03.880959Z",
     "iopub.status.busy": "2020-10-27T16:54:03.880268Z",
     "iopub.status.idle": "2020-10-27T16:54:04.085354Z",
     "shell.execute_reply": "2020-10-27T16:54:04.084772Z"
    },
    "id": "-ySWtibjm_6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {movie_title: (), user_id: (), user_rating: ()}, types: {movie_title: tf.string, user_id: tf.string, user_rating: tf.float32}>\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings',                     \n",
    "                    download=False,\n",
    "                    data_dir='/root/workshop/02_usecases/sagemaker_recommendations/tensorflow_datasets/',\n",
    "                    split='train')\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load('movielens/100k-movies',                     \n",
    "                    download=False,\n",
    "                    data_dir='/root/workshop/02_usecases/sagemaker_recommendations/tensorflow_datasets/',\n",
    "                    split='train')\n",
    "\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JRHorm8W1yf3"
   },
   "source": [
    "And repeat our preparations for building vocabularies and splitting the data into a train and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:04.092022Z",
     "iopub.status.busy": "2020-10-27T16:54:04.091271Z",
     "iopub.status.idle": "2020-10-27T16:54:09.257704Z",
     "shell.execute_reply": "2020-10-27T16:54:09.258146Z"
    },
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## A multi-task model\n",
    "\n",
    "There are two critical parts to multi-task recommenders:\n",
    "\n",
    "1. They optimize for two or more objectives, and so have two or more losses.\n",
    "2. They share variables between the tasks, allowing for transfer learning.\n",
    "\n",
    "In this tutorial, we will define our models as before, but instead of having  a single task, we will have two tasks: one that predicts ratings, and one that predicts movie watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXHrk_SLzKCM"
   },
   "source": [
    "The user and movie models are as before:\n",
    "\n",
    "```python\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_user_ids),\n",
    "  # We add 2 to account for unknown and mask tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_titles),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 2, embedding_dimension)\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWCwkE5z8QBe"
   },
   "source": [
    "However, now we will have two tasks. The first is the rating task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrgQIXEm8UWf"
   },
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCNrv7_gakmF"
   },
   "source": [
    "As before, this task's goal is to predict which movies the user will or will not watch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSWw3xuq8mGh"
   },
   "source": [
    "### Putting it together\n",
    "\n",
    "We put it all together in a model class.\n",
    "\n",
    "The new component here is that - since we have two tasks and two losses - we need to decide on how important each loss is. We can do this by giving each of the losses a weight, and treating these weights as hyperparameters. If we assign a large loss weight to the rating task, our model is going to focus on predicting ratings (but still use some information from the retrieval task); if we assign a large loss weight to the retrieval task, it will focus on retrieval instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:09.272562Z",
     "iopub.status.busy": "2020-10-27T16:54:09.271799Z",
     "iopub.status.idle": "2020-10-27T16:54:09.274088Z",
     "shell.execute_reply": "2020-10-27T16:54:09.273595Z"
    },
    "id": "YFSkOAMgzU0K"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "    \n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=features[\"user_rating\"],\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ngvn-c0b8lc2"
   },
   "source": [
    "### Rating-specialized model\n",
    "\n",
    "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:09.278791Z",
     "iopub.status.busy": "2020-10-27T16:54:09.278086Z",
     "iopub.status.idle": "2020-10-27T16:54:09.411120Z",
     "shell.execute_reply": "2020-10-27T16:54:09.411612Z"
    },
    "id": "NNfB6rYL0VrS"
   },
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:09.416462Z",
     "iopub.status.busy": "2020-10-27T16:54:09.415698Z",
     "iopub.status.idle": "2020-10-27T16:54:09.420088Z",
     "shell.execute_reply": "2020-10-27T16:54:09.419557Z"
    },
    "id": "I6kjfF1j0iZR"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:09.426084Z",
     "iopub.status.busy": "2020-10-27T16:54:09.424532Z",
     "iopub.status.idle": "2020-10-27T16:54:20.589019Z",
     "shell.execute_reply": "2020-10-27T16:54:20.588349Z"
    },
    "id": "6NWadH1q0c_T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 2.0903 - factorized_top_k/top_1_categorical_accuracy: 3.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0024 - factorized_top_k/top_10_categorical_accuracy: 0.0055 - factorized_top_k/top_50_categorical_accuracy: 0.0295 - factorized_top_k/top_100_categorical_accuracy: 0.0590 - loss: 4.0315 - regularization_loss: 0.0000e+00 - total_loss: 4.0315\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 21s 2s/step - root_mean_squared_error: 1.1531 - factorized_top_k/top_1_categorical_accuracy: 2.3750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0024 - factorized_top_k/top_10_categorical_accuracy: 0.0054 - factorized_top_k/top_50_categorical_accuracy: 0.0297 - factorized_top_k/top_100_categorical_accuracy: 0.0592 - loss: 1.3189 - regularization_loss: 0.0000e+00 - total_loss: 1.3189\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 1.1198 - factorized_top_k/top_1_categorical_accuracy: 2.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0026 - factorized_top_k/top_10_categorical_accuracy: 0.0055 - factorized_top_k/top_50_categorical_accuracy: 0.0301 - factorized_top_k/top_100_categorical_accuracy: 0.0597 - loss: 1.2479 - regularization_loss: 0.0000e+00 - total_loss: 1.2479\n",
      "5/5 [==============================] - 3s 579ms/step - root_mean_squared_error: 1.1130 - factorized_top_k/top_1_categorical_accuracy: 4.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0030 - factorized_top_k/top_10_categorical_accuracy: 0.0053 - factorized_top_k/top_50_categorical_accuracy: 0.0297 - factorized_top_k/top_100_categorical_accuracy: 0.0595 - loss: 1.2336 - regularization_loss: 0.0000e+00 - total_loss: 1.2336\n",
      "retrieval-top-100-accuracy: 0.060.\n",
      "ranking-rmse: 1.113.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"retrieval-top-100-accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"ranking-rmse: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lENViv04-i0T"
   },
   "source": [
    "The model does OK on predicting ratings (with an RMSE of around 1.11), but performs poorly at predicting which movies will be watched or not: its accuracy at 100 is almost 4 times worse than a model trained solely to predict watches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPYd9LtE-4Fm"
   },
   "source": [
    "### Retrieval-specialized model\n",
    "\n",
    "Let's now try a model that focuses on retrieval only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:20.596008Z",
     "iopub.status.busy": "2020-10-27T16:54:20.595371Z",
     "iopub.status.idle": "2020-10-27T16:54:20.687473Z",
     "shell.execute_reply": "2020-10-27T16:54:20.687922Z"
    },
    "id": "BfnkGd2G--Qt"
   },
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:20.693237Z",
     "iopub.status.busy": "2020-10-27T16:54:20.692555Z",
     "iopub.status.idle": "2020-10-27T16:54:29.768979Z",
     "shell.execute_reply": "2020-10-27T16:54:29.768494Z"
    },
    "id": "JCCBdM7U_B11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 3.7237 - factorized_top_k/top_1_categorical_accuracy: 2.8750e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0030 - factorized_top_k/top_10_categorical_accuracy: 0.0081 - factorized_top_k/top_50_categorical_accuracy: 0.0696 - factorized_top_k/top_100_categorical_accuracy: 0.1442 - loss: 69818.0284 - regularization_loss: 0.0000e+00 - total_loss: 69818.0284\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 3.7495 - factorized_top_k/top_1_categorical_accuracy: 0.0016 - factorized_top_k/top_5_categorical_accuracy: 0.0143 - factorized_top_k/top_10_categorical_accuracy: 0.0316 - factorized_top_k/top_50_categorical_accuracy: 0.1542 - factorized_top_k/top_100_categorical_accuracy: 0.2781 - loss: 67473.2876 - regularization_loss: 0.0000e+00 - total_loss: 67473.2876\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 3.7648 - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.0200 - factorized_top_k/top_10_categorical_accuracy: 0.0418 - factorized_top_k/top_50_categorical_accuracy: 0.1822 - factorized_top_k/top_100_categorical_accuracy: 0.3093 - loss: 66329.2514 - regularization_loss: 0.0000e+00 - total_loss: 66329.2514\n",
      "5/5 [==============================] - 3s 688ms/step - root_mean_squared_error: 3.7730 - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0098 - factorized_top_k/top_10_categorical_accuracy: 0.0218 - factorized_top_k/top_50_categorical_accuracy: 0.1253 - factorized_top_k/top_100_categorical_accuracy: 0.2353 - loss: 31085.0697 - regularization_loss: 0.0000e+00 - total_loss: 31085.0697\n",
      "retrieval-top-100-accuracy: 0.235.\n",
      "ranking-rmse: 3.773.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"retrieval-top-100-accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"ranking-rmse: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjM7j7eY_jPh"
   },
   "source": [
    "We get the opposite result: a model that does well on retrieval, but poorly on predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hOFwjUus_pLU"
   },
   "source": [
    "### Joint model\n",
    "\n",
    "Let's now train a model that assigns positive weights to both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:29.775752Z",
     "iopub.status.busy": "2020-10-27T16:54:29.775128Z",
     "iopub.status.idle": "2020-10-27T16:54:29.862716Z",
     "shell.execute_reply": "2020-10-27T16:54:29.863151Z"
    },
    "id": "7xyDbNMf_t8a"
   },
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-10-27T16:54:29.868548Z",
     "iopub.status.busy": "2020-10-27T16:54:29.867885Z",
     "iopub.status.idle": "2020-10-27T16:54:38.982984Z",
     "shell.execute_reply": "2020-10-27T16:54:38.983394Z"
    },
    "id": "2pZmM_ub_uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 2.5007 - factorized_top_k/top_1_categorical_accuracy: 2.1250e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0027 - factorized_top_k/top_10_categorical_accuracy: 0.0076 - factorized_top_k/top_50_categorical_accuracy: 0.0640 - factorized_top_k/top_100_categorical_accuracy: 0.1391 - loss: 69811.8246 - regularization_loss: 0.0000e+00 - total_loss: 69811.8246\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 1.2097 - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0137 - factorized_top_k/top_10_categorical_accuracy: 0.0298 - factorized_top_k/top_50_categorical_accuracy: 0.1488 - factorized_top_k/top_100_categorical_accuracy: 0.2721 - loss: 67481.2720 - regularization_loss: 0.0000e+00 - total_loss: 67481.2720\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 20s 2s/step - root_mean_squared_error: 1.1200 - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0195 - factorized_top_k/top_10_categorical_accuracy: 0.0403 - factorized_top_k/top_50_categorical_accuracy: 0.1802 - factorized_top_k/top_100_categorical_accuracy: 0.3089 - loss: 66297.9290 - regularization_loss: 0.0000e+00 - total_loss: 66297.9290\n",
      "5/5 [==============================] - 3s 692ms/step - root_mean_squared_error: 1.1311 - factorized_top_k/top_1_categorical_accuracy: 7.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0083 - factorized_top_k/top_10_categorical_accuracy: 0.0225 - factorized_top_k/top_50_categorical_accuracy: 0.1246 - factorized_top_k/top_100_categorical_accuracy: 0.2349 - loss: 31062.8203 - regularization_loss: 0.0000e+00 - total_loss: 31062.8203\n",
      "Retrieval top-100 accuracy: 0.235.\n",
      "Ranking RMSE: 1.131.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ni_rkOsaB3f9"
   },
   "source": [
    "The result is a model that performs roughly as well on both tasks as each specialized model. \n",
    "\n",
    "While the results here do not show a clear accuracy benefit from a joint model in this case, multi-task learning is in general an extremely useful tool. We can expect better results when we can transfer knowledge from a data-abundant task (such as clicks) to a closely related data-sparse task (such as purchases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fba1204b3d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and returns the predicted movie titles\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index(movies.batch(100).map(model.movie_model), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 42: [b'Homeward Bound: The Incredible Journey (1993)' b'Jack (1996)'\n",
      " b'First Wives Club, The (1996)' b'101 Dalmatians (1996)'\n",
      " b'Rent-a-Kid (1995)']\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "user_id = \"42\"\n",
    "\n",
    "_, titles = index(np.array([user_id]))\n",
    "\n",
    "print(f\"Top {k} recommendations for user {user_id}: {titles[0, :k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained index <tensorflow_recommenders.layers.factorized_top_k.BruteForce object at 0x7fba1204b3d0>\n",
      "Model: \"brute_force\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_7 (Sequential)    (None, 32)                30208     \n",
      "=================================================================\n",
      "Total params: 85,714\n",
      "Trainable params: 30,208\n",
      "Non-trainable params: 55,506\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Trained index {}'.format(index))          \n",
    "print(index.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.retrieval_task = tfrs.tasks.Retrieval()  # Removes the metrics.\n",
    "# model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Compiled model {}'.format(model))          \n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_model_dir_multitask_model = './exported_models/multitask_model/'\n",
    "\n",
    "tensorflow_saved_model_path_multitask_model = os.path.join(local_model_dir_multitask_model, 'tensorflow/saved_model/0')\n",
    "\n",
    "os.makedirs(tensorflow_saved_model_path_multitask_model, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exported_models/multitask_model/tensorflow/saved_model/0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./exported_models/multitask_model/tensorflow/saved_model/0/assets\n"
     ]
    }
   ],
   "source": [
    "index.save(tensorflow_saved_model_path_multitask_model, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 21:39:37.873096: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-11-02 21:39:37.873147: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_1'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: serving_default_input_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "    outputs['output_2'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:1\n",
      "  Method name is: tensorflow/serving/predict\n",
      "2020-11-02 21:39:39.316979: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-11-02 21:39:39.317033: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-11-02 21:39:39.317069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (datascience-1-0-ml-t3-medium-1abf3407f667f989be9d86559395): /proc/driver/nvidia/version does not exist\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/saved_model_cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 1185, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 715, in show\n",
      "    _show_all(args.dir)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 307, in _show_all\n",
      "    _show_defined_functions(saved_model_dir)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py\", line 187, in _show_defined_functions\n",
      "    trackable_object = load.load(saved_model_dir)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 603, in load\n",
      "    return load_internal(export_dir, tags, options)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 633, in load_internal\n",
      "    ckpt_options)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 131, in __init__\n",
      "    self._restore_checkpoint()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 358, in _restore_checkpoint\n",
      "    \"%r from the checkpoint.\" % obj))\n",
      "NotImplementedError: Missing functionality to restore state of object <tensorflow.python.saved_model.load._RestoredResource object at 0x7f1ed666f610> from the checkpoint.\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir $tensorflow_saved_model_path_multitask_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 21:41:59.531308: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-11-02 21:41:59.531358: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2020-11-02 21:42:00.803111: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-11-02 21:42:00.803152: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-11-02 21:42:00.803186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (datascience-1-0-ml-t3-medium-1abf3407f667f989be9d86559395): /proc/driver/nvidia/version does not exist\n",
      "2020-11-02 21:42:00.803439: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-11-02 21:42:00.810377: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\n",
      "2020-11-02 21:42:00.810587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b4b7a76dc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-02 21:42:00.810628: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py:444: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from ./exported_models/multitask_model/tensorflow/saved_model/0/variables/variables\n",
      "Result for output key output_1:\n",
      "[[0.11276153 0.10607237 0.10029443 0.09820339 0.09082752 0.08627339\n",
      "  0.08380152 0.08380152 0.08288748 0.08045805]]\n",
      "Result for output key output_2:\n",
      "[[b\"Dante's Peak (1997)\" b'Saint, The (1997)' b'Mouse Hunt (1997)'\n",
      "  b'George of the Jungle (1997)' b'Hunchback of Notre Dame, The (1996)'\n",
      "  b'Tomorrow Never Dies (1997)' b'That Darn Cat! (1997)'\n",
      "  b'That Darn Cat! (1997)' b'Anastasia (1997)' b'Liar Liar (1997)']]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --input_exprs 'input_1=[\"$user_id\"]' --tag_set serve --signature_def serving_default --dir $tensorflow_saved_model_path_multitask_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multitask.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
