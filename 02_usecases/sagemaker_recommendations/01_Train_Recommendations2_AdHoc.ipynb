{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sT8AyHRMNh41"
   },
   "source": [
    "# TensorFlow Recommenders: Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8f-reQ11gbLB"
   },
   "source": [
    "In this tutorial, we build a simple matrix factorization model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TFRS. We can use this model to recommend movies for a given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import TensorFlow Recommender System (TFRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker==2.9.2\n",
    "!pip install -q sagemaker-experiments==0.1.24\n",
    "!pip install -q tensorflow==2.3.0\n",
    "!pip install -q tensorflow-recommenders==0.2.0\n",
    "!pip install -q tensorflow-datasets==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zCxQ1CZcO2wh"
   },
   "source": [
    "# Load Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-mxBYjdO5m7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: {bucketized_user_age: (), movie_genres: (None,), movie_id: (), movie_title: (), raw_user_age: (), timestamp: (), user_gender: (), user_id: (), user_occupation_label: (), user_occupation_text: (), user_rating: (), user_zip_code: ()}, types: {bucketized_user_age: tf.float32, movie_genres: tf.int64, movie_id: tf.string, movie_title: tf.string, raw_user_age: tf.float32, timestamp: tf.int64, user_gender: tf.bool, user_id: tf.string, user_occupation_label: tf.int64, user_occupation_text: tf.string, user_rating: tf.float32, user_zip_code: tf.string}>\n"
     ]
    }
   ],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings',                     \n",
    "                    download=False,\n",
    "                    data_dir='./tensorflow_datasets/',\n",
    "                    split='train')\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: {movie_title: (), user_id: (), user_rating: ()}, types: {movie_title: tf.string, user_id: tf.string, user_rating: tf.float32}>\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = ratings.batch(1_000_000).map(lambda x: x[\"movie_title\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "    \n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, movie_title = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['42']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [\"One Flew Over the Cuckoo's Nest (1975)\"]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [\"One Flew Over the Cuckoo's Nest (1975)\"]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.03740937]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RankingModel()(([\"42\"], [\"One Flew Over the Cuckoo's Nest (1975)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    rating_predictions = self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"movie_title\"]))\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=features[\"user_rating\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 0s 40ms/step - root_mean_squared_error: 2.1718 - loss: 4.3303 - regularization_loss: 0.0000e+00 - total_loss: 4.3303\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 26ms/step - root_mean_squared_error: 1.1227 - loss: 1.2602 - regularization_loss: 0.0000e+00 - total_loss: 1.2602\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 26ms/step - root_mean_squared_error: 1.1162 - loss: 1.2456 - regularization_loss: 0.0000e+00 - total_loss: 1.2456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6ba1a00210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - root_mean_squared_error: 1.1108 - loss: 1.2287 - regularization_loss: 0.0000e+00 - total_loss: 1.2287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.1108046770095825,\n",
       " 'loss': 1.206252932548523,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.206252932548523}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Use brute-force search to set up retrieval using the trained representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MovielensModel' object has no attribute 'user_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b2add7fa10f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBruteForce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MovielensModel' object has no attribute 'user_model'"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index(movies.batch(100).map(model.movie_model), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_model_dir_bruteforce_model = './exported_models/bruteforce_model/'\n",
    "\n",
    "tensorflow_saved_model_path_bruteforce_model = os.path.join(local_model_dir_bruteforce_model, 'tensorflow/saved_model/0')\n",
    "\n",
    "os.makedirs(tensorflow_saved_model_path_bruteforce_model, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "user_id = \"42\"\n",
    "\n",
    "_, titles = index(np.array([user_id]))\n",
    "\n",
    "print(f\"Top {k} recommendations for user {user_id}: {titles[0, :k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Compiled model {}'.format(index))          \n",
    "print(index.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.save(tensorflow_saved_model_path_bruteforce_model, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --all --dir $tensorflow_saved_model_path_bruteforce_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following works!\n",
    "\n",
    "\n",
    "```\n",
    "!saved_model_cli run --input_exprs 'input_1=[str(42)]' --tag_set serve --signature_def serving_default --dir $tensorflow_saved_model_path_bruteforce_model\n",
    "```\n",
    "\n",
    "```\n",
    "Result for output key output_1:\n",
    "[[3.9453535 2.9104383 2.7285933 2.6687438 2.5107827 2.4038887 2.3974428\n",
    "  2.386409  2.321732  2.3211298]]\n",
    "Result for output key output_2:\n",
    "[[b'Rent-a-Kid (1995)' b'Last Dance (1996)'\n",
    "  b'Adventures of Pinocchio, The (1996)'\n",
    "  b'Winnie the Pooh and the Blustery Day (1968)'\n",
    "  b'Aristocats, The (1970)' b'Celtic Pride (1996)'\n",
    "  b'Conan the Barbarian (1981)' b'House Arrest (1996)'\n",
    "  b'Just Cause (1995)' b'Johnny 100 Pesos (1993)']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!saved_model_cli run --input_exprs 'input_1=[\"$user_id\"]' --tag_set serve --signature_def serving_default --dir $tensorflow_saved_model_path_bruteforce_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pprint\n",
    "import argparse\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the directory you want to start from\n",
    "#for dirName, subdirList, fileList in os.walk('/etc/ssl/certs/'):\n",
    "#    print('Found directory: %s' % dirName)\n",
    "#    for fname in fileList:\n",
    "#        print('\\t%s' % fname)        \n",
    "        \n",
    "from typing import Dict, Text\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MovieLensModel(tfrs.Model):\n",
    "  # We derive from a custom base class to help reduce boilerplate. Under the hood,\n",
    "  # these are still plain Keras Models.\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      user_embedding: tf.keras.Model,\n",
    "      movie_embeddings: tf.keras.Model,\n",
    "      task: tfrs.tasks.Retrieval):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie representations.\n",
    "    self.user_embeddings = user_embeddings\n",
    "    self.movie_embeddings = movie_embeddings\n",
    "\n",
    "    # Set up a retrieval task.\n",
    "    self.task = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # Define how the loss is computed using the retrieval task\n",
    "    user_embeddings = self.user_embeddings(features['user_id'])\n",
    "    movie_embeddings = self.movie_embeddings(features['movie_title'])\n",
    "\n",
    "    return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "     \n",
    "    args, _ = parser.parse_known_args()\n",
    "    print(\"Args:\") \n",
    "    print(args)\n",
    "    \n",
    "    env_var = os.environ \n",
    "    print(\"Environment Variables:\") \n",
    "    pprint.pprint(dict(env_var), width = 1) \n",
    "\n",
    "    local_model_dir = './model' # os.environ['SM_MODEL_DIR']\n",
    "    output_dir = './output' # args.output_dir\n",
    "    print('output_dir {}'.format(output_dir))    \n",
    "\n",
    "    train_data = './tensorflow_datasets/' # args.train_data\n",
    "    print('train_data {}'.format(train_data))\n",
    "    epochs = 1 # args.epochs\n",
    "    print('epochs {}'.format(epochs))    \n",
    "    learning_rate = 0.5 # args.learning_rate\n",
    "    print('learning_rate {}'.format(learning_rate))    \n",
    "    enable_tensorboard = False # args.enable_tensorboard\n",
    "    print('enable_tensorboard {}'.format(enable_tensorboard))       \n",
    "    dataset_variant = '100k' # args.dataset_variant\n",
    "    print('dataset_variant {}'.format(dataset_variant))\n",
    "    embedding_dimension = int(256) # int(args.embedding_dimension)\n",
    "    print('embedding_dimension {}'.format(embedding_dimension))       \n",
    "\n",
    "    # Load the ratings data to use for training\n",
    "    ratings = tfds.load('movielens/{}-ratings'.format(dataset_variant), \n",
    "                        download=False,\n",
    "                        data_dir=train_data,\n",
    "                        split='train')\n",
    "    print('Ratings raw', ratings)\n",
    "\n",
    "    # Transform the ratings data specific to our training task\n",
    "    ratings = ratings.map(lambda x: {\n",
    "        'movie_title': x['movie_title'],\n",
    "        'user_id': x['user_id']\n",
    "    })\n",
    "    print('Ratings transformed', ratings)    \n",
    "\n",
    "    # Load the movies data to use for training\n",
    "    movies = tfds.load('movielens/{}-movies'.format(dataset_variant),\n",
    "                       download=False,\n",
    "                       data_dir=train_data,\n",
    "                       split='train')\n",
    "    print('Movies raw', movies)\n",
    "    \n",
    "    # Transform the movies data specific to our training task\n",
    "    movies = movies.map(lambda x: x['movie_title'])\n",
    "    print('Movies transformed', movies)\n",
    "\n",
    "    # Create the user vocabulary and user embeddings\n",
    "    user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "    user_ids_vocabulary.adapt(ratings.map(lambda x: x['user_id']))\n",
    "\n",
    "    user_embeddings = tf.keras.Sequential([\n",
    "        user_ids_vocabulary,\n",
    "        tf.keras.layers.Embedding(user_ids_vocabulary.vocab_size(),\n",
    "                                  embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Create the movie vocabulary and movie embeddings\n",
    "    movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(mask_token=None)\n",
    "    movie_titles_vocabulary.adapt(movies)\n",
    "\n",
    "    movie_embeddings = tf.keras.Sequential([\n",
    "        movie_titles_vocabulary,\n",
    "        tf.keras.layers.Embedding(movie_titles_vocabulary.vocab_size(),\n",
    "                                  embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Specify the task and the top-k metric to optimize during model training\n",
    "    task = tfrs.tasks.Retrieval(metrics=tfrs.metrics.FactorizedTopK(\n",
    "        movies.batch(128).map(movie_embeddings)\n",
    "    ))\n",
    "\n",
    "    # Define the optimizer and hyper-parameters\n",
    "    optimizer = tf.keras.optimizers.Adagrad(learning_rate)\n",
    "    print('Optimizer:  {}'.format(optimizer))\n",
    "\n",
    "    # Setup the callbacks to use during training\n",
    "    callbacks = []\n",
    "\n",
    "    # Setup the Tensorboard callback if Tensorboard is enabled\n",
    "    if enable_tensorboard: \n",
    "        # Tensorboard Logs \n",
    "        tensorboard_logs_path = os.path.join(local_model_dir, 'tensorboard/')\n",
    "        os.makedirs(tensorboard_logs_path, exist_ok=True)\n",
    "\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logs_path)\n",
    "        print('Adding Tensorboard callback {}'.format(tensorboard_callback))\n",
    "        callbacks.append(tensorboard_callback)\n",
    "    print('Callbacks: {}'.format(callbacks))\n",
    "\n",
    "    # Create a custom Keras model with the user embeddings, movie embeddings, and optimization task\n",
    "    model = MovieLensModel(user_embeddings, movie_embeddings, task)\n",
    "    \n",
    "    # Compile the model and prepare for training\n",
    "    model.compile(optimizer=optimizer)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(ratings.batch(4096), epochs=epochs)\n",
    "\n",
    "    # Make some sample predictions to test our model\n",
    "    # Note:  This is required to save and server our model with TensorFlow Serving\n",
    "    #        See https://github.com/tensorflow/tensorflow/issues/31057 for more  details.\n",
    "    index = tfrs.layers.factorized_top_k.BruteForce(query_model=model.user_embeddings)\n",
    "    index.index(movies.batch(100).map(model.movie_embeddings), movies)\n",
    "\n",
    "    user_id = '42'\n",
    "    _, titles = index(np.array([user_id]))\n",
    "\n",
    "    k = 10\n",
    "    print(f'Top {k} recommendations for user {user_id}: {titles[0, :k]}')\n",
    "\n",
    "    # Print a summary of our recommender model\n",
    "    print('Trained index {}'.format(index))\n",
    "    print(index.summary())\n",
    "\n",
    "    # Save the TensorFlow SavedModel for Serving Predictions\n",
    "    # SavedModel Output\n",
    "    tensorflow_saved_model_path = os.path.join(local_model_dir,\n",
    "                                               'tensorflow/saved_model/0')\n",
    "    os.makedirs(tensorflow_saved_model_path, exist_ok=True)\n",
    "    \n",
    "    print('tensorflow_saved_model_path {}'.format(tensorflow_saved_model_path))\n",
    "    index.save(tensorflow_saved_model_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"42\"\n",
    "\n",
    "!saved_model_cli run --input_exprs 'input_1=np.array([\"$user_id\"])' --tag_set serve --signature_def serving_default --dir ./model/tensorflow/saved_model/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "quickstart.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
