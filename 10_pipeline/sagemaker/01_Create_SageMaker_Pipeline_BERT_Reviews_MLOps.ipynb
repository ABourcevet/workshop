{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SageMaker MLOps Project for Pipelines\n",
    "Note:  This requires that you have enabled products within SageMaker Studio\n",
    "\n",
    "![](../img/enable-service-catalog-portfolio-for-studio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "sc = boto3.Session().client(service_name='servicecatalog', region_name=region)\n",
    "sts = boto3.Session().client(service_name='sts', region_name=region)\n",
    "iam = boto3.Session().client(service_name='iam', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod-j3ufw6hl7utxm\n"
     ]
    }
   ],
   "source": [
    "search_response = sc.search_products(\n",
    "   Filters={\n",
    "       'FullTextSearch': \n",
    "       [\n",
    "           'MLOps template for model building, training, and deployment'\n",
    "       ]\n",
    "   }\n",
    ")\n",
    "\n",
    "sagemaker_pipeline_product_id = search_response['ProductViewSummaries'][0]['ProductId']\n",
    "print(sagemaker_pipeline_product_id)\n",
    "\n",
    "# pprint(search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Budgets': [],\n",
      " 'LaunchPaths': [{'Id': 'lpv2-otfcrq7zdg5sc',\n",
      "                  'Name': 'Amazon SageMaker Solutions and ML Ops products'}],\n",
      " 'ProductViewSummary': {'HasDefaultPath': False,\n",
      "                        'Id': 'prodview-wbmrovteqfhoy',\n",
      "                        'Name': 'MLOps template for model building, training, '\n",
      "                                'and deployment',\n",
      "                        'Owner': 'Amazon SageMaker',\n",
      "                        'ProductId': 'prod-j3ufw6hl7utxm',\n",
      "                        'ShortDescription': 'This template enables you to '\n",
      "                                            'easily build, train, and deploy '\n",
      "                                            'machine learning models. You can '\n",
      "                                            'adopt MLOps best practices and '\n",
      "                                            'enable Continuous '\n",
      "                                            'Integration/Continuous Deployment '\n",
      "                                            'for building, training, and '\n",
      "                                            'evaluating machine learning '\n",
      "                                            'models using Amazon SageMaker '\n",
      "                                            'Pipelines, registering models to '\n",
      "                                            'the Model Registry, and '\n",
      "                                            'automating model model '\n",
      "                                            'deployment. Amazon SageMaker '\n",
      "                                            'creates an AWS CodeCommit code '\n",
      "                                            'repository for you to manage your '\n",
      "                                            'code and uses AWS CodePipeline to '\n",
      "                                            'build, train, and deploy your '\n",
      "                                            'machine learning models on '\n",
      "                                            'pre-production and production '\n",
      "                                            'Amazon SageMaker endpoints for '\n",
      "                                            'real-time inference.',\n",
      "                        'Type': 'CLOUD_FORMATION_TEMPLATE'},\n",
      " 'ProvisioningArtifacts': [{'CreatedTime': datetime.datetime(2020, 12, 2, 1, 23, 41, tzinfo=tzlocal()),\n",
      "                            'Guidance': 'DEFAULT',\n",
      "                            'Id': 'pa-oacphmo7m2bji',\n",
      "                            'Name': 'v1.0'}],\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1099',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Tue, 05 Jan 2021 05:57:34 GMT',\n",
      "                                      'x-amzn-requestid': 'b8935208-6eec-4c41-9f09-8731bfd58e55'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'b8935208-6eec-4c41-9f09-8731bfd58e55',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "describe_response = sc.describe_product(Id=sagemaker_pipeline_product_id)\n",
    "\n",
    "sagemaker_pipeline_product_provisioning_artifact_id = describe_response['ProvisioningArtifacts'][0]['Id']\n",
    "\n",
    "pprint(describe_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa-oacphmo7m2bji\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker_pipeline_product_provisioning_artifact_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProjectArn': 'arn:aws:sagemaker:us-east-1:835319576252:project/dsoaws-1609826255',\n",
      " 'ProjectId': 'p-mz9w9bo7oooi',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '112',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Tue, 05 Jan 2021 05:57:35 GMT',\n",
      "                                      'x-amzn-requestid': '248de865-d800-46d2-949b-44b136fbed65'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '248de865-d800-46d2-949b-44b136fbed65',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "sagemaker_project_name = 'dsoaws-{}'.format(timestamp)\n",
    "\n",
    "create_response = sm.create_project(\n",
    "    ProjectName=sagemaker_project_name,\n",
    "    ProjectDescription='dsoaws-{}'.format(timestamp),\n",
    "    ServiceCatalogProvisioningDetails={\n",
    "        'ProductId': sagemaker_pipeline_product_id,\n",
    "        'ProvisioningArtifactId': sagemaker_pipeline_product_provisioning_artifact_id\n",
    "     }\n",
    ")\n",
    "\n",
    "sagemaker_project_id = create_response['ProjectId']\n",
    "sagemaker_project_arn = create_response['ProjectArn']\n",
    "\n",
    "pprint(create_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws-1609826255-p-mz9w9bo7oooi\n"
     ]
    }
   ],
   "source": [
    "sagemaker_project_name_and_id = '{}-{}'.format(sagemaker_project_name, sagemaker_project_id)\n",
    "\n",
    "print(sagemaker_project_name_and_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the Newly-Created Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProjectArn': 'arn:aws:sagemaker:us-east-1:835319576252:project/dsoaws-1609826255', 'ProjectName': 'dsoaws-1609826255', 'ProjectId': 'p-mz9w9bo7oooi', 'ProjectDescription': 'dsoaws-1609826255', 'ServiceCatalogProvisioningDetails': {'ProductId': 'prod-j3ufw6hl7utxm', 'ProvisioningArtifactId': 'pa-oacphmo7m2bji'}, 'ProjectStatus': 'Pending', 'CreationTime': datetime.datetime(2021, 1, 5, 5, 57, 35, 759000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '540e7173-a0d9-4dd3-a000-ab3869576fe6', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '540e7173-a0d9-4dd3-a000-ab3869576fe6', 'content-type': 'application/x-amz-json-1.1', 'content-length': '360', 'date': 'Tue, 05 Jan 2021 05:57:35 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = sm.describe_project(ProjectName=sagemaker_project_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending\n"
     ]
    }
   ],
   "source": [
    "project_status = response['ProjectStatus']\n",
    "print(project_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach IAM Policies for FeatureStore \n",
    "This is used for Code Build Pipeline Executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_role_name='AmazonSageMakerServiceCatalogProductsUseRole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835319576252\n"
     ]
    }
   ],
   "source": [
    "account_id = sts.get_caller_identity()['Account']\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::835319576252:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "sc_role_arn = 'arn:aws:iam::{}:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole'.format(account_id)\n",
    "print(sc_role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'b0f96772-3e38-40b0-b9dc-60e25dfcb319', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b0f96772-3e38-40b0-b9dc-60e25dfcb319', 'content-type': 'text/xml', 'content-length': '212', 'date': 'Tue, 05 Jan 2021 05:57:36 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = iam.attach_role_policy(\n",
    "    RoleName=sc_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '37af1982-043c-4d71-9ded-2d6977961bc2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '37af1982-043c-4d71-9ded-2d6977961bc2', 'content-type': 'text/xml', 'content-length': '212', 'date': 'Tue, 05 Jan 2021 05:57:36 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = iam.attach_role_policy(\n",
    "    RoleName=sc_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFeatureStoreAccess'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for Project to be Created_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Project...\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateCompleted\n",
      "Project CreateCompleted\n",
      "{'ProjectArn': 'arn:aws:sagemaker:us-east-1:835319576252:project/dsoaws-1609826255', 'ProjectName': 'dsoaws-1609826255', 'ProjectId': 'p-mz9w9bo7oooi', 'ProjectDescription': 'dsoaws-1609826255', 'ServiceCatalogProvisioningDetails': {'ProductId': 'prod-j3ufw6hl7utxm', 'ProvisioningArtifactId': 'pa-oacphmo7m2bji'}, 'ServiceCatalogProvisionedProductDetails': {'ProvisionedProductId': 'pp-nlsshgqldnx5m'}, 'ProjectStatus': 'CreateCompleted', 'CreationTime': datetime.datetime(2021, 1, 5, 5, 57, 35, 759000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'd33cd4ca-41fc-437d-96a3-469566430c99', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd33cd4ca-41fc-437d-96a3-469566430c99', 'content-type': 'application/x-amz-json-1.1', 'content-length': '454', 'date': 'Tue, 05 Jan 2021 06:00:06 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "try:\n",
    "    create_project_response = sm.describe_project(ProjectName=sagemaker_project_name)\n",
    "    project_status = create_project_response['ProjectStatus']\n",
    "    print('Creating Project...')\n",
    "\n",
    "    while project_status in ['Pending', 'CreateInProgress']:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)\n",
    "        create_project_response = sm.describe_project(ProjectName=sagemaker_project_name)\n",
    "        project_status = create_project_response['ProjectStatus']\n",
    "        print('Project status: {}'.format(project_status))\n",
    "\n",
    "    if project_status == 'CreateCompleted':   \n",
    "        print('Project {}'.format(project_status))\n",
    "\n",
    "    else:\n",
    "        print('Project status: {}'.format(project_status))\n",
    "        raise Exception('Project not created.')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(create_project_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for Project to be Created ^^ Above ^^_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the `Abalone` Sample Pipeline that Ships with SageMaker Pipelines\n",
    "The sample \"abalone\" pipeline starts automatically when we create the project.  We want to stop this pipeline to release these resources and use them for our own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi/execution/tupernr5vfdh\n"
     ]
    }
   ],
   "source": [
    "sample_abalone_pipeline_execution_arn = sm.list_pipeline_executions(PipelineName=sagemaker_project_name_and_id)['PipelineExecutionSummaries'][0]['PipelineExecutionArn']\n",
    "\n",
    "print(sample_abalone_pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi/execution/tupernr5vfdh',\n",
       " 'ResponseMetadata': {'RequestId': '4df95727-0bac-4171-b671-144883f97a67',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4df95727-0bac-4171-b671-144883f97a67',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Tue, 05 Jan 2021 06:00:07 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stop_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline execution status Stopped\n",
      "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi', 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi/execution/tupernr5vfdh', 'PipelineExecutionDisplayName': 'execution-1609826384700', 'PipelineExecutionStatus': 'Stopped', 'CreationTime': datetime.datetime(2021, 1, 5, 5, 59, 44, 572000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2021, 1, 5, 6, 3, 36, 25000, tzinfo=tzlocal()), 'CreatedBy': {}, 'LastModifiedBy': {}, 'ResponseMetadata': {'RequestId': 'b43449e6-65fa-45e8-96e9-d71b9fcb704b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b43449e6-65fa-45e8-96e9-d71b9fcb704b', 'content-type': 'application/x-amz-json-1.1', 'content-length': '427', 'date': 'Tue, 05 Jan 2021 06:04:52 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "    pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "\n",
    "    while pipeline_execution_status not in ['Stopped', 'Failed']:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)\n",
    "        describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "        pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "        print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "\n",
    "    if pipeline_execution_status in ['Stopped', 'Failed']:   \n",
    "        print('Pipeline execution status {}'.format(pipeline_execution_status))\n",
    "    else:\n",
    "        print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "        raise Exception('Pipeline execution not deleted.')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(describe_pipeline_execution_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi',\n",
       " 'ResponseMetadata': {'RequestId': '5ebacd78-367e-4ca7-8ab7-84e75f753c3a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '5ebacd78-367e-4ca7-8ab7-84e75f753c3a',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '100',\n",
       "   'date': 'Tue, 05 Jan 2021 06:04:58 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_pipeline(PipelineName=sagemaker_project_name_and_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone the MLOps Repositories in AWS CodeCommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sm_studio_root_path='/root/' \n",
    "sm_notebooks_root_path='/home/ec2-user/SageMaker/'\n",
    "\n",
    "root_path = sm_notebooks_root_path if os.path.isdir(sm_notebooks_root_path) else sm_studio_root_path\n",
    "\n",
    "print(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild\n"
     ]
    }
   ],
   "source": [
    "code_commit_repo1 = 'https://git-codecommit.{}.amazonaws.com/v1/repos/sagemaker-{}-modelbuild'.format(region, sagemaker_project_name_and_id)\n",
    "print(code_commit_repo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild\n"
     ]
    }
   ],
   "source": [
    "sagemaker_mlops_build_code = '{}{}/sagemaker-{}-modelbuild'.format(root_path, sagemaker_project_name_and_id, sagemaker_project_name_and_id)\n",
    "print(sagemaker_mlops_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "code_commit_repo2 = 'https://git-codecommit.{}.amazonaws.com/v1/repos/sagemaker-{}-modeldeploy'.format(region, sagemaker_project_name_and_id)\n",
    "print(code_commit_repo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "sagemaker_mlops_deploy_code = '{}{}/sagemaker-{}-modeldeploy'.format(root_path, sagemaker_project_name_and_id, sagemaker_project_name_and_id)\n",
    "print(sagemaker_mlops_deploy_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper '!aws codecommit credential-helper $@'\n",
    "!git config --global credential.UseHttpPath true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for Project to be Created ^^ Above ^^_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild'...\n",
      "remote: Counting objects: 26, done.\u001b[K\n",
      "Unpacking objects: 100% (26/26), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone $code_commit_repo1 $sagemaker_mlops_build_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modeldeploy'...\n",
      "remote: Counting objects: 12, done.\u001b[K\n",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone $code_commit_repo2 $sagemaker_mlops_deploy_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stock `Abalone` Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $sagemaker_mlops_build_code/pipelines/abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Workshop Code Into Local Project Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/workshop/10_pipeline/sagemaker/sagemaker-project-modelbuild\n"
     ]
    }
   ],
   "source": [
    "workshop_project_build_code='{}workshop/10_pipeline/sagemaker/sagemaker-project-modelbuild'.format(root_path)\n",
    "print(workshop_project_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/workshop/10_pipeline/sagemaker/sagemaker-project-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "workshop_project_deploy_code='{}workshop/10_pipeline/sagemaker/sagemaker-project-modeldeploy'.format(root_path)\n",
    "print(workshop_project_deploy_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R $workshop_project_build_code/* $sagemaker_mlops_build_code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R $workshop_project_deploy_code/* $sagemaker_mlops_deploy_code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit New Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker_mlops_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   README.md\u001b[m\n",
      "\t\u001b[31mmodified:   codebuild-buildspec.yml\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/__init__.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/evaluate.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/pipeline.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/preprocess.py\u001b[m\n",
      "\t\u001b[31mmodified:   pipelines/run_pipeline.py\u001b[m\n",
      "\t\u001b[31mmodified:   setup.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31mpipelines/dsoaws/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[master 0e02d04] Data Science on AWS\n",
      " 14 files changed, 2227 insertions(+), 452 deletions(-)\n",
      " delete mode 100644 pipelines/abalone/evaluate.py\n",
      " delete mode 100644 pipelines/abalone/pipeline.py\n",
      " delete mode 100644 pipelines/abalone/preprocess.py\n",
      " rename pipelines/{abalone => dsoaws}/__init__.py (100%)\n",
      " create mode 100644 pipelines/dsoaws/evaluate_model_metrics.py\n",
      " create mode 100644 pipelines/dsoaws/inference.py\n",
      " create mode 100644 pipelines/dsoaws/pipeline.py\n",
      " create mode 100644 pipelines/dsoaws/preprocess-scikit-text-to-bert-feature-store.py\n",
      " create mode 100644 pipelines/dsoaws/test_data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      " create mode 100644 pipelines/dsoaws/tf_bert_reviews.py\n",
      "Enumerating objects: 21, done.\n",
      "Counting objects: 100% (21/21), done.\n",
      "Delta compression using up to 8 threads.\n",
      "Compressing objects: 100% (15/15), done.\n",
      "Writing objects: 100% (15/15), 18.14 MiB | 18.69 MiB/s, done.\n",
      "Total 15 (delta 6), reused 0 (delta 0)\n",
      "To https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild\n",
      "   a96097c..0e02d04  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd $sagemaker_mlops_build_code; git status; git add --all .; git commit -m \"Data Science on AWS\"; git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   README.md\u001b[m\n",
      "\t\u001b[31mmodified:   prod-config.json\u001b[m\n",
      "\t\u001b[31mmodified:   staging-config.json\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[master 99f41fe] Data Science on AWS\n",
      " 3 files changed, 3 insertions(+), 3 deletions(-)\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 8 threads.\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 442 bytes | 442.00 KiB/s, done.\n",
      "Total 5 (delta 4), reused 0 (delta 0)\n",
      "To https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modeldeploy\n",
      "   1955a17..99f41fe  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd $sagemaker_mlops_deploy_code; git status; git add --all .; git commit -m \"Data Science on AWS\"; git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 15072 Jan  5 06:05 /home/ec2-user/SageMaker/dsoaws-1609826255-p-mz9w9bo7oooi/sagemaker-dsoaws-1609826255-p-mz9w9bo7oooi-modelbuild/pipelines/dsoaws/pipeline.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $sagemaker_mlops_build_code/pipelines/dsoaws/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mExample workflow pipeline script for BERT pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m                                                 . -RegisterModel\u001b[39;49;00m\r\n",
      "\u001b[33m                                                .\u001b[39;49;00m\r\n",
      "\u001b[33m    Process-> Train -> (Evaluate -> Condition) .\u001b[39;49;00m\r\n",
      "\u001b[33m                                                .\u001b[39;49;00m\r\n",
      "\u001b[33m                                                 . -(stop)\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33mImplements a get_pipeline(**kwargs) method.\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mbotocore\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexceptions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ClientError\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msession\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mestimator\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Estimator\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36minputs\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TrainingInput\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SKLearnProcessor\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TensorFlow\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    MetricsSource,\r\n",
      "    ModelMetrics,\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ProcessingInput,\r\n",
      "    ProcessingOutput,\r\n",
      "    ScriptProcessor,\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ParameterInteger,\r\n",
      "    ParameterString,\r\n",
      "    ParameterFloat\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msteps\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ProcessingStep,\r\n",
      "    TrainingStep,\r\n",
      "    CreateModelStep\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MetricsSource, ModelMetrics \r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mconditions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ConditionGreaterThanOrEqualTo\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcondition_step\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ConditionStep,\r\n",
      "    JsonGet,\r\n",
      ")\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mproperties\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PropertyFile\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mstep_collections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RegisterModel\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Model\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36minputs\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CreateModelInput\r\n",
      "\r\n",
      "\r\n",
      "sess   = sagemaker.Session()\r\n",
      "bucket = sess.default_bucket()\r\n",
      "timestamp = \u001b[36mint\u001b[39;49;00m(time.time())\r\n",
      "\r\n",
      "BASE_DIR = os.path.dirname(os.path.realpath(\u001b[31m__file__\u001b[39;49;00m))\r\n",
      "\u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mBASE_DIR: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BASE_DIR))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_pipeline\u001b[39;49;00m(\r\n",
      "    region,\r\n",
      "    role,\r\n",
      "    default_bucket,\r\n",
      "    pipeline_name,\r\n",
      "    model_package_group_name,\r\n",
      "    base_job_prefix\r\n",
      "):\r\n",
      "    \u001b[33m\"\"\"Gets a SageMaker ML Pipeline instance working with BERT.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        region: AWS region to create and run the pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m        role: IAM role to create and run steps and pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m        default_bucket: the bucket to use for storing the artifacts\u001b[39;49;00m\r\n",
      "\u001b[33m        pipeline_name:  name of this pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m        model_package_group_name:  model package group\u001b[39;49;00m\r\n",
      "\u001b[33m        base_job_prefix:  prefic of the job name\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        an instance of a pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \r\n",
      "    sm = boto3.Session().client(service_name=\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, region_name=region)\r\n",
      "    \r\n",
      "    input_data = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mInputDataUrl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/amazon-reviews-pds/tsv/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(bucket),\r\n",
      "    )\r\n",
      "        \r\n",
      "    processing_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    processing_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.2xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    max_seq_length = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mMaxSeqLength\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m64\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    balance_dataset = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mBalanceDataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    train_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.90\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    validation_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mValidationSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.05\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    test_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTestSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.05\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    feature_store_offline_prefix = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mFeatureStoreOfflinePrefix\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mreviews-feature-store-\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(timestamp),\r\n",
      "    )\r\n",
      "\r\n",
      "    feature_group_name = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mFeatureGroupName\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mreviews-feature-group-\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(timestamp)\r\n",
      "    )\r\n",
      "    \r\n",
      "    train_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainingInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.9xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    train_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainingInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    model_approval_status = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mModelApprovalStatus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mPendingManualApproval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    deploy_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mDeployInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.m5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    deploy_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mDeployInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# PROCESSING STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    processor = SKLearnProcessor(\r\n",
      "        framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m0.23-1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        role=role,\r\n",
      "        instance_type=processing_instance_type,\r\n",
      "        instance_count=processing_instance_count,\r\n",
      "        env={\u001b[33m'\u001b[39;49;00m\u001b[33mAWS_DEFAULT_REGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: region},\r\n",
      "        max_runtime_in_seconds=\u001b[34m7200\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    processing_inputs=[\r\n",
      "        ProcessingInput(\r\n",
      "            input_name=\u001b[33m'\u001b[39;49;00m\u001b[33mraw-input-data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "            source=input_data,\r\n",
      "            destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "            s3_data_distribution_type=\u001b[33m'\u001b[39;49;00m\u001b[33mShardedByS3Key\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "        )\r\n",
      "    ]\r\n",
      "    \r\n",
      "    processing_outputs=[\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "    ]\r\n",
      "    \r\n",
      "    processing_step = ProcessingStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        processor=processor,\r\n",
      "        inputs=processing_inputs,\r\n",
      "        outputs=processing_outputs,\r\n",
      "        job_arguments=[\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--train-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(train_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--validation-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(validation_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--test-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(test_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--max-seq-length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(max_seq_length.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--balance-dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(balance_dataset.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--feature-store-offline-prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(feature_store_offline_prefix.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--feature-group-name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(feature_group_name.default_value)\r\n",
      "        ],\r\n",
      "        code=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33mpreprocess-scikit-text-to-bert-feature-store.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# TRAINING STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    epochs=\u001b[34m1\u001b[39;49;00m\r\n",
      "    learning_rate=\u001b[34m0.00001\u001b[39;49;00m\r\n",
      "    epsilon=\u001b[34m0.00000001\u001b[39;49;00m\r\n",
      "    train_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    validation_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    test_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    train_steps_per_epoch=\u001b[34m50\u001b[39;49;00m\r\n",
      "    validation_steps=\u001b[34m50\u001b[39;49;00m\r\n",
      "    test_steps=\u001b[34m50\u001b[39;49;00m\r\n",
      "    train_volume_size=\u001b[34m1024\u001b[39;49;00m\r\n",
      "    use_xla=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    use_amp=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    freeze_bert_layer=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_sagemaker_debugger=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_checkpointing=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_tensorboard=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    input_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mFile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    run_validation=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    run_test=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    run_sample_predictions=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    \r\n",
      "    metrics_definitions = [\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain:loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mloss: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain:accuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33maccuracy: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation:loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mval_loss: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation:accuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mval_accuracy: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\r\n",
      "    ]\r\n",
      "    \r\n",
      "    train_src=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \r\n",
      "    model_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{default_bucket}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{base_job_prefix}\u001b[39;49;00m\u001b[33m/output/model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \r\n",
      "    estimator = TensorFlow(\r\n",
      "        entry_point=\u001b[33m'\u001b[39;49;00m\u001b[33mtf_bert_reviews.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        source_dir=BASE_DIR,\r\n",
      "        role=role,\r\n",
      "        output_path=model_path,\r\n",
      "        instance_count=train_instance_count,\r\n",
      "        instance_type=train_instance_type,\r\n",
      "        volume_size=train_volume_size,\r\n",
      "        py_version=\u001b[33m'\u001b[39;49;00m\u001b[33mpy37\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m2.3.1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        hyperparameters={\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epochs,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mlearning_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: learning_rate,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mepsilon\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epsilon,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: validation_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_steps_per_epoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_steps_per_epoch,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: validation_steps,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_steps,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33muse_xla\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: use_xla,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33muse_amp\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: use_amp,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mmax_seq_length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: max_seq_length,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mfreeze_bert_layer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: freeze_bert_layer,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_sagemaker_debugger\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_sagemaker_debugger,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_checkpointing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_checkpointing,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_tensorboard\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_tensorboard,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_validation,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_test,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_sample_predictions\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_sample_predictions},\r\n",
      "        input_mode=input_mode,\r\n",
      "        metric_definitions=metrics_definitions,\r\n",
      "\u001b[37m#        max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "\r\n",
      "    training_step = TrainingStep(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mTrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        estimator=estimator,\r\n",
      "        inputs={\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            )        \r\n",
      "        }\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# EVALUATION STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "        \r\n",
      "    evaluation_processor = SKLearnProcessor(framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m0.23-1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                                            role=role,\r\n",
      "                                            instance_type=processing_instance_type,\r\n",
      "                                            instance_count=processing_instance_count,\r\n",
      "                                            env={\u001b[33m'\u001b[39;49;00m\u001b[33mAWS_DEFAULT_REGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: region},\r\n",
      "                                            max_runtime_in_seconds=\u001b[34m7200\u001b[39;49;00m)    \r\n",
      "    \r\n",
      "    evaluation_report = PropertyFile(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mEvaluationReport\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mmetrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        path=\u001b[33m'\u001b[39;49;00m\u001b[33mevaluation.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    evaluation_step = ProcessingStep(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mEvaluateModel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        processor=evaluation_processor,\r\n",
      "        code=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluate_model_metrics.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\r\n",
      "        inputs=[\r\n",
      "            ProcessingInput(\r\n",
      "                source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "                destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            ProcessingInput(\r\n",
      "                source=input_data,\r\n",
      "                destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            )\r\n",
      "        ],\r\n",
      "        outputs=[\r\n",
      "            ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mmetrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \r\n",
      "                             s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                             source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/metrics/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\r\n",
      "        ],\r\n",
      "        job_arguments=[\r\n",
      "                       \u001b[33m'\u001b[39;49;00m\u001b[33m--max-seq-length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(max_seq_length.default_value),\r\n",
      "                      ],\r\n",
      "        property_files=[evaluation_report],  \u001b[37m# these cause deserialization issues\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "    \r\n",
      "    model_metrics = ModelMetrics(\r\n",
      "        model_statistics=MetricsSource(\r\n",
      "            s3_uri=\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\r\n",
      "                evaluation_step.arguments[\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingOutputConfig\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mOutputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mS3Output\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "            ),\r\n",
      "            content_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        )\r\n",
      "    )    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################    \u001b[39;49;00m\r\n",
      "    \u001b[37m## REGISTER TRAINED MODEL STEP \u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    inference_image_uri = sagemaker.image_uris.retrieve(\r\n",
      "        framework=\u001b[33m\"\u001b[39;49;00m\u001b[33mtensorflow\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        region=region,\r\n",
      "        version=\u001b[33m\"\u001b[39;49;00m\u001b[33m2.3.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        py_version=\u001b[33m\"\u001b[39;49;00m\u001b[33mpy37\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        instance_type=deploy_instance_type,\r\n",
      "        image_scope=\u001b[33m\"\u001b[39;49;00m\u001b[33minference\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(inference_image_uri)\r\n",
      "\r\n",
      "    register_step = RegisterModel(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mRegisterModel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        estimator=estimator,\r\n",
      "        image_uri=inference_image_uri, \u001b[37m# we have to specify, by default it's using training image\u001b[39;49;00m\r\n",
      "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "        content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\r\n",
      "        response_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\r\n",
      "        inference_instances=[deploy_instance_type], \u001b[37m# The JSON spec must be within these instance types or we will see \"Instance Type Not Allowed\" Exception \u001b[39;49;00m\r\n",
      "        transform_instances=[deploy_instance_type],\r\n",
      "        model_package_group_name=model_package_group_name,\r\n",
      "        approval_status=model_approval_status,\r\n",
      "    )\r\n",
      "        \r\n",
      "      \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CREATE MODEL FOR DEPLOYMENT STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    model = Model(\r\n",
      "        image_uri=inference_image_uri,\r\n",
      "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "        sagemaker_session=sess,\r\n",
      "        role=role,\r\n",
      "    )\r\n",
      "\r\n",
      "    create_inputs = CreateModelInput(\r\n",
      "        instance_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.m5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    create_step = CreateModelStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCreateModel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        model=model,\r\n",
      "        inputs=create_inputs,\r\n",
      "    )\r\n",
      "    \r\n",
      "\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CONDITION STEP:  EVALUATE THE MODEL\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\r\n",
      "        left=JsonGet(\r\n",
      "            step=evaluation_step,\r\n",
      "            property_file=evaluation_report,\r\n",
      "            json_path=\u001b[33m\"\u001b[39;49;00m\u001b[33mmetrics.accuracy.value\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        ),\r\n",
      "        right=\u001b[34m0.01\u001b[39;49;00m \u001b[37m# accuracy \u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    minimum_accuracy_condition_step = ConditionStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mAccuracyCondition\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        conditions=[minimum_accuracy_condition],\r\n",
      "        if_steps=[register_step, create_step], \u001b[37m# success, continue with model registration\u001b[39;49;00m\r\n",
      "        else_steps=[], \u001b[37m# fail, end the pipeline\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CREATE PIPELINE\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    pipeline = Pipeline(\r\n",
      "        name=pipeline_name,\r\n",
      "        parameters=[\r\n",
      "            input_data,\r\n",
      "            processing_instance_count,\r\n",
      "            processing_instance_type,\r\n",
      "            max_seq_length,\r\n",
      "            balance_dataset,\r\n",
      "            train_split_percentage,\r\n",
      "            validation_split_percentage,\r\n",
      "            test_split_percentage,\r\n",
      "            feature_store_offline_prefix,\r\n",
      "            feature_group_name,\r\n",
      "            train_instance_type,\r\n",
      "            train_instance_count,\r\n",
      "            model_approval_status,\r\n",
      "            deploy_instance_type,\r\n",
      "            deploy_instance_count\r\n",
      "        ],\r\n",
      "    steps=[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step], \u001b[37m# register_step, create_step],\u001b[39;49;00m\r\n",
      "        sagemaker_session=sess\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################    \u001b[39;49;00m\r\n",
      "    \u001b[37m## RETURN PIPELINE\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize $sagemaker_mlops_build_code/pipelines/dsoaws/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You Are Now Running a BERT Pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi/execution/42ulswocfppp',\n",
      "  'PipelineExecutionDisplayName': 'execution-1609827003925',\n",
      "  'PipelineExecutionStatus': 'Executing',\n",
      "  'StartTime': datetime.datetime(2021, 1, 5, 6, 10, 3, 808000, tzinfo=tzlocal())},\n",
      " {'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609826255-p-mz9w9bo7oooi/execution/fzfyr23fvab6',\n",
      "  'PipelineExecutionDisplayName': 'execution-1609826827202',\n",
      "  'PipelineExecutionStatus': 'Failed',\n",
      "  'StartTime': datetime.datetime(2021, 1, 5, 6, 7, 7, 92000, tzinfo=tzlocal())}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "list_executions_response = sm.list_pipeline_executions(PipelineName=sagemaker_project_name_and_id)['PipelineExecutionSummaries']\n",
    "\n",
    "pprint(list_executions_response)\n",
    "\n",
    "# try:\n",
    "#     describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "#     pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "\n",
    "#     while pipeline_execution_status not in ['Stopped', 'Failed']:\n",
    "#         print('Please wait...')\n",
    "#         time.sleep(30)\n",
    "#         describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "#         pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "#         print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "\n",
    "#     if pipeline_execution_status in ['Stopped', 'Failed']:   \n",
    "#         print('Pipeline execution status {}'.format(pipeline_execution_status))\n",
    "#     else:\n",
    "#         print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "#         raise Exception('Pipeline execution not deleted.')\n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "    \n",
    "# print(describe_pipeline_execution_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Pipeline Executions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sagemaker_project_name_and_id)\n",
    "\n",
    "# sm.list_pipeline_executions(PipelineName=sagemaker_project_name_and_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'sagemaker_mlops_build_code' (str)\n",
      "Stored 'sagemaker_mlops_deploy_code' (str)\n",
      "Stored 'sagemaker_project_name' (str)\n",
      "Stored 'sagemaker_project_id' (str)\n",
      "Stored 'sagemaker_project_name_and_id' (str)\n",
      "Stored 'sagemaker_project_arn' (str)\n",
      "Stored 'sagemaker_pipeline_product_id' (str)\n",
      "Stored 'sagemaker_pipeline_product_provisioning_artifact_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store sagemaker_mlops_build_code\n",
    "%store sagemaker_mlops_deploy_code\n",
    "%store sagemaker_project_name\n",
    "%store sagemaker_project_id\n",
    "%store sagemaker_project_name_and_id\n",
    "%store sagemaker_project_arn\n",
    "%store sagemaker_pipeline_product_id\n",
    "%store sagemaker_pipeline_product_provisioning_artifact_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
