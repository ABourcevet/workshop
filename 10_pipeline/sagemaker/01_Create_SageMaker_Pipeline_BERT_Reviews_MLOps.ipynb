{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SageMaker MLOps Project for Pipelines\n",
    "Note:  This requires that you have enabled products within SageMaker Studio\n",
    "\n",
    "![](../img/enable-service-catalog-portfolio-for-studio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "sc = boto3.Session().client(service_name='servicecatalog', region_name=region)\n",
    "sts = boto3.Session().client(service_name='sts', region_name=region)\n",
    "iam = boto3.Session().client(service_name='iam', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod-j3ufw6hl7utxm\n"
     ]
    }
   ],
   "source": [
    "search_response = sc.search_products(\n",
    "   Filters={\n",
    "       'FullTextSearch': \n",
    "       [\n",
    "           'MLOps template for model building, training, and deployment'\n",
    "       ]\n",
    "   }\n",
    ")\n",
    "\n",
    "sagemaker_pipeline_product_id = search_response['ProductViewSummaries'][0]['ProductId']\n",
    "print(sagemaker_pipeline_product_id)\n",
    "\n",
    "# pprint(search_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Budgets': [],\n",
      " 'LaunchPaths': [{'Id': 'lpv2-otfcrq7zdg5sc',\n",
      "                  'Name': 'Amazon SageMaker Solutions and ML Ops products'}],\n",
      " 'ProductViewSummary': {'HasDefaultPath': False,\n",
      "                        'Id': 'prodview-wbmrovteqfhoy',\n",
      "                        'Name': 'MLOps template for model building, training, '\n",
      "                                'and deployment',\n",
      "                        'Owner': 'Amazon SageMaker',\n",
      "                        'ProductId': 'prod-j3ufw6hl7utxm',\n",
      "                        'ShortDescription': 'This template enables you to '\n",
      "                                            'easily build, train, and deploy '\n",
      "                                            'machine learning models. You can '\n",
      "                                            'adopt MLOps best practices and '\n",
      "                                            'enable Continuous '\n",
      "                                            'Integration/Continuous Deployment '\n",
      "                                            'for building, training, and '\n",
      "                                            'evaluating machine learning '\n",
      "                                            'models using Amazon SageMaker '\n",
      "                                            'Pipelines, registering models to '\n",
      "                                            'the Model Registry, and '\n",
      "                                            'automating model model '\n",
      "                                            'deployment. Amazon SageMaker '\n",
      "                                            'creates an AWS CodeCommit code '\n",
      "                                            'repository for you to manage your '\n",
      "                                            'code and uses AWS CodePipeline to '\n",
      "                                            'build, train, and deploy your '\n",
      "                                            'machine learning models on '\n",
      "                                            'pre-production and production '\n",
      "                                            'Amazon SageMaker endpoints for '\n",
      "                                            'real-time inference.',\n",
      "                        'Type': 'CLOUD_FORMATION_TEMPLATE'},\n",
      " 'ProvisioningArtifacts': [{'CreatedTime': datetime.datetime(2020, 12, 2, 1, 23, 41, tzinfo=tzlocal()),\n",
      "                            'Guidance': 'DEFAULT',\n",
      "                            'Id': 'pa-oacphmo7m2bji',\n",
      "                            'Name': 'v1.0'}],\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '1099',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Tue, 05 Jan 2021 08:34:16 GMT',\n",
      "                                      'x-amzn-requestid': '4c40d896-5685-4905-95cb-515f543f969a'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '4c40d896-5685-4905-95cb-515f543f969a',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "describe_response = sc.describe_product(Id=sagemaker_pipeline_product_id)\n",
    "\n",
    "sagemaker_pipeline_product_provisioning_artifact_id = describe_response['ProvisioningArtifacts'][0]['Id']\n",
    "\n",
    "pprint(describe_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa-oacphmo7m2bji\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker_pipeline_product_provisioning_artifact_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a SageMaker Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProjectArn': 'arn:aws:sagemaker:us-east-1:835319576252:project/dsoaws-1609835656',\n",
      " 'ProjectId': 'p-ef3uutdiztnk',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '112',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Tue, 05 Jan 2021 08:34:15 GMT',\n",
      "                                      'x-amzn-requestid': 'adfdac25-8eb1-433e-9ac7-55f7326970e3'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'adfdac25-8eb1-433e-9ac7-55f7326970e3',\n",
      "                      'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "sagemaker_project_name = 'dsoaws-{}'.format(timestamp)\n",
    "\n",
    "create_response = sm.create_project(\n",
    "    ProjectName=sagemaker_project_name,\n",
    "    ProjectDescription='dsoaws-{}'.format(timestamp),\n",
    "    ServiceCatalogProvisioningDetails={\n",
    "        'ProductId': sagemaker_pipeline_product_id,\n",
    "        'ProvisioningArtifactId': sagemaker_pipeline_product_provisioning_artifact_id\n",
    "     }\n",
    ")\n",
    "\n",
    "sagemaker_project_id = create_response['ProjectId']\n",
    "sagemaker_project_arn = create_response['ProjectArn']\n",
    "\n",
    "pprint(create_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dsoaws-1609835656-p-ef3uutdiztnk\n"
     ]
    }
   ],
   "source": [
    "sagemaker_project_name_and_id = '{}-{}'.format(sagemaker_project_name, sagemaker_project_id)\n",
    "\n",
    "print(sagemaker_project_name_and_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for the Project to be Created_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Project...\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateInProgress\n",
      "Please wait...\n",
      "Project status: CreateCompleted\n",
      "Project CreateCompleted\n",
      "{'ProjectArn': 'arn:aws:sagemaker:us-east-1:835319576252:project/dsoaws-1609835656', 'ProjectName': 'dsoaws-1609835656', 'ProjectId': 'p-ef3uutdiztnk', 'ProjectDescription': 'dsoaws-1609835656', 'ServiceCatalogProvisioningDetails': {'ProductId': 'prod-j3ufw6hl7utxm', 'ProvisioningArtifactId': 'pa-oacphmo7m2bji'}, 'ServiceCatalogProvisionedProductDetails': {'ProvisionedProductId': 'pp-w6pysji7lvncm'}, 'ProjectStatus': 'CreateCompleted', 'CreationTime': datetime.datetime(2021, 1, 5, 8, 34, 16, 349000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'd568e4ef-692a-4bdb-868a-3e8e97603bd3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'd568e4ef-692a-4bdb-868a-3e8e97603bd3', 'content-type': 'application/x-amz-json-1.1', 'content-length': '454', 'date': 'Tue, 05 Jan 2021 08:36:46 GMT'}, 'RetryAttempts': 0}}\n",
      "CPU times: user 55.4 ms, sys: 5.05 ms, total: 60.4 ms\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "\n",
    "try:\n",
    "    create_project_response = sm.describe_project(ProjectName=sagemaker_project_name)\n",
    "    project_status = create_project_response['ProjectStatus']\n",
    "    print('Creating Project...')\n",
    "\n",
    "    while project_status in ['Pending', 'CreateInProgress']:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)\n",
    "        create_project_response = sm.describe_project(ProjectName=sagemaker_project_name)\n",
    "        project_status = create_project_response['ProjectStatus']\n",
    "        print('Project status: {}'.format(project_status))\n",
    "\n",
    "    if project_status == 'CreateCompleted':   \n",
    "        print('Project {}'.format(project_status))\n",
    "\n",
    "    else:\n",
    "        print('Project status: {}'.format(project_status))\n",
    "        raise Exception('Project not created.')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(create_project_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for Project to be Created ^^ Above ^^_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach IAM Policies for FeatureStore \n",
    "This is used for Code Build Pipeline Executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_role_name='AmazonSageMakerServiceCatalogProductsUseRole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "835319576252\n"
     ]
    }
   ],
   "source": [
    "account_id = sts.get_caller_identity()['Account']\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_role_arn = 'arn:aws:iam::{}:role/service-role/AmazonSageMakerServiceCatalogProductsUseRole'.format(account_id)\n",
    "# print(sc_role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '36827aa9-9dce-4011-b755-dea2156b4a1c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '36827aa9-9dce-4011-b755-dea2156b4a1c', 'content-type': 'text/xml', 'content-length': '212', 'date': 'Tue, 05 Jan 2021 08:36:46 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = iam.attach_role_policy(\n",
    "    RoleName=sc_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '2e3c0cae-ab32-4b3c-aef4-75b79f194f2a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '2e3c0cae-ab32-4b3c-aef4-75b79f194f2a', 'content-type': 'text/xml', 'content-length': '212', 'date': 'Tue, 05 Jan 2021 08:36:47 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = iam.attach_role_policy(\n",
    "    RoleName=sc_role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFeatureStoreAccess'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the `Abalone` Sample Pipeline that Ships with SageMaker Pipelines\n",
    "The sample \"abalone\" pipeline starts automatically when we create the project.  We want to stop this pipeline to release these resources and use them for our own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk/execution/q6xwg6lbgpz0\n"
     ]
    }
   ],
   "source": [
    "sample_abalone_pipeline_execution_arn = sm.list_pipeline_executions(PipelineName=sagemaker_project_name_and_id)['PipelineExecutionSummaries'][0]['PipelineExecutionArn']\n",
    "\n",
    "print(sample_abalone_pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk/execution/q6xwg6lbgpz0',\n",
       " 'ResponseMetadata': {'RequestId': 'bb7fe512-89b9-454a-a309-53bef5aa241b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'bb7fe512-89b9-454a-a309-53bef5aa241b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Tue, 05 Jan 2021 08:36:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.stop_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n",
      "Pipeline execution status: Stopping\n",
      "Please wait...\n",
      "Pipeline execution status: Stopping\n",
      "Please wait...\n",
      "Pipeline execution status: Stopping\n",
      "Please wait...\n",
      "Pipeline execution status: Stopping\n",
      "Please wait...\n",
      "Pipeline execution status: Stopping\n",
      "Please wait...\n",
      "Pipeline execution status: Stopped\n",
      "Pipeline execution status Stopped\n",
      "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk', 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk/execution/q6xwg6lbgpz0', 'PipelineExecutionDisplayName': 'execution-1609835758114', 'PipelineExecutionStatus': 'Stopped', 'CreationTime': datetime.datetime(2021, 1, 5, 8, 35, 58, 44000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2021, 1, 5, 8, 39, 38, 838000, tzinfo=tzlocal()), 'CreatedBy': {}, 'LastModifiedBy': {}, 'ResponseMetadata': {'RequestId': '5057a6af-4c35-47bb-9c8c-3afdd705a5e7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5057a6af-4c35-47bb-9c8c-3afdd705a5e7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '427', 'date': 'Tue, 05 Jan 2021 08:39:47 GMT'}, 'RetryAttempts': 0}}\n",
      "CPU times: user 72.2 ms, sys: 0 ns, total: 72.2 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "    pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "\n",
    "    while pipeline_execution_status not in ['Stopped', 'Failed']:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)\n",
    "        describe_pipeline_execution_response = sm.describe_pipeline_execution(PipelineExecutionArn=sample_abalone_pipeline_execution_arn)\n",
    "        pipeline_execution_status = describe_pipeline_execution_response['PipelineExecutionStatus']\n",
    "        print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "\n",
    "    if pipeline_execution_status in ['Stopped', 'Failed']:   \n",
    "        print('Pipeline execution status {}'.format(pipeline_execution_status))\n",
    "    else:\n",
    "        print('Pipeline execution status: {}'.format(pipeline_execution_status))\n",
    "        raise Exception('Pipeline execution not deleted.')\n",
    "        \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(describe_pipeline_execution_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk',\n",
       " 'ResponseMetadata': {'RequestId': 'c4278191-75a2-47e7-8141-77c51b4085fe',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c4278191-75a2-47e7-8141-77c51b4085fe',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '100',\n",
       "   'date': 'Tue, 05 Jan 2021 08:39:47 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.delete_pipeline(PipelineName=sagemaker_project_name_and_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone the MLOps Repositories in AWS CodeCommit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sm_studio_root_path='/root/' \n",
    "sm_notebooks_root_path='/home/ec2-user/SageMaker/'\n",
    "\n",
    "root_path = sm_notebooks_root_path if os.path.isdir(sm_notebooks_root_path) else sm_studio_root_path\n",
    "\n",
    "print(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modelbuild\n"
     ]
    }
   ],
   "source": [
    "code_commit_repo1 = 'https://git-codecommit.{}.amazonaws.com/v1/repos/sagemaker-{}-modelbuild'.format(region, sagemaker_project_name_and_id)\n",
    "print(code_commit_repo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3uutdiztnk/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modelbuild\n"
     ]
    }
   ],
   "source": [
    "sagemaker_mlops_build_code = '{}{}/sagemaker-{}-modelbuild'.format(root_path, sagemaker_project_name_and_id, sagemaker_project_name_and_id)\n",
    "print(sagemaker_mlops_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "code_commit_repo2 = 'https://git-codecommit.{}.amazonaws.com/v1/repos/sagemaker-{}-modeldeploy'.format(region, sagemaker_project_name_and_id)\n",
    "print(code_commit_repo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3uutdiztnk/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "sagemaker_mlops_deploy_code = '{}{}/sagemaker-{}-modeldeploy'.format(root_path, sagemaker_project_name_and_id, sagemaker_project_name_and_id)\n",
    "print(sagemaker_mlops_deploy_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper '!aws codecommit credential-helper $@'\n",
    "!git config --global credential.UseHttpPath true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait for Project to be Created ^^ Above ^^_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3uutdiztnk/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modelbuild'...\n",
      "remote: Counting objects: 26, done.\u001b[K\n",
      "Unpacking objects: 100% (26/26), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone $code_commit_repo1 $sagemaker_mlops_build_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3uutdiztnk/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modeldeploy'...\n",
      "remote: Counting objects: 12, done.\u001b[K\n",
      "Unpacking objects: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone $code_commit_repo2 $sagemaker_mlops_deploy_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stock `Abalone` Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $sagemaker_mlops_build_code/pipelines/abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy Workshop Code Into Local Project Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/workshop/10_pipeline/sagemaker/sagemaker-project-modelbuild\n"
     ]
    }
   ],
   "source": [
    "workshop_project_build_code='{}workshop/10_pipeline/sagemaker/sagemaker-project-modelbuild'.format(root_path)\n",
    "print(workshop_project_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/workshop/10_pipeline/sagemaker/sagemaker-project-modeldeploy\n"
     ]
    }
   ],
   "source": [
    "workshop_project_deploy_code='{}workshop/10_pipeline/sagemaker/sagemaker-project-modeldeploy'.format(root_path)\n",
    "print(workshop_project_deploy_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R $workshop_project_build_code/* $sagemaker_mlops_build_code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -R $workshop_project_deploy_code/* $sagemaker_mlops_deploy_code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit New Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3uutdiztnk/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modelbuild\n"
     ]
    }
   ],
   "source": [
    "print(sagemaker_mlops_build_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   README.md\u001b[m\n",
      "\t\u001b[31mmodified:   codebuild-buildspec.yml\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/__init__.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/evaluate.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/pipeline.py\u001b[m\n",
      "\t\u001b[31mdeleted:    pipelines/abalone/preprocess.py\u001b[m\n",
      "\t\u001b[31mmodified:   pipelines/run_pipeline.py\u001b[m\n",
      "\t\u001b[31mmodified:   setup.py\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\n",
      "\t\u001b[31mpipelines/dsoaws/\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[master a09e278] Data Science on AWS\n",
      " 14 files changed, 2229 insertions(+), 452 deletions(-)\n",
      " delete mode 100644 pipelines/abalone/evaluate.py\n",
      " delete mode 100644 pipelines/abalone/pipeline.py\n",
      " delete mode 100644 pipelines/abalone/preprocess.py\n",
      " rename pipelines/{abalone => dsoaws}/__init__.py (100%)\n",
      " create mode 100644 pipelines/dsoaws/evaluate_model_metrics.py\n",
      " create mode 100644 pipelines/dsoaws/inference.py\n",
      " create mode 100644 pipelines/dsoaws/pipeline.py\n",
      " create mode 100644 pipelines/dsoaws/preprocess-scikit-text-to-bert-feature-store.py\n",
      " create mode 100644 pipelines/dsoaws/test_data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      " create mode 100644 pipelines/dsoaws/tf_bert_reviews.py\n",
      "Enumerating objects: 21, done.\n",
      "Counting objects: 100% (21/21), done.\n",
      "Delta compression using up to 8 threads.\n",
      "Compressing objects: 100% (15/15), done.\n",
      "Writing objects: 100% (15/15), 18.15 MiB | 18.77 MiB/s, done.\n",
      "Total 15 (delta 6), reused 0 (delta 0)\n",
      "To https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modelbuild\n",
      "   bd2a9b9..a09e278  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd $sagemaker_mlops_build_code; git status; git add --all .; git commit -m \"Data Science on AWS\"; git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   README.md\u001b[m\n",
      "\t\u001b[31mmodified:   prod-config.json\u001b[m\n",
      "\t\u001b[31mmodified:   staging-config.json\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "[master a17e050] Data Science on AWS\n",
      " 3 files changed, 3 insertions(+), 3 deletions(-)\n",
      "Enumerating objects: 9, done.\n",
      "Counting objects: 100% (9/9), done.\n",
      "Delta compression using up to 8 threads.\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 442 bytes | 442.00 KiB/s, done.\n",
      "Total 5 (delta 4), reused 0 (delta 0)\n",
      "To https://git-codecommit.us-east-1.amazonaws.com/v1/repos/sagemaker-dsoaws-1609835656-p-ef3uutdiztnk-modeldeploy\n",
      "   8518ca8..a17e050  master -> master\n"
     ]
    }
   ],
   "source": [
    "!cd $sagemaker_mlops_deploy_code; git status; git add --all .; git commit -m \"Data Science on AWS\"; git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'sagemaker_mlops_build_code' (str)\n",
      "Stored 'sagemaker_mlops_deploy_code' (str)\n",
      "Stored 'sagemaker_project_name' (str)\n",
      "Stored 'sagemaker_project_id' (str)\n",
      "Stored 'sagemaker_project_name_and_id' (str)\n",
      "Stored 'sagemaker_project_arn' (str)\n",
      "Stored 'sagemaker_pipeline_product_id' (str)\n",
      "Stored 'sagemaker_pipeline_product_provisioning_artifact_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store sagemaker_mlops_build_code\n",
    "%store sagemaker_mlops_deploy_code\n",
    "%store sagemaker_project_name\n",
    "%store sagemaker_project_id\n",
    "%store sagemaker_project_name_and_id\n",
    "%store sagemaker_project_arn\n",
    "%store sagemaker_pipeline_product_id\n",
    "%store sagemaker_pipeline_product_provisioning_artifact_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 108\r\n",
      "drwxrwxr-x 4 ec2-user ec2-user  4096 Jan  5 08:39 .\r\n",
      "drwxrwxr-x 4 ec2-user ec2-user  4096 Jan  5 08:39 ..\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  8923 Jan  5 08:39 evaluate_model_metrics.py\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  3042 Jan  5 08:39 inference.py\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     0 Jan  5 08:39 __init__.py\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 15072 Jan  5 08:39 pipeline.py\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 26680 Jan  5 08:39 preprocess-scikit-text-to-bert-feature-store.py\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user  4096 Jan  5 08:39 __pycache__\r\n",
      "drwxrwxr-x 2 ec2-user ec2-user  4096 Jan  5 08:39 test_data\r\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 28793 Jan  5 08:39 tf_bert_reviews.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -al $sagemaker_mlops_build_code/pipelines/dsoaws/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33mExample workflow pipeline script for BERT pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m                                                 . -RegisterModel\u001b[39;49;00m\r\n",
      "\u001b[33m                                                .\u001b[39;49;00m\r\n",
      "\u001b[33m    Process-> Train -> (Evaluate -> Condition) .\u001b[39;49;00m\r\n",
      "\u001b[33m                                                .\u001b[39;49;00m\r\n",
      "\u001b[33m                                                 . -(stop)\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33mImplements a get_pipeline(**kwargs) method.\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mbotocore\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexceptions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ClientError\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msession\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mestimator\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Estimator\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36minputs\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TrainingInput\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SKLearnProcessor\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TensorFlow\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    MetricsSource,\r\n",
      "    ModelMetrics,\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ProcessingInput,\r\n",
      "    ProcessingOutput,\r\n",
      "    ScriptProcessor,\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mparameters\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ParameterInteger,\r\n",
      "    ParameterString,\r\n",
      "    ParameterFloat\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msteps\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ProcessingStep,\r\n",
      "    TrainingStep,\r\n",
      "    CreateModelStep\r\n",
      ")\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MetricsSource, ModelMetrics \r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mconditions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ConditionGreaterThanOrEqualTo\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mcondition_step\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    ConditionStep,\r\n",
      "    JsonGet,\r\n",
      ")\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mproperties\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m PropertyFile\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mworkflow\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mstep_collections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m RegisterModel\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Model\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36minputs\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CreateModelInput\r\n",
      "\r\n",
      "\r\n",
      "sess   = sagemaker.Session()\r\n",
      "bucket = sess.default_bucket()\r\n",
      "timestamp = \u001b[36mint\u001b[39;49;00m(time.time())\r\n",
      "\r\n",
      "BASE_DIR = os.path.dirname(os.path.realpath(\u001b[31m__file__\u001b[39;49;00m))\r\n",
      "\u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mBASE_DIR: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(BASE_DIR))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_pipeline\u001b[39;49;00m(\r\n",
      "    region,\r\n",
      "    role,\r\n",
      "    default_bucket,\r\n",
      "    pipeline_name,\r\n",
      "    model_package_group_name,\r\n",
      "    base_job_prefix\r\n",
      "):\r\n",
      "    \u001b[33m\"\"\"Gets a SageMaker ML Pipeline instance working with BERT.\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m        region: AWS region to create and run the pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m        role: IAM role to create and run steps and pipeline.\u001b[39;49;00m\r\n",
      "\u001b[33m        default_bucket: the bucket to use for storing the artifacts\u001b[39;49;00m\r\n",
      "\u001b[33m        pipeline_name:  name of this pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m        model_package_group_name:  model package group\u001b[39;49;00m\r\n",
      "\u001b[33m        base_job_prefix:  prefic of the job name\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    Returns:\u001b[39;49;00m\r\n",
      "\u001b[33m        an instance of a pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \r\n",
      "    sm = boto3.Session().client(service_name=\u001b[33m'\u001b[39;49;00m\u001b[33msagemaker\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, region_name=region)\r\n",
      "    \r\n",
      "    input_data = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mInputDataUrl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/amazon-reviews-pds/tsv/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(bucket),\r\n",
      "    )\r\n",
      "        \r\n",
      "    processing_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    processing_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.2xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    max_seq_length = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mMaxSeqLength\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m64\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    balance_dataset = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mBalanceDataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    train_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.90\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    validation_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mValidationSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.05\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    test_split_percentage = ParameterFloat(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTestSplitPercentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m0.05\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    feature_store_offline_prefix = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mFeatureStoreOfflinePrefix\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mreviews-feature-store-\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(timestamp),\r\n",
      "    )\r\n",
      "\r\n",
      "    feature_group_name = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mFeatureGroupName\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mreviews-feature-group-\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(timestamp)\r\n",
      "    )\r\n",
      "    \r\n",
      "    train_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainingInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.9xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    train_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mTrainingInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    model_approval_status = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mModelApprovalStatus\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mPendingManualApproval\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    deploy_instance_type = ParameterString(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mDeployInstanceType\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.m5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    deploy_instance_count = ParameterInteger(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mDeployInstanceCount\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        default_value=\u001b[34m1\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# PROCESSING STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    processor = SKLearnProcessor(\r\n",
      "        framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m0.23-1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        role=role,\r\n",
      "        instance_type=processing_instance_type,\r\n",
      "        instance_count=processing_instance_count,\r\n",
      "        env={\u001b[33m'\u001b[39;49;00m\u001b[33mAWS_DEFAULT_REGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: region},\r\n",
      "        max_runtime_in_seconds=\u001b[34m7200\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    processing_inputs=[\r\n",
      "        ProcessingInput(\r\n",
      "            input_name=\u001b[33m'\u001b[39;49;00m\u001b[33mraw-input-data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "            source=input_data,\r\n",
      "            destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "            s3_data_distribution_type=\u001b[33m'\u001b[39;49;00m\u001b[33mShardedByS3Key\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "        )\r\n",
      "    ]\r\n",
      "    \r\n",
      "    processing_outputs=[\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "        ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mbert-test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                         s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                         \r\n",
      "                         source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/bert/test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        ),\r\n",
      "    ]\r\n",
      "    \r\n",
      "    processing_step = ProcessingStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        processor=processor,\r\n",
      "        inputs=processing_inputs,\r\n",
      "        outputs=processing_outputs,\r\n",
      "        job_arguments=[\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--train-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(train_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--validation-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(validation_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--test-split-percentage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(test_split_percentage.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--max-seq-length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(max_seq_length.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--balance-dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(balance_dataset.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--feature-store-offline-prefix\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(feature_store_offline_prefix.default_value),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33m--feature-group-name\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(feature_group_name.default_value)\r\n",
      "        ],\r\n",
      "        code=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33mpreprocess-scikit-text-to-bert-feature-store.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# TRAINING STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    epochs=\u001b[34m1\u001b[39;49;00m\r\n",
      "    learning_rate=\u001b[34m0.00001\u001b[39;49;00m\r\n",
      "    epsilon=\u001b[34m0.00000001\u001b[39;49;00m\r\n",
      "    train_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    validation_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    test_batch_size=\u001b[34m128\u001b[39;49;00m\r\n",
      "    train_steps_per_epoch=\u001b[34m50\u001b[39;49;00m\r\n",
      "    validation_steps=\u001b[34m50\u001b[39;49;00m\r\n",
      "    test_steps=\u001b[34m50\u001b[39;49;00m\r\n",
      "    train_volume_size=\u001b[34m1024\u001b[39;49;00m\r\n",
      "    use_xla=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    use_amp=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    freeze_bert_layer=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_sagemaker_debugger=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_checkpointing=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    enable_tensorboard=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    input_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mFile\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    run_validation=\u001b[34mTrue\u001b[39;49;00m\r\n",
      "    run_test=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    run_sample_predictions=\u001b[34mFalse\u001b[39;49;00m\r\n",
      "    \r\n",
      "    metrics_definitions = [\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain:loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mloss: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mtrain:accuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33maccuracy: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation:loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mval_loss: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m},\r\n",
      "        {\u001b[33m'\u001b[39;49;00m\u001b[33mName\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation:accuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRegex\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mval_accuracy: ([0-9\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m.]+)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\r\n",
      "    ]\r\n",
      "    \r\n",
      "    train_src=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33msrc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \r\n",
      "    model_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m{default_bucket}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{base_job_prefix}\u001b[39;49;00m\u001b[33m/output/model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \r\n",
      "    estimator = TensorFlow(\r\n",
      "        entry_point=\u001b[33m'\u001b[39;49;00m\u001b[33mtf_bert_reviews.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        source_dir=BASE_DIR,\r\n",
      "        role=role,\r\n",
      "        output_path=model_path,\r\n",
      "        instance_count=train_instance_count,\r\n",
      "        instance_type=train_instance_type,\r\n",
      "        volume_size=train_volume_size,\r\n",
      "        py_version=\u001b[33m'\u001b[39;49;00m\u001b[33mpy37\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m2.3.1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        hyperparameters={\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mepochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epochs,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mlearning_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: learning_rate,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mepsilon\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: epsilon,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: validation_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_batch_size,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_steps_per_epoch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_steps_per_epoch,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: validation_steps,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_steps,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33muse_xla\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: use_xla,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33muse_amp\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: use_amp,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mmax_seq_length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: max_seq_length,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mfreeze_bert_layer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: freeze_bert_layer,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_sagemaker_debugger\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_sagemaker_debugger,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_checkpointing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_checkpointing,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33menable_tensorboard\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: enable_tensorboard,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_validation,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_test,\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mrun_sample_predictions\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: run_sample_predictions},\r\n",
      "        input_mode=input_mode,\r\n",
      "        metric_definitions=metrics_definitions,\r\n",
      "\u001b[37m#        max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "\r\n",
      "    training_step = TrainingStep(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mTrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        estimator=estimator,\r\n",
      "        inputs={\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-validation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: TrainingInput(\r\n",
      "                s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\r\n",
      "                    \u001b[33m'\u001b[39;49;00m\u001b[33mbert-test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "                ].S3Output.S3Uri,\r\n",
      "                content_type=\u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            )        \r\n",
      "        }\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m# EVALUATION STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "        \r\n",
      "    evaluation_processor = SKLearnProcessor(framework_version=\u001b[33m'\u001b[39;49;00m\u001b[33m0.23-1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                                            role=role,\r\n",
      "                                            instance_type=processing_instance_type,\r\n",
      "                                            instance_count=processing_instance_count,\r\n",
      "                                            env={\u001b[33m'\u001b[39;49;00m\u001b[33mAWS_DEFAULT_REGION\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: region},\r\n",
      "                                            max_runtime_in_seconds=\u001b[34m7200\u001b[39;49;00m)    \r\n",
      "    \r\n",
      "    evaluation_report = PropertyFile(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mEvaluationReport\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mmetrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        path=\u001b[33m'\u001b[39;49;00m\u001b[33mevaluation.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \r\n",
      "    evaluation_step = ProcessingStep(\r\n",
      "        name=\u001b[33m'\u001b[39;49;00m\u001b[33mEvaluateModel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "        processor=evaluation_processor,\r\n",
      "        code=os.path.join(BASE_DIR, \u001b[33m\"\u001b[39;49;00m\u001b[33mevaluate_model_metrics.py\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\r\n",
      "        inputs=[\r\n",
      "            ProcessingInput(\r\n",
      "                source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "                destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            ),\r\n",
      "            ProcessingInput(\r\n",
      "                source=input_data,\r\n",
      "                destination=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "            )\r\n",
      "        ],\r\n",
      "        outputs=[\r\n",
      "            ProcessingOutput(output_name=\u001b[33m'\u001b[39;49;00m\u001b[33mmetrics\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \r\n",
      "                             s3_upload_mode=\u001b[33m'\u001b[39;49;00m\u001b[33mEndOfJob\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                             source=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/metrics/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\r\n",
      "        ],\r\n",
      "        job_arguments=[\r\n",
      "                       \u001b[33m'\u001b[39;49;00m\u001b[33m--max-seq-length\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mstr\u001b[39;49;00m(max_seq_length.default_value),\r\n",
      "                      ],\r\n",
      "        property_files=[evaluation_report],  \u001b[37m# these cause deserialization issues\u001b[39;49;00m\r\n",
      "    )    \r\n",
      "    \r\n",
      "    model_metrics = ModelMetrics(\r\n",
      "        model_statistics=MetricsSource(\r\n",
      "            s3_uri=\u001b[33m\"\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(\r\n",
      "                evaluation_step.arguments[\u001b[33m\"\u001b[39;49;00m\u001b[33mProcessingOutputConfig\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mOutputs\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mS3Output\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m][\u001b[33m\"\u001b[39;49;00m\u001b[33mS3Uri\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "            ),\r\n",
      "            content_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        )\r\n",
      "    )    \r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################    \u001b[39;49;00m\r\n",
      "    \u001b[37m## REGISTER TRAINED MODEL STEP \u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    inference_image_uri = sagemaker.image_uris.retrieve(\r\n",
      "        framework=\u001b[33m\"\u001b[39;49;00m\u001b[33mtensorflow\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        region=region,\r\n",
      "        version=\u001b[33m\"\u001b[39;49;00m\u001b[33m2.3.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        py_version=\u001b[33m\"\u001b[39;49;00m\u001b[33mpy37\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        instance_type=deploy_instance_type,\r\n",
      "        image_scope=\u001b[33m\"\u001b[39;49;00m\u001b[33minference\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(inference_image_uri)\r\n",
      "\r\n",
      "    register_step = RegisterModel(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mRegisterModel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        estimator=estimator,\r\n",
      "        image_uri=inference_image_uri, \u001b[37m# we have to specify, by default it's using training image\u001b[39;49;00m\r\n",
      "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "        content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\r\n",
      "        response_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\r\n",
      "        inference_instances=[deploy_instance_type], \u001b[37m# The JSON spec must be within these instance types or we will see \"Instance Type Not Allowed\" Exception \u001b[39;49;00m\r\n",
      "        transform_instances=[deploy_instance_type],\r\n",
      "        model_package_group_name=model_package_group_name,\r\n",
      "        approval_status=model_approval_status,\r\n",
      "    )\r\n",
      "        \r\n",
      "      \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CREATE MODEL FOR DEPLOYMENT STEP\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    model = Model(\r\n",
      "        image_uri=inference_image_uri,\r\n",
      "        model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\r\n",
      "        sagemaker_session=sess,\r\n",
      "        role=role,\r\n",
      "    )\r\n",
      "\r\n",
      "    create_inputs = CreateModelInput(\r\n",
      "        instance_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mml.m5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "\r\n",
      "    create_step = CreateModelStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mCreateModel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        model=model,\r\n",
      "        inputs=create_inputs,\r\n",
      "    )\r\n",
      "    \r\n",
      "\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CONDITION STEP:  EVALUATE THE MODEL\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\r\n",
      "        left=JsonGet(\r\n",
      "            step=evaluation_step,\r\n",
      "            property_file=evaluation_report,\r\n",
      "            json_path=\u001b[33m\"\u001b[39;49;00m\u001b[33mmetrics.accuracy.value\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        ),\r\n",
      "        right=\u001b[34m0.01\u001b[39;49;00m \u001b[37m# accuracy \u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    minimum_accuracy_condition_step = ConditionStep(\r\n",
      "        name=\u001b[33m\"\u001b[39;49;00m\u001b[33mAccuracyCondition\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        conditions=[minimum_accuracy_condition],\r\n",
      "        if_steps=[register_step, create_step], \u001b[37m# success, continue with model registration\u001b[39;49;00m\r\n",
      "        else_steps=[], \u001b[37m# fail, end the pipeline\u001b[39;49;00m\r\n",
      "    )\r\n",
      "\r\n",
      "    \r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \u001b[37m## CREATE PIPELINE\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    pipeline = Pipeline(\r\n",
      "        name=pipeline_name,\r\n",
      "        parameters=[\r\n",
      "            input_data,\r\n",
      "            processing_instance_count,\r\n",
      "            processing_instance_type,\r\n",
      "            max_seq_length,\r\n",
      "            balance_dataset,\r\n",
      "            train_split_percentage,\r\n",
      "            validation_split_percentage,\r\n",
      "            test_split_percentage,\r\n",
      "            feature_store_offline_prefix,\r\n",
      "            feature_group_name,\r\n",
      "            train_instance_type,\r\n",
      "            train_instance_count,\r\n",
      "            model_approval_status,\r\n",
      "            deploy_instance_type,\r\n",
      "            deploy_instance_count\r\n",
      "        ],\r\n",
      "    steps=[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step], \u001b[37m# register_step, create_step],\u001b[39;49;00m\r\n",
      "        sagemaker_session=sess\r\n",
      "    )\r\n",
      "    \r\n",
      "    \r\n",
      "    \u001b[37m#########################    \u001b[39;49;00m\r\n",
      "    \u001b[37m## RETURN PIPELINE\u001b[39;49;00m\r\n",
      "    \u001b[37m#########################\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[34mreturn\u001b[39;49;00m pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize $sagemaker_mlops_build_code/pipelines/dsoaws/pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wait for Pipeline Execution to Start\n",
    "Now that we have committed code, our pipeline will start.  Let's wait for the pipeline to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing executions for our pipeline...\n",
      "Please wait...\n",
      "Listing executions for our pipeline...\n",
      "Please wait...\n",
      "Listing executions for our pipeline...\n",
      "Please wait...\n",
      "Listing executions for our pipeline...\n",
      "[{'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:835319576252:pipeline/dsoaws-1609835656-p-ef3uutdiztnk/execution/x6eflnsfnpps',\n",
      "  'PipelineExecutionDisplayName': 'execution-1609836085954',\n",
      "  'PipelineExecutionStatus': 'Executing',\n",
      "  'StartTime': datetime.datetime(2021, 1, 5, 8, 41, 25, 795000, tzinfo=tzlocal())}]\n",
      "CPU times: user 53.2 ms, sys: 0 ns, total: 53.2 ms\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print('Listing executions for our pipeline...')\n",
    "        list_executions_response = sm.list_pipeline_executions(PipelineName=sagemaker_project_name_and_id)['PipelineExecutionSummaries']\n",
    "        break;\n",
    "    except Exception as e:\n",
    "        print('Please wait...')\n",
    "        time.sleep(30)   \n",
    "    #    print(e)\n",
    "    \n",
    "pprint(list_executions_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "balance_dataset                                                 -> True\n",
      "experiment_name                                                 -> 'Amazon-Customer-Reviews-BERT-Experiment-160964927\n",
      "feature_group_name                                              -> 'reviews-feature-group-1609649274'\n",
      "feature_store_offline_prefix                                    -> 'reviews-feature-store-1609649274'\n",
      "ingest_create_athena_db_passed                                  -> True\n",
      "ingest_create_athena_table_tsv_passed                           -> True\n",
      "max_seq_length                                                  -> 64\n",
      "processed_test_data_s3_uri                                      -> 's3://sagemaker-us-east-1-835319576252/sagemaker-s\n",
      "processed_train_data_s3_uri                                     -> 's3://sagemaker-us-east-1-835319576252/sagemaker-s\n",
      "processed_validation_data_s3_uri                                -> 's3://sagemaker-us-east-1-835319576252/sagemaker-s\n",
      "raw_input_data_s3_uri                                           -> 's3://sagemaker-us-east-1-835319576252/amazon-revi\n",
      "s3_private_path_tsv                                             -> 's3://sagemaker-us-east-1-835319576252/amazon-revi\n",
      "s3_public_path_tsv                                              -> 's3://amazon-reviews-pds/tsv'\n",
      "sagemaker_mlops_build_code                                      -> '/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3u\n",
      "sagemaker_mlops_deploy_code                                     -> '/home/ec2-user/SageMaker/dsoaws-1609835656-p-ef3u\n",
      "sagemaker_pipeline_product_id                                   -> 'prod-j3ufw6hl7utxm'\n",
      "sagemaker_pipeline_product_provisioning_artifact_id             -> 'pa-oacphmo7m2bji'\n",
      "sagemaker_project_arn                                           -> 'arn:aws:sagemaker:us-east-1:835319576252:project/\n",
      "sagemaker_project_id                                            -> 'p-ef3uutdiztnk'\n",
      "sagemaker_project_name                                          -> 'dsoaws-1609835656'\n",
      "sagemaker_project_name_and_id                                   -> 'dsoaws-1609835656-p-ef3uutdiztnk'\n",
      "setup_dependencies_passed                                       -> True\n",
      "setup_iam_roles_passed                                          -> True\n",
      "setup_instance_check_passed                                     -> True\n",
      "setup_s3_bucket_passed                                          -> True\n",
      "test_split_percentage                                           -> 0.05\n",
      "train_split_percentage                                          -> 0.9\n",
      "training_job_debugger_artifacts_path                            -> 's3://sagemaker-us-east-1-835319576252/tensorflow-\n",
      "training_job_name                                               -> 'tensorflow-training-2021-01-03-05-49-48-016'\n",
      "trial_name                                                      -> 'trial-1609649274'\n",
      "validation_split_percentage                                     -> 0.05\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
