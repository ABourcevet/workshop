{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Jobs, Model Registration, Continuous Deployment, and Lineage Tracking with Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The SageMaker Workflow service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call.\n",
    "\n",
    "And the SageMaker Lineage service makes it easy to track all the artifacts created in a SageMaker Machine Learning Pipeline from start to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelines support the following:\n",
    "\n",
    "* Pipelines - A Directed Acyclic Graph of steps and conditions to orchestrate SageMaker jobs and resource creation.\n",
    "* Processing Job steps - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* Training Job steps - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* Conditional step execution - Provides conditional execution of branches in a pipeline.\n",
    "* Registering Models - Creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* Parametrized Pipeline executions - Allows pipeline executions to vary by supplied parameters.\n",
    "* Transform Job steps - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from your dataset, get inferences from large datasets, and run inference when you don't need a persistent endpoint.\n",
    "\n",
    "## SageMaker Model Registry\n",
    "\n",
    "Amazon SageMaker Model Registry supports the following:\n",
    "\n",
    "* Catalog models after the training step - data scientists run tens to thousands of experiments and may select a small set of models as candidates for production.\n",
    "* Manage model versions - data scientists can register new models which will be automatically versioned in the model registry.\n",
    "* Compare models - data scientists can run model evaluation steps in Tioga pipeline and generate model metrics (e.g. accuracy metrics and bias metrics) which are recorded in the Model Registry and can be used to compare model versions.\n",
    "* Approve models - data scientists can mark model versions as “approved” or “rejected”. Alternately, the Tioga pipeline can also automate the model approvals. If there is a deployment pipeline associated with a Model and a live endpoint, then the model version is propagated in production. Currently SageMaker supports a Blue/ Green update, but as part of Yosemite, we are adding support for Canary and Rolling deployments also.\n",
    "* Deploy models in different AWS accounts - models in the Model Registry support resource sharing across accounts which enables models built in data scientist accounts to be deployed in different pre-production and production accounts.\n",
    "\n",
    "## SageMaker Lineage\n",
    "\n",
    "Amazon SageMaker Lineage supports the following:\n",
    "\n",
    "* Automatically tracks all the artifacts created in a machine learning workflow from start to finish.  Modeled as a directed graph like structure.\n",
    "* Explore the lineage artifacts with easy to use SDK methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "### SageMaker Workflows\n",
    "\n",
    "* Define a set of Workflow Parameters that can be used to parametrize a Workflow Pipeline\n",
    "* Define a Processing step that performs cleaning and feature engineering, splitting the input data into train and test data sets\n",
    "* Define a Training step that trains a model on the pre-processed train data set\n",
    "* Define a Processing step that evaluates the trained model's performance on the test data set\n",
    "* Define a Register Model step that creates a model package from the estimator and model artifacts used in training\n",
    "* Define a Conditional step that measures a condition based on output from prior steps and conditionally executes the Register Model step\n",
    "* Define and create a Pipeline in a Workflow DAG, with the defined parameters and steps defined\n",
    "* Start a Pipeline execution and wait for execution to complete\n",
    "* Download from S3 the model evaluation report for examination\n",
    "* Start a second Pipeline execution\n",
    "\n",
    "### SageMaker Model Registry\n",
    "\n",
    "* Create a SageMaker Project based on the Model Package Group name from the pipeline execution defined before\n",
    "* Observe CI/CD code pipeline on subsequent successful executions of the pipeline and the registration of a new Model Package version.\n",
    "\n",
    "### SageMaker Lineage\n",
    "\n",
    "Amazon SageMaker Lineage supports the following:\n",
    "\n",
    "* Provide the inputs and outputs of SageMaker job artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A SageMaker Workflow\n",
    "\n",
    "The pipeline that we create follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and model registration:\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)\n",
    "\n",
    "### Create SageMaker Clients and Session\n",
    "\n",
    "First, we create a new SageMaker Session in the `us-east-2` region. We also acquire the role arn for the session.\n",
    "\n",
    "This role arn should be the execution role arn that you set up in the Prerequisites section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3                              1.16.36\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q sagemaker==2.23.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments==0.1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16093884477192150\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestamp = str(int(time.time() * 10**7))\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Pipeline In `Experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'BERT-pipeline-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: BERT-pipeline-16093884477192150\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "experiment = Experiment.create(\n",
    "                experiment_name=pipeline_name,\n",
    "                description='Amazon Customer Reviews BERT Pipeline Experiment', \n",
    "                sagemaker_boto_client=sm)\n",
    "\n",
    "experiment_name = experiment.experiment_name\n",
    "print('Experiment name: {}'.format(experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `Experiment Config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config_prepare = {\n",
    "#     'ExperimentName': experiment_name,\n",
    "#     'TrialName': trial.trial_name,\n",
    "#     'TrialComponentDisplayName': 'prepare'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config_train = {\n",
    "#     'ExperimentName': experiment_name,\n",
    "#     'TrialName': trial.trial_name,\n",
    "#     'TrialComponentDisplayName': 'train'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config_model_reg = {\n",
    "#     'ExperimentName': experiment_name,\n",
    "#     'TrialName': trial.trial_name,\n",
    "#     'TrialComponentDisplayName': 'model_reg'\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the Raw Inputs S3 Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-231218423789/amazon-reviews-pds/tsv/\n"
     ]
    }
   ],
   "source": [
    "raw_input_data_s3_uri = 's3://{}/amazon-reviews-pds/tsv/'.format(bucket)\n",
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-30 21:10:20 1294879074 amazon_reviews_us_Digital_Ebook_Purchase_v1_01.tsv.gz\n",
      "2020-12-18 17:44:16   18997559 amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "2020-12-18 17:44:18   27442648 amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Processing Job Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_seq_length=64\n",
    "# train_split_percentage=0.90\n",
    "# validation_split_percentage=0.05\n",
    "# test_split_percentage=0.05\n",
    "balance_dataset='True'\n",
    "# processing_instance_count=1\n",
    "# processing_instance_type='ml.c5.2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters to Parametrize Pipeline Execution\n",
    "\n",
    "We define Workflow Parameters by which we can parametrize our Pipeline and vary the values injected and used in Pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - representing a `str` Python type\n",
    "* `ParameterInteger` - representing an `int` Python type\n",
    "* `ParameterFloat` - representing a `float` Python type\n",
    "\n",
    "These parameters support providing a default value, which can be overridden on pipeline execution. The default value specified should be an instance of the type of the parameter.\n",
    "\n",
    "The parameters defined in this workflow below include:\n",
    "\n",
    "* `processing_instance_type` - The `ml.*` instance type of the processing job.\n",
    "* `processing_instance_count` - The instance count of the processing job. For illustrative purposes only: 1 is the only value that makes sense here.\n",
    "* `training_instance_type` - The `ml.*` instance type of the training job.\n",
    "* `model_approval_status` - What approval status to register the trained model with for CI/CD purposes. Defaults to \"PendingManualApproval\". (NOTE: not available in service yet)\n",
    "* `input_data` - The URL location of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    "#    ParameterBoolean\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = ParameterString(\n",
    "    name=\"ExperimentName\",\n",
    "    default_value=experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_percentage = ParameterFloat(\n",
    "    name=\"TrainSplitPercentage\",\n",
    "    default_value=0.90,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_input_data_s3_uri,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\"\n",
    ")\n",
    "\n",
    "max_seq_length = ParameterInteger(\n",
    "    name=\"MaxSeqLength\",\n",
    "    default_value=64,\n",
    ")\n",
    "\n",
    "# balance_dataset = ParameterBoolean(\n",
    "#     name=\"BalanceDataset\",\n",
    "#     default_value=True,\n",
    "# )\n",
    "\n",
    "train_split_percentage = ParameterFloat(\n",
    "    name=\"TrainSplitPercentage\",\n",
    "    default_value=0.90,\n",
    ")\n",
    "\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name=\"ValidationSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name=\"TestSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.c5.9xlarge\"\n",
    ")\n",
    "\n",
    "train_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define Parameters](img/pipeline-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of an `SKLearnProcessor` processor and we use that in our `ProcessingStep`.\n",
    "\n",
    "We also specify the `framework_version` we will use throughout.\n",
    "\n",
    "Note the `processing_instance_type` and `processing_instance_count` parameters that used by the processor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                             role=role,\n",
    "                             instance_type=processing_instance_type,\n",
    "                             instance_count=processing_instance_count,\n",
    "                             max_runtime_in_seconds=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Processing', step_type=<StepTypeEnum.PROCESSING: 'Processing'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name='raw_input',\n",
    "            source=raw_input_data_s3_uri,\n",
    "            destination='/opt/ml/processing/input/data/',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        )\n",
    "]\n",
    "\n",
    "processing_outputs=[\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-train',\n",
    "                         source='/opt/ml/processing/output/bert/train',\n",
    "#                         destination=processed_train_data_s3_uri\n",
    "                        ),\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-validation',\n",
    "                         source='/opt/ml/processing/output/bert/validation',\n",
    "#                         destination=processed_validation_data_s3_uri\n",
    "                        ),\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-test',\n",
    "                         source='/opt/ml/processing/output/bert/test',\n",
    "#                         destination=processed_test_data_s3_uri\n",
    "                        ),\n",
    "]        \n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Processing', \n",
    "    processor=processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    job_arguments=['--train-split-percentage', str(train_split_percentage.default_value), \n",
    "                   # using default_value because SM Processing Job doesn't resolve Parameter to actual value\n",
    "                   '--validation-split-percentage', str(validation_split_percentage.default_value),\n",
    "                   '--test-split-percentage', str(test_split_percentage.default_value),\n",
    "                   '--max-seq-length', str(max_seq_length.default_value),\n",
    "                   '--balance-dataset', str(balance_dataset)],\n",
    "    code='preprocess-scikit-text-to-bert.py'\n",
    "#    container_entrypoint=['python3', '/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py'],\n",
    ")        \n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Processing Step for Feature Engineering](img/pipeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "Note the `input_data` parameters passed into `ProcessingStep` as the input data of the step itself. This input data will be used by the processor instance when it is run.\n",
    "\n",
    "Also, take note the `\"train_data\"` and `\"test_data\"` named channels specified in the output configuration for the processing job. Such step `Properties` can be used in subsequent steps and will resolve to their runtime values at execution. In particular, we'll call out this usage when we define our training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize src/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Hyper-Parameters\n",
    "Note that `max_seq_length` is re-used from the processing hyper-parameters above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "train_steps_per_epoch=50\n",
    "validation_steps=50\n",
    "test_steps=50\n",
    "#train_instance_count=1\n",
    "#train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "freeze_bert_layer=False\n",
    "enable_sagemaker_debugger=False\n",
    "enable_checkpointing=False\n",
    "enable_tensorboard=False\n",
    "input_mode='File'\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True\n",
    "deploy_instance_count=1\n",
    "deploy_instance_type='ml.m5.4xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Metrics To Track Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Training Step to Train a Model\n",
    "\n",
    "We configure an Estimator and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later.\n",
    "\n",
    "We also specify the model path where the models from training will be saved.\n",
    "\n",
    "Note the `training_instance_type` parameter passed may be also used and passed into other places in the pipeline. In this case, the `training_instance_type` is passed into the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.utils import name_from_base\n",
    "# training_job_name = name_from_base('bert-train')\n",
    "# print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 's3://{}/{}/model'.format(default_bucket,training_job_name)\n",
    "# print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1.0-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=train_instance_type,\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(image_uri)\n",
    "\n",
    "estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "#                       output_path=model_path,\n",
    "#                       base_job_name=training_job_name,\n",
    "                       instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       instance_type=train_instance_type,\n",
    "                       volume_size=train_volume_size,                       \n",
    "                       image_uri=image_uri,\n",
    "#                       py_version='py3',\n",
    "#                       framework_version='2.1.0',\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "                                        'enable_checkpointing': enable_checkpointing,\n",
    "                                        'enable_tensorboard': enable_tensorboard,                                        \n",
    "                                        'run_validation': run_validation,\n",
    "                                        'run_test': run_test,\n",
    "                                        'run_sample_predictions': run_sample_predictions},\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions,\n",
    "#                       max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the estimator instance to construct a `TrainingStep` as well as the `Properties` of the prior `ProcessingStep` used as input in the `TrainingStep` inputs and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to an estimator's `fit` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3Uri` of the `\"train_data\"` output channel to the `TrainingStep`. We will also use the other `\"test_data\"` output channel for model evaluation in the pipeline. The `properties` attribute of a Workflow step match the object model of the corresponding response of a describe call. These properties can be referenced as placeholder values and are resolved, or filled in, at runtime. For example, the `ProcessingStep` `properties` attribute matches the object model of the [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', step_type=<StepTypeEnum.TRAINING: 'Training'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name=\"Train\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )        \n",
    "    },\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Training Step to Train a Model](img/pipeline-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, we develop an evaluation script that will be specified in a Processing step that will perform the model evaluation.\n",
    "\n",
    "The evaluation script `evaluation.py` takes the trained model and the test dataset as input, and produces a JSON file containing classification evaluation metrics, including precision, recall, and F1 score for each label, and accuracy and ROC AUC for the model.\n",
    "\n",
    "After pipeline execution, we will examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script:\n",
    "\n",
    "* loads in the model\n",
    "* reads in the test data\n",
    "* issues a bunch o' predictions against the test data\n",
    "* builds a classification report, including accuracy and roc\n",
    "* saves the evaluation report to the evaluation directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an instance of a `ScriptProcessor` processor and we use that in our `ProcessingStep`.\n",
    "\n",
    "Note the `processing_instance_type` parameter passed into the processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "# script_eval = ScriptProcessor(\n",
    "#     image_uri=image_uri,\n",
    "#     command=[\"python3\"],\n",
    "#     instance_type=processing_instance_type,\n",
    "#     instance_count=1,\n",
    "#     base_job_name=\"script-abalone-eval\",\n",
    "#     sagemaker_session=sess,\n",
    "#     role=role,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties as well as the `S3Uri` of the `\"test_data\"` output channel of the first `ProcessingStep`, `step_process`.\n",
    "\n",
    "The `TrainingStep` and `ProcessingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) and  [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "# # NOTE:\n",
    "# # property files cause deserialization failure on listing pipeline executions\n",
    "# # therefore jsonget and robust conditions won't work\n",
    "# evaluation_report = PropertyFile(\n",
    "#     name=\"EvaluationReport\",\n",
    "#     output_name=\"evaluation\",\n",
    "#     path=\"evaluation.json\"\n",
    "# )\n",
    "# step_eval = ProcessingStep(\n",
    "#     name=\"AbaloneEval\",\n",
    "#     processor=script_eval,\n",
    "#     inputs=[\n",
    "#         ProcessingInput(\n",
    "#             source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#             destination=\"/opt/ml/processing/model\"\n",
    "#         ),\n",
    "#         ProcessingInput(\n",
    "#             source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#                 \"test\"\n",
    "#             ].S3Output.S3Uri,\n",
    "#             destination=\"/opt/ml/processing/test\"\n",
    "#         )\n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "#     ],\n",
    "#     code=\"evaluation.py\",\n",
    "#     # property_files=[evaluation_report],  # these cause deserialization issues\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Model Evaluation Step to Evaluate the Trained Model](img/pipeline-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Register Model Step to Create a Model Package\n",
    "\n",
    "We use the estimator instance that was used for the training step to construct an instance of `RegisterModel`. The result of executing `RegisterModel` in a pipeline is a Model Package. A Model Package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A Model Package Group is a collection of Model Packages. You can create a Model Package Group for a specific ML business problem, and you can keep adding versions/model packages into it. Typically, we expect customers to create a ModelPackageGroup for a SageMaker Workflow Pipeline so that they can keep adding versions/model packages to the group for every Workflow Pipeline run.\n",
    "\n",
    "The construction of `RegisterModel` is very similar to an estimator instance's `register` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object.\n",
    "\n",
    "Of note, we provided a specific model package group name which we will use in the Model Registry and CI/CD work later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-Reviews-1609388448\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"BERT-Reviews-{timestamp}\"\n",
    "\n",
    "# # NOTE: in the future, the model package group will be created automatically if it doesn't exist\n",
    "sm.create_model_package_group(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelPackageGroupDescription=\"BERT-Reviews\",\n",
    ")\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary Python version: py3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1.0-cpu\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    image_scope=\"inference\"\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.workflow.properties.Properties object at 0x7fef9f5a6210>\n"
     ]
    }
   ],
   "source": [
    "print(training_step.properties.ModelArtifacts.S3ModelArtifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# NOTE: model_approval_status is not available as arg in service dsl currently\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=estimator,\n",
    "    image_uri=inference_image_uri, # we have to specify, by default it's using training image\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.4xlarge\"],\n",
    "    transform_instances=[\"ml.c5.18xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "#    model_approval_status=model_approval_status\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Register Model\n",
    "\n",
    "Finally, we'd like to only register this model if the accuracy of the model, as determined by our evaluation step `step_eval`, exceeded some value. A `ConditionStep` allows for pipelines to support conditional execution in the pipeline DAG based on conditions of step properties. \n",
    "\n",
    "Below, we:\n",
    "\n",
    "* define a `ConditionGreaterThan` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* use the condition in the list of conditions in a `ConditionStep`\n",
    "* pass the `RegisterModel` step collection into the `if_steps` of the `ConditionStep`\n",
    "* use the `FailStep` in the `else_steps` of the `ConditionStep` to fail the pipeline if the accuracy condition was not met\n",
    "\n",
    "NOTE: there are a few things that are planned to be implemented in the Workflow service that are currently unavailable to us:\n",
    "\n",
    "* JsonGet - a function to allow getting json files from S3 and using their values in conditions\n",
    "* FailStep - a step that terminates the pipeline in failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.conditions import (\n",
    "#     ConditionEquals,\n",
    "#     ConditionLessThanOrEqualTo,\n",
    "# )\n",
    "# from sagemaker.workflow.condition_step import (\n",
    "#     ConditionStep,\n",
    "#     JsonGet,\n",
    "# )\n",
    "# from sagemaker.workflow.steps import FailStep\n",
    "\n",
    "\n",
    "# # NOTE:\n",
    "# # This is not an ideal condition, but processing jobs have no dynamic properties, as-is\n",
    "# cond_equals = ConditionEquals(\n",
    "#     left=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "#     right=step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"],\n",
    "# )\n",
    "\n",
    "# # NOTE:\n",
    "# # Ideally, we would use JsonGet to get the mean squared error from the evaluation report\n",
    "# # This is what a non-trivial condition looks like for a processing job\n",
    "# #\n",
    "# # NOTE:\n",
    "# # jsonpaths only support single characters in the service\n",
    "# cond_lte = ConditionLessThanOrEqualTo(\n",
    "#     left=JsonGet(\n",
    "#         step=step_eval,\n",
    "#         property_file=evaluation_report,\n",
    "#         json_path=\"m\"\n",
    "#     ),\n",
    "#     right=\"5.0\"\n",
    "# )\n",
    "\n",
    "# # NOTE: \n",
    "# # we forego the cond_lte and use the cond_equals as jsonget/propertyfiles don't work quite\n",
    "# # right in service/can't be listed\n",
    "# #\n",
    "# # NOTE:\n",
    "# # FailStep not available in the service yet\n",
    "# step_cond = ConditionStep(\n",
    "#     name=\"AbaloneMSECond\",\n",
    "#     conditions=[cond_equals],  # cond_lte],\n",
    "#     if_steps=[step_register],\n",
    "#     else_steps=[],  # [FailStep()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Condition Step to Check Accuracy and Conditionally Register Model](img/pipeline-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "Let's tie it all up into a workflow pipeline so we can execute it, and even schedule it.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair so we tack on the timestamp to the name.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline need not be in the order of execution. The SageMaker Workflow service will resolve the _data dependency_ DAG as steps the execution complete.\n",
    "* Steps must be unique to either pipeline step list or a single condition step if/else list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Pipeline of Parameters, Steps, and Conditions](img/pipeline-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# NOTE:\n",
    "# condition steps have issues in service so we go straight to step_register\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        max_seq_length,\n",
    "        train_split_percentage,\n",
    "        validation_split_percentage,\n",
    "        test_split_percentage,\n",
    "        train_instance_type,\n",
    "        train_instance_count,\n",
    "        model_approval_status\n",
    "    ],\n",
    "    steps=[processing_step, training_step, register_step],  # step_cond],\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the Json of the pipeline definition that meets the SageMaker Workflow Pipeline DSL specification.\n",
    "\n",
    "By examining the definition, we're also confirming that the pipeline was well-defined, and that the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Metadata': {},\n",
      " 'Parameters': [{'DefaultValue': 's3://sagemaker-us-east-1-231218423789/amazon-reviews-pds/tsv/',\n",
      "                 'Name': 'InputData',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 1,\n",
      "                 'Name': 'ProcessingInstanceCount',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'ml.c5.2xlarge',\n",
      "                 'Name': 'ProcessingInstanceType',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 64, 'Name': 'MaxSeqLength', 'Type': 'Integer'},\n",
      "                {'DefaultValue': 0.9,\n",
      "                 'Name': 'TrainSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 0.05,\n",
      "                 'Name': 'ValidationSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 0.05,\n",
      "                 'Name': 'TestSplitPercentage',\n",
      "                 'Type': 'Float'},\n",
      "                {'DefaultValue': 'ml.c5.9xlarge',\n",
      "                 'Name': 'TrainingInstanceType',\n",
      "                 'Type': 'String'},\n",
      "                {'DefaultValue': 1,\n",
      "                 'Name': 'TrainingInstanceCount',\n",
      "                 'Type': 'Integer'},\n",
      "                {'DefaultValue': 'PendingManualApproval',\n",
      "                 'Name': 'ModelApprovalStatus',\n",
      "                 'Type': 'String'}],\n",
      " 'Steps': [{'Arguments': {'AppSpecification': {'ContainerArguments': ['--train-split-percentage',\n",
      "                                                                      {'Get': 'Parameters.TrainSplitPercentage'},\n",
      "                                                                      '--validation-split-percentage',\n",
      "                                                                      {'Get': 'Parameters.ValidationSplitPercentage'},\n",
      "                                                                      '--test-split-percentage',\n",
      "                                                                      {'Get': 'Parameters.TestSplitPercentage'},\n",
      "                                                                      '--max-seq-length',\n",
      "                                                                      {'Get': 'Parameters.MaxSeqLength'},\n",
      "                                                                      '--balance-dataset',\n",
      "                                                                      'True'],\n",
      "                                               'ContainerEntrypoint': ['python3',\n",
      "                                                                       '/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py'],\n",
      "                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3'},\n",
      "                          'ProcessingInputs': [{'AppManaged': False,\n",
      "                                                'InputName': 'raw_input',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-231218423789/amazon-reviews-pds/tsv/'}},\n",
      "                                               {'AppManaged': False,\n",
      "                                                'InputName': 'code',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-231218423789/sagemaker-scikit-learn-2020-12-31-04-20-51-590/input/code/preprocess-scikit-text-to-bert.py'}}],\n",
      "                          'ProcessingOutputConfig': {'Outputs': [{'AppManaged': False,\n",
      "                                                                  'OutputName': 'bert-train',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/train',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-231218423789/sagemaker-scikit-learn-2020-12-31-04-20-51-590/output/bert-train'}},\n",
      "                                                                 {'AppManaged': False,\n",
      "                                                                  'OutputName': 'bert-validation',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/validation',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-231218423789/sagemaker-scikit-learn-2020-12-31-04-20-51-590/output/bert-validation'}},\n",
      "                                                                 {'AppManaged': False,\n",
      "                                                                  'OutputName': 'bert-test',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/test',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-231218423789/sagemaker-scikit-learn-2020-12-31-04-20-51-590/output/bert-test'}}]},\n",
      "                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
      "                                                                    'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
      "                                                                    'VolumeSizeInGB': 30}},\n",
      "                          'RoleArn': 'arn:aws:iam::231218423789:role/TeamRole',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 7200}},\n",
      "            'Name': 'Processing',\n",
      "            'Type': 'Processing'},\n",
      "           {'Arguments': {'AlgorithmSpecification': {'MetricDefinitions': [{'Name': 'train:loss',\n",
      "                                                                            'Regex': 'loss: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'train:accuracy',\n",
      "                                                                            'Regex': 'accuracy: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'validation:loss',\n",
      "                                                                            'Regex': 'val_loss: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'validation:accuracy',\n",
      "                                                                            'Regex': 'val_accuracy: '\n",
      "                                                                                     '([0-9\\\\.]+)'}],\n",
      "                                                     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1.0-cpu-py3',\n",
      "                                                     'TrainingInputMode': 'File'},\n",
      "                          'DebugHookConfig': {'CollectionConfigurations': [],\n",
      "                                              'S3OutputPath': 's3://sagemaker-us-east-1-231218423789/'},\n",
      "                          'HyperParameters': {'enable_checkpointing': 'false',\n",
      "                                              'enable_sagemaker_debugger': 'false',\n",
      "                                              'enable_tensorboard': 'false',\n",
      "                                              'epochs': '1',\n",
      "                                              'epsilon': '1e-08',\n",
      "                                              'freeze_bert_layer': 'false',\n",
      "                                              'learning_rate': '1e-05',\n",
      "                                              'max_seq_length': '64',\n",
      "                                              'model_dir': '\"s3://sagemaker-us-east-1-231218423789/tensorflow-training-2020-12-31-04-20-51-801/model\"',\n",
      "                                              'run_sample_predictions': 'true',\n",
      "                                              'run_test': 'true',\n",
      "                                              'run_validation': 'true',\n",
      "                                              'sagemaker_container_log_level': '20',\n",
      "                                              'sagemaker_job_name': '\"tensorflow-training-2020-12-31-04-20-51-801\"',\n",
      "                                              'sagemaker_program': '\"tf_bert_reviews.py\"',\n",
      "                                              'sagemaker_region': '\"us-east-1\"',\n",
      "                                              'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-231218423789/tensorflow-training-2020-12-31-04-20-51-801/source/sourcedir.tar.gz\"',\n",
      "                                              'test_batch_size': '128',\n",
      "                                              'test_steps': '50',\n",
      "                                              'train_batch_size': '128',\n",
      "                                              'train_steps_per_epoch': '50',\n",
      "                                              'use_amp': 'true',\n",
      "                                              'use_xla': 'true',\n",
      "                                              'validation_batch_size': '128',\n",
      "                                              'validation_steps': '50'},\n",
      "                          'InputDataConfig': [{'ChannelName': 'train',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-train'].S3Output.S3Uri\"}}}},\n",
      "                                              {'ChannelName': 'validation',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-validation'].S3Output.S3Uri\"}}}},\n",
      "                                              {'ChannelName': 'test',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-test'].S3Output.S3Uri\"}}}}],\n",
      "                          'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-231218423789/'},\n",
      "                          'ResourceConfig': {'InstanceCount': {'Get': 'Parameters.TrainingInstanceCount'},\n",
      "                                             'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
      "                                             'VolumeSizeInGB': 1024},\n",
      "                          'RoleArn': 'arn:aws:iam::231218423789:role/TeamRole',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},\n",
      "            'Name': 'Train',\n",
      "            'Type': 'Training'},\n",
      "           {'Arguments': {'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1.0-cpu',\n",
      "                                                                     'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}],\n",
      "                                                     'SupportedContentTypes': ['text/csv'],\n",
      "                                                     'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.4xlarge'],\n",
      "                                                     'SupportedResponseMIMETypes': ['text/csv'],\n",
      "                                                     'SupportedTransformInstanceTypes': ['ml.c5.18xlarge']},\n",
      "                          'ModelApprovalStatus': 'PendingManualApproval',\n",
      "                          'ModelPackageGroupName': 'BERT-Reviews-1609388448'},\n",
      "            'Name': 'RegisterModel',\n",
      "            'Type': 'RegisterModel'}],\n",
      " 'Version': '2020-12-01'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "pprint(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-pipeline-16093884477192150\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the `WARNING` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments not yet supported by boto3 API\n",
    "# response = pipeline.create(role_arn=role,\n",
    "#                            experiment_name=experiment_name)\n",
    "\n",
    "response = pipeline.create(role_arn=role)\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start the pipeline, accepting all the default parameters.\n",
    "\n",
    "Values can also be passed into these pipeline parameters on starting of the pipeline, and will be covered later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "# TODO:  ADD THESE - SAME AS 2nd RUN BELOW\n",
    ")\n",
    "\n",
    "\n",
    "print(execution.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Now we describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_run = execution.describe()\n",
    "print(execution_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Execution Run as Trial to Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_run_name = execution_run['PipelineExecutionDisplayName']\n",
    "print(execution_run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `Trial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "trial = Trial.create(trial_name=execution_run_name,\n",
    "                     experiment_name=experiment_name,\n",
    "                     sagemaker_boto_client=sm)\n",
    "\n",
    "trial_name = trial.trial_name\n",
    "print('Trial name: {}'.format(trial_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Execution Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Artifacts Generated By The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_name=None\n",
    "training_job_name=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "for execution_step in reversed(execution.list_steps()):\n",
    "    print(execution_step)\n",
    "    # We are doing this because there appears to be a bug of this LineageTableVisualizer handling the Processing Step\n",
    "    if execution_step['StepName'] == 'Processing':\n",
    "        processing_job_name=execution_step['Metadata']['ProcessingJob']['Arn'].split('/')[-1]\n",
    "        print(processing_job_name)\n",
    "        display(viz.show(processing_job_name=processing_job_name))\n",
    "    elif execution_step['StepName'] == 'Train':\n",
    "        training_job_name=execution_step['Metadata']['TrainingJob']['Arn'].split('/')[-1]\n",
    "        print(training_job_name)\n",
    "        display(viz.show(training_job_name=training_job_name))\n",
    "    else:\n",
    "        display(viz.show(pipeline_execution_step=execution_step))\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Trial Compontents To Experiment Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processing_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_tc = '{}-aws-processing-job'.format(processing_job_name)\n",
    "print(processing_job_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.associate_trial_component(\n",
    "    # -aws-processing-job is the default name assigned by ProcessingJob\n",
    "    TrialComponentName=processing_job_tc,\n",
    "    TrialName=trial_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_tc = '{}-aws-training-job'.format(training_job_name)\n",
    "print(training_job_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.associate_trial_component(\n",
    "    # -aws-training-job is the default name assigned by TrainingJob\n",
    "    TrialComponentName=training_job_tc,\n",
    "    TrialName=trial_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Additional Parameters within Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments import tracker\n",
    "\n",
    "processing_job_tracker = tracker.Tracker.load(trial_component_name=processing_job_tc)\n",
    "print(processing_job_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_job_tracker.log_parameters({\n",
    "    \"balance_dataset\": str(balance_dataset), \n",
    "})\n",
    "\n",
    "# must save after logging\n",
    "processing_job_tracker.trial_component.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the evalution\n",
    "\n",
    "We can examine the resulting model evaluation after the pipeline completes.\n",
    "\n",
    "We download the resulting `evaluation.json` file from S3 and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "#     step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------ Run another Pipeline Execution with Different Parameters ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# THIS IS RUNNING A 2nd PIPELINE\n",
    "###\n",
    "execution_parametrized = pipeline.start(\n",
    "    parameters=dict(\n",
    "#         InputData='',\n",
    "#         ProcessingInstanceCount=1,\n",
    "#         ProcessingInstanceType='',\n",
    "#         MaxSeqLength=64,\n",
    "#         TrainSplitPercentage=0.9,\n",
    "#         ValidationSplitPercentage=0.05,\n",
    "#         TestSplitPercentage=0.05,\n",
    "#         TrainingInstanceType='',\n",
    "#         TrainingInstanceCount=1,\n",
    "        ModelApprovalStatus='Approved'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", 500)\n",
    "#pd.set_option(\"max_rows\", 100)\n",
    "\n",
    "experiment_analytics = ExperimentAnalytics(\n",
    "    experiment_name=experiment_name,\n",
    ")\n",
    "\n",
    "experiment_analytics_df = experiment_analytics.dataframe()\n",
    "experiment_analytics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List All Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.analytics import ArtifactAnalytics\n",
    "# analytics = ArtifactAnalytics()\n",
    "# artifact_analytics_df = analytics.dataframe()\n",
    "# artifact_analytics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Registry and CI/CD\n",
    "\n",
    "\n",
    "The pipeline that was executed created a Model Package version within the specified Model Package Group. Of particular note, the registration of the model/creation of the Model Package was done so with approval status as `PendingManualApproval`.\n",
    "\n",
    "Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    if execution_step[\"StepName\"] == \"RegisterModel\":\n",
    "        model_package_arn = execution_step[\"Metadata\"][\"RegisterModel\"][\"Arn\"]\n",
    "        break\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Model Package Approval Status\n",
    "\n",
    "As noted above, the model has been registered with `\"PendingManualApproval\"` status. As part of Yosemite, data scientists can register the model with approved/pending manual approval as part of the Tioga workflow. Here we are demonstrating how they can approve the generated model manually. In GA (Nov 2020), we will have UX in SageMaker Studio so that datascients can approve the model, which will inturn trigger the Ci/CD system. For now, here is a way to approve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")\n",
    "\n",
    "print(model_package_update_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model From Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-model-{}'.format(timestamp)\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "primary_container = {\n",
    "    'ModelPackageName': model_package_arn,\n",
    "}\n",
    "create_model_respose = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "print(\"Model arn : {}\".format(create_model_respose[\"ModelArn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'bert-model-epc-{}'.format(timestamp)\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.4xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'bert-model-ep-{}'.format(timestamp)\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait Until the Endpoint is Deployed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "\n",
    "predictor = TensorFlowPredictor(endpoint_name=endpoint_name,\n",
    "                                sagemaker_session=sess,\n",
    "                                model_name='saved_model',\n",
    "                                model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the `star_rating` with Ad Hoc `review_body` Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"This is great!\"]\n",
    "\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
