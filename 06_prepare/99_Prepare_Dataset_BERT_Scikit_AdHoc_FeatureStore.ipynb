{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation with Scikit-Learn In This Notebook\n",
    "\n",
    "\n",
    "**Presentation Deep-Dive on BERT:** \n",
    "* [Slides - https://speakerdeck.com/antje/visualize-bert-attention](https://speakerdeck.com/antje/visualize-bert-attention)\n",
    "* [Video - https://youtu.be/4PQyRJd9d_E](https://youtu.be/4PQyRJd9d_E)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/prepare_dataset_bert.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)\n",
    "s3 = boto3.Session().client(service_name='s3', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::806570384721:role/TeamRole\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Raw Text to BERT Features using Hugging Face and TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "REVIEW_BODY_COLUMN = 'review_body'\n",
    "REVIEW_ID_COLUMN = 'review_id'\n",
    "# DATE_COLUMN = 'date'\n",
    "\n",
    "LABEL_COLUMN = 'star_rating'\n",
    "LABEL_VALUES = [1, 2, 3, 4, 5]\n",
    "\n",
    "label_map = {}\n",
    "for (i, label) in enumerate(LABEL_VALUES):\n",
    "    label_map[label] = i\n",
    "\n",
    "    \n",
    "class InputFeatures(object):\n",
    "  \"\"\"BERT feature vectors.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               input_ids,\n",
    "               input_mask,\n",
    "               segment_ids,\n",
    "               label_id,\n",
    "               review_id,\n",
    "               date):\n",
    "    self.input_ids = input_ids\n",
    "    self.input_mask = input_mask\n",
    "    self.segment_ids = segment_ids\n",
    "    self.label_id = label_id\n",
    "    self.review_id = review_id\n",
    "    self.date = date\n",
    "    \n",
    "    \n",
    "class Input(object):\n",
    "  \"\"\"A single training/test input for sequence classification.\"\"\"\n",
    "\n",
    "  def __init__(self, text, review_id, date, label=None):\n",
    "    \"\"\"Constructs an Input.\n",
    "    Args:\n",
    "      text: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "    self.text = text\n",
    "    self.review_id = review_id\n",
    "    self.date = date\n",
    "    self.label = label\n",
    "    \n",
    "\n",
    "def convert_input(the_input, max_seq_length):\n",
    "    # First, we need to preprocess our data so that it matches the data BERT was trained on:\n",
    "    # 1. Lowercase our text (if we're using a BERT lowercase model)\n",
    "    # 2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
    "    # 3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
    "    # \n",
    "    # Fortunately, the Transformers tokenizer does this for us!\n",
    "\n",
    "    tokens = tokenizer.tokenize(the_input.text)\n",
    "    print('**tokens**\\n{}\\n'.format(tokens))\n",
    "\n",
    "    encode_plus_tokens = tokenizer.encode_plus(the_input.text,\n",
    "                                               pad_to_max_length=True,\n",
    "                                               max_length=max_seq_length,\n",
    "#                                               truncation=True\n",
    "                                              )\n",
    "\n",
    "    # The id from the pre-trained BERT vocabulary that represents the token.  (Padding of 0 will be used if the # of tokens is less than `max_seq_length`)\n",
    "    input_ids = encode_plus_tokens['input_ids']\n",
    "    \n",
    "    # Specifies which tokens BERT should pay attention to (0 or 1).  Padded `input_ids` will have 0 in each of these vector elements.    \n",
    "    input_mask = encode_plus_tokens['attention_mask']\n",
    "\n",
    "    # Segment ids are always 0 for single-sequence tasks such as text classification.  1 is used for two-sequence tasks such as question/answer and next sentence prediction.\n",
    "    segment_ids = [0] * max_seq_length\n",
    "\n",
    "    # Label for each training row (`star_rating` 1 through 5)\n",
    "    label_id = label_map[the_input.label]\n",
    "\n",
    "    features = InputFeatures(\n",
    "        input_ids=input_ids,\n",
    "        input_mask=input_mask,\n",
    "        segment_ids=segment_ids,\n",
    "        label_id=label_id,\n",
    "        review_id=the_input.review_id,\n",
    "        date=the_input.date)\n",
    "\n",
    "    print('**input_ids**\\n{}\\n'.format(features.input_ids))\n",
    "    print('**input_mask**\\n{}\\n'.format(features.input_mask))\n",
    "    print('**segment_ids**\\n{}\\n'.format(features.segment_ids))\n",
    "    print('**label_id**\\n{}\\n'.format(features.label_id))\n",
    "    print('**review_id**\\n{}\\n'.format(features.review_id))\n",
    "    print('**date**\\n{}\\n'.format(features.date))\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# We'll need to transform our data into a format that BERT understands.\n",
    "# - `text` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
    "# - `label` is the star_rating label (1, 2, 3, 4, 5) for our training input data\n",
    "def transform_inputs_to_tfrecord(inputs, max_seq_length):\n",
    "    records = []\n",
    "    for (input_idx, the_input) in enumerate(inputs):\n",
    "        if input_idx % 10000 == 0:\n",
    "            print('Writing input {} of {}\\n'.format(input_idx, len(inputs)))\n",
    "\n",
    "        features = convert_input(the_input, max_seq_length)\n",
    "\n",
    "        all_features = collections.OrderedDict()\n",
    "        all_features['input_ids'] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_ids))\n",
    "        all_features['input_mask'] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.input_mask))\n",
    "        all_features['segment_ids'] = tf.train.Feature(int64_list=tf.train.Int64List(value=features.segment_ids))\n",
    "        all_features['label_ids'] = tf.train.Feature(int64_list=tf.train.Int64List(value=[features.label_id]))\n",
    "\n",
    "#        tf_record = tf.train.Example(features=tf.train.Features(feature=all_features))\n",
    "\n",
    "#        print(tf_record.SerializeToString())\n",
    "\n",
    "        records.append({'review_id': the_input.review_id,\n",
    "                        'date': the_input.date,\n",
    "#                        'tf_record': tf_record.SerializeToString(),\n",
    "                        'input_ids': features.input_ids,\n",
    "                        'input_mask': features.input_mask,\n",
    "                        'segment_ids': features.segment_ids,\n",
    "                        'label_id': features.label_id,\n",
    "                       })\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three(3) feature vectors are created from each raw review (`review_body`) during the feature engineering phase to prepare for BERT processing:\n",
    "\n",
    "* **`input_ids`**:  The id from the pre-trained BERT vocabulary that represents the token.  (Padding of 0 will be used if the # of tokens is less than `max_seq_length`)\n",
    "    \n",
    "* **`input_mask`**:  Specifies which tokens BERT should pay attention to (0 or 1).  Padded `input_ids` will have 0 in each of these vector elements.\n",
    "\n",
    "* **`segment_ids`**:  Segment ids are always 0 for single-sequence tasks such as text classification.  1 is used for two-sequence tasks such as question/answer and next sentence prediction.\n",
    "\n",
    "And one(1) label is created from each raw review (`star_rating`)  :\n",
    "\n",
    "* **`label_id`**:  Label for each training row (`star_rating` 1 through 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate the BERT-specific Feature Engineering Step\n",
    "While we are demonstrating this code with a small amount of data here in the notebook, we will soon scale this to much more data on a powerful SageMaker cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Event time date feature type provided Integral. Event time type should be either Fractional(Unix timestamp in seconds) or String (ISO-8601 format) type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14T17:34:35Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from time import strftime\n",
    "\n",
    "#timestamp = datetime.now().replace(microsecond=0).isoformat()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "        [5, 'ABCD12345', \"\"\"I needed an antivirus application and know the quality of Norton products.  This was a no brainer for me and I am glad it was so simple to get.\"\"\"],\n",
    "        [3, 'EFGH12345', \"\"\"The problem with ElephantDrive is that it requires the use of Java. Since Java is notorious for security problems I haveit removed from all of my computers. What files I do have stored are photos.\"\"\"],\n",
    "        [1, 'IJKL2345', \"\"\"Terrible, none of my codes worked, and I can't uninstall it.  I think this product IS malware and viruses\"\"\"]\n",
    "       ]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['star_rating', 'review_id',  'review_body'])\n",
    "\n",
    "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "inputs = df.apply(lambda x: Input(\n",
    "                                label = x[LABEL_COLUMN],\n",
    "                                text = x[REVIEW_BODY_COLUMN],\n",
    "                                review_id = x[REVIEW_ID_COLUMN],\n",
    "                                date = timestamp\n",
    "                            ),\n",
    "                  axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14T17:34:35Z\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0].date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input 0 of 3\n",
      "\n",
      "**tokens**\n",
      "['i', 'needed', 'an', 'anti', '##virus', 'application', 'and', 'know', 'the', 'quality', 'of', 'norton', 'products', '.', 'this', 'was', 'a', 'no', 'brain', '##er', 'for', 'me', 'and', 'i', 'am', 'glad', 'it', 'was', 'so', 'simple', 'to', 'get', '.']\n",
      "\n",
      "**input_ids**\n",
      "[101, 1045, 2734, 2019, 3424, 23350, 4646, 1998, 2113, 1996, 3737, 1997, 10770, 3688, 1012, 2023, 2001, 1037, 2053, 4167, 2121, 2005, 2033, 1998, 1045, 2572, 5580, 2009, 2001, 2061, 3722, 2000, 2131, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "4\n",
      "\n",
      "**review_id**\n",
      "ABCD12345\n",
      "\n",
      "**date**\n",
      "2020-12-14T17:34:35Z\n",
      "\n",
      "b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ns\\n\\tinput_ids\\x12f\\x1ad\\nbe\\x95\\x08\\xae\\x15\\xe3\\x0f\\xe0\\x1a\\xb6\\xb6\\x01\\xa6$\\xce\\x0f\\xc1\\x10\\xcc\\x0f\\x99\\x1d\\xcd\\x0f\\x92T\\xe8\\x1c\\xf4\\x07\\xe7\\x0f\\xd1\\x0f\\x8d\\x08\\x85\\x10\\xc7 \\xc9\\x10\\xd5\\x0f\\xf1\\x0f\\xce\\x0f\\x95\\x08\\x8c\\x14\\xcc+\\xd9\\x0f\\xd1\\x0f\\x8d\\x10\\x8a\\x1d\\xd0\\x0f\\xd3\\x10\\xf4\\x07f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "**tokens**\n",
      "['the', 'problem', 'with', 'elephant', '##drive', 'is', 'that', 'it', 'requires', 'the', 'use', 'of', 'java', '.', 'since', 'java', 'is', 'notorious', 'for', 'security', 'problems', 'i', 'have', '##it', 'removed', 'from', 'all', 'of', 'my', 'computers', '.', 'what', 'files', 'i', 'do', 'have', 'stored', 'are', 'photos', '.']\n",
      "\n",
      "**input_ids**\n",
      "[101, 1996, 3291, 2007, 10777, 23663, 2003, 2008, 2009, 5942, 1996, 2224, 1997, 9262, 1012, 2144, 9262, 2003, 12536, 2005, 3036, 3471, 1045, 2031, 4183, 3718, 2013, 2035, 1997, 2026, 7588, 1012, 2054, 6764, 1045, 2079, 2031, 8250, 2024, 7760, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "2\n",
      "\n",
      "**review_id**\n",
      "EFGH12345\n",
      "\n",
      "**date**\n",
      "2020-12-14T17:34:35Z\n",
      "\n",
      "b'\\n\\xb9\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nz\\n\\tinput_ids\\x12m\\x1ak\\nie\\xcc\\x0f\\xdb\\x19\\xd7\\x0f\\x99T\\xef\\xb8\\x01\\xd3\\x0f\\xd8\\x0f\\xd9\\x0f\\xb6.\\xcc\\x0f\\xb0\\x11\\xcd\\x0f\\xaeH\\xf4\\x07\\xe0\\x10\\xaeH\\xd3\\x0f\\xf8a\\xd5\\x0f\\xdc\\x17\\x8f\\x1b\\x95\\x08\\xef\\x0f\\xd7 \\x86\\x1d\\xdd\\x0f\\xf3\\x0f\\xcd\\x0f\\xea\\x0f\\xa4;\\xf4\\x07\\x86\\x10\\xec4\\x95\\x08\\x9f\\x10\\xef\\x0f\\xba@\\xe8\\x0f\\xd0<\\xf4\\x07f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "**tokens**\n",
      "['terrible', ',', 'none', 'of', 'my', 'codes', 'worked', ',', 'and', 'i', 'can', \"'\", 't', 'un', '##ins', '##tal', '##l', 'it', '.', 'i', 'think', 'this', 'product', 'is', 'mal', '##ware', 'and', 'viruses']\n",
      "\n",
      "**input_ids**\n",
      "[101, 6659, 1010, 3904, 1997, 2026, 9537, 2499, 1010, 1998, 1045, 2064, 1005, 1056, 4895, 7076, 9080, 2140, 2009, 1012, 1045, 2228, 2023, 4031, 2003, 15451, 8059, 1998, 18191, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**input_mask**\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**segment_ids**\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "**label_id**\n",
      "0\n",
      "\n",
      "**review_id**\n",
      "IJKL2345\n",
      "\n",
      "**date**\n",
      "2020-12-14T17:34:35Z\n",
      "\n",
      "b'\\n\\xad\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nn\\n\\tinput_ids\\x12a\\x1a_\\n]e\\x834\\xf2\\x07\\xc0\\x1e\\xcd\\x0f\\xea\\x0f\\xc1J\\xc3\\x13\\xf2\\x07\\xce\\x0f\\x95\\x08\\x90\\x10\\xed\\x07\\xa0\\x08\\x9f&\\xa47\\xf8F\\xdc\\x10\\xd9\\x0f\\xf4\\x07\\x95\\x08\\xb4\\x11\\xe7\\x0f\\xbf\\x1f\\xd3\\x0f\\xdbx\\xfb>\\xce\\x0f\\x8f\\x8e\\x01f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 64\n",
    "records = transform_inputs_to_tfrecord(inputs, max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three(3) features vectors and one(1) label are converted into a list of `TFRecord` instances (1 per each row of training data):\n",
    "* **`tf_records`**:  Binary representation of each row of training data (3 features + 1 label)\n",
    "\n",
    "These `TFRecord`s are the engineered features that we will use throughout the rest of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**records**\n",
      "b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ns\\n\\tinput_ids\\x12f\\x1ad\\nbe\\x95\\x08\\xae\\x15\\xe3\\x0f\\xe0\\x1a\\xb6\\xb6\\x01\\xa6$\\xce\\x0f\\xc1\\x10\\xcc\\x0f\\x99\\x1d\\xcd\\x0f\\x92T\\xe8\\x1c\\xf4\\x07\\xe7\\x0f\\xd1\\x0f\\x8d\\x08\\x85\\x10\\xc7 \\xc9\\x10\\xd5\\x0f\\xf1\\x0f\\xce\\x0f\\x95\\x08\\x8c\\x14\\xcc+\\xd9\\x0f\\xd1\\x0f\\x8d\\x10\\x8a\\x1d\\xd0\\x0f\\xd3\\x10\\xf4\\x07f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "b'\\n\\xb9\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nz\\n\\tinput_ids\\x12m\\x1ak\\nie\\xcc\\x0f\\xdb\\x19\\xd7\\x0f\\x99T\\xef\\xb8\\x01\\xd3\\x0f\\xd8\\x0f\\xd9\\x0f\\xb6.\\xcc\\x0f\\xb0\\x11\\xcd\\x0f\\xaeH\\xf4\\x07\\xe0\\x10\\xaeH\\xd3\\x0f\\xf8a\\xd5\\x0f\\xdc\\x17\\x8f\\x1b\\x95\\x08\\xef\\x0f\\xd7 \\x86\\x1d\\xdd\\x0f\\xf3\\x0f\\xcd\\x0f\\xea\\x0f\\xa4;\\xf4\\x07\\x86\\x10\\xec4\\x95\\x08\\x9f\\x10\\xef\\x0f\\xba@\\xe8\\x0f\\xd0<\\xf4\\x07f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
      "b'\\n\\xad\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x00\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nn\\n\\tinput_ids\\x12a\\x1a_\\n]e\\x834\\xf2\\x07\\xc0\\x1e\\xcd\\x0f\\xea\\x0f\\xc1J\\xc3\\x13\\xf2\\x07\\xce\\x0f\\x95\\x08\\x90\\x10\\xed\\x07\\xa0\\x08\\x9f&\\xa47\\xf8F\\xdc\\x10\\xd9\\x0f\\xf4\\x07\\x95\\x08\\xb4\\x11\\xe7\\x0f\\xbf\\x1f\\xd3\\x0f\\xdbx\\xfb>\\xce\\x0f\\x8f\\x8e\\x01f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# print('**records**')\n",
    "\n",
    "# for record in records:\n",
    "#     print(record['tf_record'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x03\\n\\x01\\x04\\nS\\n\\x0bsegment_ids\\x12D\\x1aB\\n@\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\ns\\n\\tinput_ids\\x12f\\x1ad\\nbe\\x95\\x08\\xae\\x15\\xe3\\x0f\\xe0\\x1a\\xb6\\xb6\\x01\\xa6$\\xce\\x0f\\xc1\\x10\\xcc\\x0f\\x99\\x1d\\xcd\\x0f\\x92T\\xe8\\x1c\\xf4\\x07\\xe7\\x0f\\xd1\\x0f\\x8d\\x08\\x85\\x10\\xc7 \\xc9\\x10\\xd5\\x0f\\xf1\\x0f\\xce\\x0f\\x95\\x08\\x8c\\x14\\xcc+\\xd9\\x0f\\xd1\\x0f\\x8d\\x10\\x8a\\x1d\\xd0\\x0f\\xd3\\x10\\xf4\\x07f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\nR\\n\\ninput_mask\\x12D\\x1aB\\n@\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# my_tf_record = records[0]['tf_record']\n",
    "# print(my_tf_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.core.example.example_pb2.Example'>\n",
      "features {\n",
      "  feature {\n",
      "    key: \"input_ids\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 101\n",
      "        value: 1045\n",
      "        value: 2734\n",
      "        value: 2019\n",
      "        value: 3424\n",
      "        value: 23350\n",
      "        value: 4646\n",
      "        value: 1998\n",
      "        value: 2113\n",
      "        value: 1996\n",
      "        value: 3737\n",
      "        value: 1997\n",
      "        value: 10770\n",
      "        value: 3688\n",
      "        value: 1012\n",
      "        value: 2023\n",
      "        value: 2001\n",
      "        value: 1037\n",
      "        value: 2053\n",
      "        value: 4167\n",
      "        value: 2121\n",
      "        value: 2005\n",
      "        value: 2033\n",
      "        value: 1998\n",
      "        value: 1045\n",
      "        value: 2572\n",
      "        value: 5580\n",
      "        value: 2009\n",
      "        value: 2001\n",
      "        value: 2061\n",
      "        value: 3722\n",
      "        value: 2000\n",
      "        value: 2131\n",
      "        value: 1012\n",
      "        value: 102\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"input_mask\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 1\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label_ids\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 4\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"segment_ids\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deserialized_tf_record_example = tf.train.Example.FromString(my_tf_record)\n",
    "# print(type(deserialized_tf_record_example))\n",
    "# print(deserialized_tf_record_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.readers.TFRecordDatasetV2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data.TFRecordDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2500ac22d1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#def _parse_function(example_proto):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Parse the input `tf.train.Example` proto using the dictionary above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeserialized_tf_record\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2_unoptimized\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     with ops.name_scope(name, \"ParseSingleExample\",\n\u001b[1;32m    470\u001b[0m                         [serialized, example_names]):\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mparse_example_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# # Create a description of the features.\n",
    "# feature_description = {\n",
    "#     'input_ids': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'input_mask': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'label_ids': tf.io.FixedLenFeature([], tf.int64),\n",
    "#     'segment_ids': tf.io.FixedLenFeature([], tf.int64),\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-82c1e6ab8317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeserialized_tf_record_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2_unoptimized\u001b[0;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     with ops.name_scope(name, \"ParseSingleExample\",\n\u001b[1;32m    470\u001b[0m                         [serialized, example_names]):\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assert_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serialized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mparse_example_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# tf.io.parse_single_example(deserialized_tf_record_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    463\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 464\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for [features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n] with type list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0f797cea9f09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeserialized_tf_record\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    642\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2782\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (features {\n  feature {\n    key: \"input_ids\"\n    value {\n      int64_list {\n        value: 101\n        value: 1045\n        value: 2734\n        value: 2019\n        value: 3424\n        value: 23350\n        value: 4646\n        value: 1998\n        value: 2113\n        value: 1996\n        value: 3737\n        value: 1997\n        value: 10770\n        value: 3688\n        value: 1012\n        value: 2023\n        value: 2001\n        value: 1037\n        value: 2053\n        value: 4167\n        value: 2121\n        value: 2005\n        value: 2033\n        value: 1998\n        value: 1045\n        value: 2572\n        value: 5580\n        value: 2009\n        value: 2001\n        value: 2061\n        value: 3722\n        value: 2000\n        value: 2131\n        value: 1012\n        value: 102\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"input_mask\"\n    value {\n      int64_list {\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 1\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n  feature {\n    key: \"label_ids\"\n    value {\n      int64_list {\n        value: 4\n      }\n    }\n  }\n  feature {\n    key: \"segment_ids\"\n    value {\n      int64_list {\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n        value: 0\n      }\n    }\n  }\n}\n) with an unsupported type (<class 'tensorflow.core.example.example_pb2.Example'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# tf.data.Dataset.from_tensor_slices([deserialized_tf_record])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add BERT Embeddings to Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurestore_runtime = boto3.Session().client(service_name='sagemaker-featurestore-runtime', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define FeatureGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "reviews_feature_group_name = 'reviews-feature-group-' + strftime('%d-%H-%M-%S', gmtime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "reviews_feature_group = FeatureGroup(name=reviews_feature_group_name, sagemaker_session=sagemaker_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record identifier and event time feature names\n",
    "record_identifier_feature_name = \"review_id\"\n",
    "event_time_feature_name = \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tf_record</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>input_mask</th>\n",
       "      <th>segment_ids</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCD12345</td>\n",
       "      <td>2020-12-14T17:34:35Z</td>\n",
       "      <td>b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...</td>\n",
       "      <td>[101, 1045, 2734, 2019, 3424, 23350, 4646, 199...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EFGH12345</td>\n",
       "      <td>2020-12-14T17:34:35Z</td>\n",
       "      <td>b'\\n\\xb9\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...</td>\n",
       "      <td>[101, 1996, 3291, 2007, 10777, 23663, 2003, 20...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IJKL2345</td>\n",
       "      <td>2020-12-14T17:34:35Z</td>\n",
       "      <td>b'\\n\\xad\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...</td>\n",
       "      <td>[101, 6659, 1010, 3904, 1997, 2026, 9537, 2499...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                  date  \\\n",
       "0  ABCD12345  2020-12-14T17:34:35Z   \n",
       "1  EFGH12345  2020-12-14T17:34:35Z   \n",
       "2   IJKL2345  2020-12-14T17:34:35Z   \n",
       "\n",
       "                                           tf_record  \\\n",
       "0  b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "1  b'\\n\\xb9\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "2  b'\\n\\xad\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1045, 2734, 2019, 3424, 23350, 4646, 199...   \n",
       "1  [101, 1996, 3291, 2007, 10777, 23663, 2003, 20...   \n",
       "2  [101, 6659, 1010, 3904, 1997, 2026, 9537, 2499...   \n",
       "\n",
       "                                          input_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         segment_ids  label_id  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         4  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         2  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_records = pd.DataFrame.from_dict(records)\n",
    "df_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Cast needed for Feature Store_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_object_to_string(data_frame):\n",
    "    for label in data_frame.columns:\n",
    "        if data_frame.dtypes[label] == 'object':\n",
    "            data_frame[label] = data_frame[label].astype(\"str\").astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast object dtype to string. The SageMaker FeatureStore Python SDK will then map the string dtype to String feature type.\n",
    "cast_object_to_string(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature definitions to the feature group. SageMaker FeatureStore Python SDK will auto-detect the data schema based on input data.\n",
    "reviews_feature_group.load_feature_definitions(data_frame=df_records); # output is suppressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'reviews_feature_store'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-17-34-36',\n",
       " 'ResponseMetadata': {'RequestId': '929a03e4-dfdf-4c9a-9dcf-47eb1246b2a5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '929a03e4-dfdf-4c9a-9dcf-47eb1246b2a5',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '110',\n",
       "   'date': 'Mon, 14 Dec 2020 17:34:36 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_feature_group.create(\n",
    "    s3_uri=f\"s3://{bucket}/{prefix}\",\n",
    "    record_identifier_name=record_identifier_feature_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-17-34-36',\n",
       " 'FeatureGroupName': 'reviews-feature-group-14-17-34-36',\n",
       " 'RecordIdentifierFeatureName': 'review_id',\n",
       " 'EventTimeFeatureName': 'date',\n",
       " 'FeatureDefinitions': [{'FeatureName': 'review_id', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'date', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'tf_record', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'input_ids', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'input_mask', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'segment_ids', 'FeatureType': 'String'},\n",
       "  {'FeatureName': 'label_id', 'FeatureType': 'Integral'}],\n",
       " 'CreationTime': datetime.datetime(2020, 12, 14, 17, 34, 36, 958000, tzinfo=tzlocal()),\n",
       " 'OnlineStoreConfig': {'EnableOnlineStore': True},\n",
       " 'OfflineStoreConfig': {'S3StorageConfig': {'S3Uri': 's3://sagemaker-us-east-1-806570384721/reviews_feature_store'},\n",
       "  'DisableGlueTableCreation': False},\n",
       " 'RoleArn': 'arn:aws:iam::806570384721:role/TeamRole',\n",
       " 'FeatureGroupStatus': 'Creating',\n",
       " 'ResponseMetadata': {'RequestId': 'c5a95710-b765-4d73-82d9-8f6928a1c050',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c5a95710-b765-4d73-82d9-8f6928a1c050',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '925',\n",
       "   'date': 'Mon, 14 Dec 2020 17:34:36 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_feature_group.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupSummaries': [{'FeatureGroupName': 'reviews-feature-group-14-17-34-36',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-17-34-36',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 17, 34, 36, 958000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Creating'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-16-16-22',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-16-16-22',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 16, 16, 57, 333000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-15-54-17',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-15-54-17',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 15, 54, 34, 344000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created',\n",
       "   'OfflineStoreStatus': {'Status': 'Active'}},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-06-16-36',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-06-16-36',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 6, 16, 36, 150000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created',\n",
       "   'OfflineStoreStatus': {'Status': 'Active'}},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-06-14-43',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-06-14-43',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 6, 14, 43, 762000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-06-12-19',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-06-12-19',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 6, 12, 19, 501000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-06-03-04',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-06-03-04',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 6, 3, 5, 95000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-06-01-21',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-06-01-21',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 6, 1, 21, 745000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-05-56-46',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-05-56-46',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 5, 56, 46, 460000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'},\n",
       "  {'FeatureGroupName': 'reviews-feature-group-14-05-53-54',\n",
       "   'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:806570384721:feature-group/reviews-feature-group-14-05-53-54',\n",
       "   'CreationTime': datetime.datetime(2020, 12, 14, 5, 53, 54, 564000, tzinfo=tzlocal()),\n",
       "   'FeatureGroupStatus': 'Created'}],\n",
       " 'NextToken': 'cIws2QhTXUIa8bi8Va1Yd0CRnbOb9L0/udYn/RzMx6cXGI/fDvgPIiy7JxQYaUf169bOHoQWOwJgR9tfEwXOg5K6qwgx90lB9xqIVUHFSAEaJd+wAo8RIIxkV43DBHRZRRdSQBSF74+DFqFDHVv8xLhVEYPv3Fmca3pFcvtmBhP6HW8KREisueqCcbPYo8GtWsayrG3Dg/qIhulx7tUjtol2x1sfB5E8fstdtPuxD7dJlNFH3gsJCvo1FBybq6rWDxmTq1KjfsXrQftZ2gesUsOSoVrVB18EFh5iaz6Dj8OyDlGOwQrR7WrEgdfxBTtutte93YWwyMzx4U2ySCzgZwtV4Zz7dsUUaPkh4FS9eMaIlxrnlhVoCL0PVqJ7d5730WO8qcdF9g/APsGJZcP4y1Q0ayUrxjZaNS6LUda59ZuL/BgBnY68nNPm31rHEUt8Y3EWx+j3KzEmSraWnXeflkqD3cbr3CbSosy7zBPT3LYNFwjeD7chSNSqK54kstbyfX8QTwVjf7uhpDhZX/JA856Zj62FRx4CdBgKytQ1TQz6v2OK3hWwlSz0BkPV9clRyHE+',\n",
       " 'ResponseMetadata': {'RequestId': 'd7c0b649-88f7-4ee2-936a-439b82f8af4f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd7c0b649-88f7-4ee2-936a-439b82f8af4f',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2993',\n",
       "   'date': 'Mon, 14 Dec 2020 17:34:37 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.list_feature_groups() # use boto client to list FeatureGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PutRecords into FeatureGroup\n",
    "\n",
    "After the FeatureGroups have been created, we can put data into the FeatureGroups by using the PutRecord API. This API can handle high TPS and is designed to be called by different streams. The data from all of these Put requests is buffered and written to S3 in chunks. The files will be written to the offline store within a few minutes of ingestion. For this example, to accelerate the ingestion process, we are specifying multiple workers to do the job simultaneously. It will take ~1min to ingest data to the 2 FeatureGroups, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    while status == \"Creating\":\n",
    "        print(\"Waiting for Feature Group Creation\")\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "    if status != \"Created\":\n",
    "        raise RuntimeError(f\"Failed to create feature group {feature_group.name}\")\n",
    "    print(f\"FeatureGroup {feature_group.name} successfully created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for Feature Group Creation\n",
      "Waiting for Feature Group Creation\n",
      "FeatureGroup reviews-feature-group-14-17-34-36 successfully created.\n"
     ]
    }
   ],
   "source": [
    "wait_for_feature_group_creation_complete(feature_group=reviews_feature_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionManagerPandas(feature_group_name='reviews-feature-group-14-17-34-36', sagemaker_session=<sagemaker.session.Session object at 0x7fdc9469feb8>, data_frame=   review_id                  date  \\\n",
       "0  ABCD12345  2020-12-14T17:34:35Z   \n",
       "1  EFGH12345  2020-12-14T17:34:35Z   \n",
       "2   IJKL2345  2020-12-14T17:34:35Z   \n",
       "\n",
       "                                           tf_record  \\\n",
       "0  b'\\n\\xb2\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "1  b'\\n\\xb9\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "2  b'\\n\\xad\\x02\\n\\x12\\n\\tlabel_ids\\x12\\x05\\x1a\\x0...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1045, 2734, 2019, 3424, 23350, 4646, 199...   \n",
       "1  [101, 1996, 3291, 2007, 10777, 23663, 2003, 20...   \n",
       "2  [101, 6659, 1010, 3904, 1997, 2026, 9537, 2499...   \n",
       "\n",
       "                                          input_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         segment_ids  label_id  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         4  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         2  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         0  , max_workers=3, _futures={<Future at 0x7fdc5ad20e48 state=finished returned NoneType>: (0, 1), <Future at 0x7fdbbbd1eac8 state=finished returned NoneType>: (1, 2), <Future at 0x7fdbbb53af60 state=finished returned NoneType>: (2, 3)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_feature_group.ingest(\n",
    "    data_frame=df_records, max_workers=3, wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '240e861f-c95e-431f-bd72-66951831382c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '240e861f-c95e-431f-bd72-66951831382c',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '2284',\n",
       "   'date': 'Mon, 14 Dec 2020 17:34:48 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Record': [{'FeatureName': 'review_id', 'ValueAsString': 'IJKL2345'},\n",
       "  {'FeatureName': 'date', 'ValueAsString': '2020-12-14T17:34:35Z'},\n",
       "  {'FeatureName': 'tf_record',\n",
       "   'ValueAsString': \"b'\\\\n\\\\xad\\\\x02\\\\n\\\\x12\\\\n\\\\tlabel_ids\\\\x12\\\\x05\\\\x1a\\\\x03\\\\n\\\\x01\\\\x00\\\\nS\\\\n\\\\x0bsegment_ids\\\\x12D\\\\x1aB\\\\n@\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\nn\\\\n\\\\tinput_ids\\\\x12a\\\\x1a_\\\\n]e\\\\x834\\\\xf2\\\\x07\\\\xc0\\\\x1e\\\\xcd\\\\x0f\\\\xea\\\\x0f\\\\xc1J\\\\xc3\\\\x13\\\\xf2\\\\x07\\\\xce\\\\x0f\\\\x95\\\\x08\\\\x90\\\\x10\\\\xed\\\\x07\\\\xa0\\\\x08\\\\x9f&\\\\xa47\\\\xf8F\\\\xdc\\\\x10\\\\xd9\\\\x0f\\\\xf4\\\\x07\\\\x95\\\\x08\\\\xb4\\\\x11\\\\xe7\\\\x0f\\\\xbf\\\\x1f\\\\xd3\\\\x0f\\\\xdbx\\\\xfb>\\\\xce\\\\x0f\\\\x8f\\\\x8e\\\\x01f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\nR\\\\n\\\\ninput_mask\\\\x12D\\\\x1aB\\\\n@\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00'\"},\n",
       "  {'FeatureName': 'input_ids',\n",
       "   'ValueAsString': '[101, 6659, 1010, 3904, 1997, 2026, 9537, 2499, 1010, 1998, 1045, 2064, 1005, 1056, 4895, 7076, 9080, 2140, 2009, 1012, 1045, 2228, 2023, 4031, 2003, 15451, 8059, 1998, 18191, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'},\n",
       "  {'FeatureName': 'input_mask',\n",
       "   'ValueAsString': '[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'},\n",
       "  {'FeatureName': 'segment_ids',\n",
       "   'ValueAsString': '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]'},\n",
       "  {'FeatureName': 'label_id', 'ValueAsString': '0'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_identifier_value = 'IJKL2345'\n",
    "\n",
    "featurestore_runtime.get_record(FeatureGroupName=reviews_feature_group_name, RecordIdentifierValueAsString=record_identifier_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTERNAL TABLE IF NOT EXISTS sagemaker_featurestore.reviews-feature-group-14-17-34-36 (\n",
      "  review_id STRING\n",
      "  date STRING\n",
      "  tf_record STRING\n",
      "  input_ids STRING\n",
      "  input_mask STRING\n",
      "  segment_ids STRING\n",
      "  label_id INT\n",
      ")\n",
      "ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'\n",
      "  STORED AS\n",
      "  INPUTFORMAT 'parquet.hive.DeprecatedParquetInputFormat'\n",
      "  OUTPUTFORMAT 'parquet.hive.DeprecatedParquetOutputFormat'\n",
      "LOCATION 's3://sagemaker-us-east-1-806570384721/reviews_feature_store/806570384721/sagemaker/us-east-1/offline-store/reviews-feature-group-14-17-34-36'\n"
     ]
    }
   ],
   "source": [
    "print(reviews_feature_group.as_hive_ddl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data available.\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity()[\"Account\"]\n",
    "\n",
    "reviews_feature_group_s3_prefix = prefix + '/' + account_id + '/sagemaker/' + region + '/offline-store/' + reviews_feature_group_name + '/data'\n",
    "\n",
    "offline_store_contents = None\n",
    "while (offline_store_contents is None):\n",
    "    objects_in_bucket = s3.list_objects(Bucket=bucket,Prefix=prefix)\n",
    "    if ('Contents' in objects_in_bucket and len(objects_in_bucket['Contents']) > 1):\n",
    "        offline_store_contents = objects_in_bucket['Contents']\n",
    "    else:\n",
    "        print('Waiting for data in offline store...\\n')\n",
    "        sleep(60)\n",
    "    \n",
    "print('Data available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Training Dataset\n",
    "\n",
    "SageMaker FeatureStore automatically builds the Glue Data Catalog for FeatureGroups (you can optionally turn it on/off while creating the FeatureGroup). In this example, we want to create one training dataset with FeatureValues from both identity and transaction FeatureGroups. This is done by utilizing the auto-built Catalog. We run an Athena query that joins the data stored in the offline store in S3 from the 2 FeatureGroups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SELECT tf_record FROM \"reviews-feature-group-14-17-34-36-1607967276\" LIMIT 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_record</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tf_record]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_query = reviews_feature_group.athena_query()\n",
    "\n",
    "reviews_table = reviews_query.table_name\n",
    "# sagemaker_featurestore.reviews-feature-group-14-06-16-36\n",
    "\n",
    "query_string = 'SELECT tf_record FROM \"'+reviews_table+'\" LIMIT 1'\n",
    "print('Running ' + query_string)\n",
    "\n",
    "# run Athena query. The output is loaded to a Pandas dataframe.\n",
    "dataset = pd.DataFrame()\n",
    "reviews_query.run(query_string=query_string, output_location='s3://'+bucket+'/'+prefix+'/query_results/')\n",
    "reviews_query.wait()\n",
    "dataset = reviews_query.as_dataframe()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare query results for training.\n",
    "# query_execution = reviews_query.get_query_execution()\n",
    "# query_result = 's3://'+bucket+'/'+prefix+'/query_results/'+query_execution['QueryExecution']['QueryExecutionId']+'.csv'\n",
    "# print(query_result)\n",
    "\n",
    "# # Select useful columns for training with target column as the first.\n",
    "# dataset = dataset[[\"embedding\"]]\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Check if to_csv is ok\n",
    "## Possibly change to sth. else (might be ok for now, as we have only 1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data-tfrecord-featurestore/reviews-embeddings.tfrecord'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv in S3 without headers and index column.\n",
    "dataset.to_csv(file_name, header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Run these next 2 lines to confirm if .tfrecord is still corrupt or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_tfrecord_dataset = tf.data.TFRecordDataset(file_name)\n",
    "restored_tfrecord_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.dataset_ops._NumpyIterator at 0x7fdc5afc8dd8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_tfrecord_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(restored_tfrecord_dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from io import TextIOWrapper\n",
    "\n",
    "# with open(file_name, mode=\"wb\") as fd:\n",
    "#   dataset.to_csv(TextIOWrapper(fd), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3.upload_file('reviews-embeddings.csv', bucket, prefix+'/training_input/reviews_embeddings.csv')\n",
    "#dataset_uri_prefix = 's3://'+bucket+'/'+prefix+'/training_input/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Deploy the Model\n",
    "\n",
    "Now it's time to launch a Training job to fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_record_dataset = tf.data.TFRecordDataset(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TFRecordDatasetV2 shapes: (), types: tf.string>\n"
     ]
    }
   ],
   "source": [
    "print(tf_record_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_path = 's3://'+bucket+'/'+prefix+'/training_output'\n",
    "training_image = '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.0-1-cpu-py3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "train_steps_per_epoch=50\n",
    "validation_steps=50\n",
    "test_steps=50\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "freeze_bert_layer=False\n",
    "enable_sagemaker_debugger=True\n",
    "enable_checkpointing=False\n",
    "enable_tensorboard=False\n",
    "input_mode='File'\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_s3_uri' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2f131ab693b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#                        use_spot_instances=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                        max_wait=7200, # Seconds to wait for spot instances to become available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                        \u001b[0mcheckpoint_s3_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_s3_uri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                        \u001b[0mpy_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'py3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                        \u001b[0mframework_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2.1.0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_s3_uri' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       instance_count=train_instance_count,\n",
    "                       instance_type=train_instance_type,\n",
    "                       volume_size=train_volume_size,\n",
    "#                        use_spot_instances=True,\n",
    "#                        max_wait=7200, # Seconds to wait for spot instances to become available\n",
    "                       checkpoint_s3_uri=checkpoint_s3_uri,\n",
    "                       py_version='py3',\n",
    "                       framework_version='2.1.0',\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "                                        'enable_checkpointing': enable_checkpointing,\n",
    "                                        'enable_tensorboard': enable_tensorboard,                                        \n",
    "                                        'run_validation': run_validation,\n",
    "                                        'run_test': run_test,\n",
    "                                        'run_sample_predictions': run_sample_predictions},\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions,\n",
    "                       rules=rules,\n",
    "                       debugger_hook_config=hook_config,                       \n",
    "#                       max_run=7200, # number of seconds\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "training_model = Estimator(training_image,\n",
    "                           role, \n",
    "                           instance_count=1, \n",
    "                           instance_type='ml.m5.2xlarge',\n",
    "                           volume_size = 5,\n",
    "                           max_run = 3600,\n",
    "                           input_mode= 'File',\n",
    "                           output_path=training_output_path,\n",
    "                           sagemaker_session=feature_store_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker.inputs\n",
    "\n",
    "train_data = sagemaker.inputs.TrainingInput(dataset_uri_prefix, distribution='FullyReplicated', \n",
    "                                            content_type='text/csv', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.save_checkpoint();\n",
    "Jupyter.notebook.session.delete();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
