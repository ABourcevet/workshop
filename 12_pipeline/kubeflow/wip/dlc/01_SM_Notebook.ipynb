{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SM_HOSTS']='1'\n",
    "os.environ['SM_CURRENT_HOST']='localhost'\n",
    "os.environ['SM_MODEL_DIR']='./model'\n",
    "os.environ['SM_CHANNEL_TRAIN']='./data-tfrecord/bert-train'\n",
    "os.environ['SM_CHANNEL_VALIDATION']='./data-tfrecord/bert-validation'\n",
    "os.environ['SM_CHANNEL_TEST']='./data-tfrecord/bert-test'\n",
    "os.environ['SM_OUTPUT_DIR']='./output/'\n",
    "os.environ['SM_OUTPUT_DATA_DIR']='./output/data/'\n",
    "os.environ['SM_NUM_GPUS']='0'\n",
    "os.environ['SAGEMAKER_JOB_NAME']='JOB_NAME'\n",
    "os.environ['SM_TRAINING_ENV']='{\\\"is_master\\\":true}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Model Training Code In Noteboook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data='./input/data/train'\n",
    "validation_data='./input/data/validation'\n",
    "test_data='./input/data/test'\n",
    "\n",
    "output_dir='./output/'\n",
    "output_data_dir='./output/data/'\n",
    "local_model_dir='./model/'\n",
    "\n",
    "train_steps_per_epoch=1\n",
    "epochs=1\n",
    "learning_rate=0.00003\n",
    "epsilon=0.00000001\n",
    "train_batch_size=8\n",
    "validation_batch_size=8\n",
    "test_batch_size=8\n",
    "validation_steps=1\n",
    "test_steps=1\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "max_seq_length=64\n",
    "freeze_bert_layer=True\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True\n",
    "\n",
    "hosts=1\n",
    "current_host='localhost'\n",
    "num_gpus=0\n",
    "enable_sagemaker_debugger=False\n",
    "is_master=True\n",
    "pipe_mode=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Variables:\n",
      "{'AWS_AUTO_SCALING_HOME': '/opt/aws/apitools/as',\n",
      " 'AWS_CLOUDWATCH_HOME': '/opt/aws/apitools/mon',\n",
      " 'AWS_ELB_HOME': '/opt/aws/apitools/elb',\n",
      " 'AWS_PATH': '/opt/aws',\n",
      " 'BASH_FUNC_module()': '() '\n",
      "                       '{  '\n",
      "                       'eval '\n",
      "                       '`/usr/bin/modulecmd '\n",
      "                       'bash '\n",
      "                       '$*`\\n'\n",
      "                       '}',\n",
      " 'CLICOLOR': '1',\n",
      " 'CONDA_DEFAULT_ENV': 'python3',\n",
      " 'CONDA_EXE': '/home/ec2-user/anaconda3/bin/conda',\n",
      " 'CONDA_PREFIX': '/home/ec2-user/anaconda3/envs/python3',\n",
      " 'CONDA_PREFIX_1': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv',\n",
      " 'CONDA_PREFIX_2': '/home/ec2-user/anaconda3',\n",
      " 'CONDA_PROMPT_MODIFIER': '(python3) ',\n",
      " 'CONDA_PYTHON_EXE': '/home/ec2-user/anaconda3/bin/python',\n",
      " 'CONDA_SHLVL': '3',\n",
      " 'CUDA_PATH': '/usr/local/cuda-10.0',\n",
      " 'CVS_RSH': 'ssh',\n",
      " 'EC2_AMITOOL_HOME': '/opt/aws/amitools/ec2',\n",
      " 'EC2_HOME': '/opt/aws/apitools/ec2',\n",
      " 'ENV_NAME': 'python3',\n",
      " 'GIT_PAGER': 'cat',\n",
      " 'GIT_PYTHON_REFRESH': 'quiet',\n",
      " 'GSETTINGS_SCHEMA_DIR': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv/share/glib-2.0/schemas',\n",
      " 'GSETTINGS_SCHEMA_DIR_CONDA_BACKUP': '',\n",
      " 'HISTCONTROL': 'ignoredups',\n",
      " 'HISTSIZE': '1000',\n",
      " 'HOME': '/home/ec2-user',\n",
      " 'HOSTNAME': 'ip-172-16-92-211',\n",
      " 'JAVA_HOME': '/usr/lib/jvm/java',\n",
      " 'JAVA_HOME_CONDA_BACKUP': '/usr/lib/jvm/java',\n",
      " 'JAVA_LD_LIBRARY_PATH': '/home/ec2-user/anaconda3/envs/JupyterSystemEnv/lib/server',\n",
      " 'JAVA_LD_LIBRARY_PATH_BACKUP': '',\n",
      " 'JPY_PARENT_PID': '4348',\n",
      " 'KMP_DUPLICATE_LIB_OK': 'True',\n",
      " 'KMP_INIT_AT_FORK': 'FALSE',\n",
      " 'LANG': 'en_US.UTF-8',\n",
      " 'LD_LIBRARY_PATH': '/usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:',\n",
      " 'LD_LIBRARY_PATH_WITHOUT_CUDA': '/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:',\n",
      " 'LD_LIBRARY_PATH_WITH_DEFAULT_CUDA': '/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda-10.0/lib/:',\n",
      " 'LESSOPEN': '||/usr/bin/lesspipe.sh '\n",
      "             '%s',\n",
      " 'LESS_TERMCAP_mb': '\\x1b[01;31m',\n",
      " 'LESS_TERMCAP_md': '\\x1b[01;38;5;208m',\n",
      " 'LESS_TERMCAP_me': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_se': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_ue': '\\x1b[0m',\n",
      " 'LESS_TERMCAP_us': '\\x1b[04;38;5;111m',\n",
      " 'LOADEDMODULES': '',\n",
      " 'LOGNAME': 'ec2-user',\n",
      " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=01;05;37;41:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.axv=01;35:*.anx=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=01;36:*.au=01;36:*.flac=01;36:*.mid=01;36:*.midi=01;36:*.mka=01;36:*.mp3=01;36:*.mpc=01;36:*.ogg=01;36:*.ra=01;36:*.wav=01;36:*.axa=01;36:*.oga=01;36:*.spx=01;36:*.xspf=01;36:',\n",
      " 'MAIL': '/var/spool/mail/ec2-user',\n",
      " 'MANPATH': ':',\n",
      " 'MODULEPATH': '/usr/share/Modules/modulefiles:/etc/modulefiles',\n",
      " 'MODULESHOME': '/usr/share/Modules',\n",
      " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
      " 'PAGER': 'cat',\n",
      " 'PATH': '/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/home/ec2-user/anaconda3/envs/python3/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/home/ec2-user/.dl_binaries/bin:/usr/local/mpi/bin:/home/ec2-user/anaconda3/bin:/home/ec2-user/anaconda3/condabin:/home/ec2-user/anaconda3/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/libexec/gcc/x86_64-amazon-linux/4.8.5:/opt/amazon/openmpi/bin:/opt/amazon/efa/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/aws/bin:/opt/aws/bin',\n",
      " 'PKG_CONFIG_PATH': '/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:/usr/local/lib/pkgconfig:',\n",
      " 'PWD': '/home/ec2-user',\n",
      " 'PYTHON_INSTALL_LAYOUT': 'amzn',\n",
      " 'PYTHON_VERSION': '3.6',\n",
      " 'SAGEMAKER_JOB_NAME': 'JOB_NAME',\n",
      " 'SHELL': '/bin/sh',\n",
      " 'SHLVL': '1',\n",
      " 'SM_CHANNEL_TEST': './data-tfrecord/bert-test',\n",
      " 'SM_CHANNEL_TRAIN': './data-tfrecord/bert-train',\n",
      " 'SM_CHANNEL_VALIDATION': './data-tfrecord/bert-validation',\n",
      " 'SM_CURRENT_HOST': 'localhost',\n",
      " 'SM_HOSTS': '1',\n",
      " 'SM_MODEL_DIR': './model',\n",
      " 'SM_NUM_GPUS': '0',\n",
      " 'SM_OUTPUT_DATA_DIR': './output/data/',\n",
      " 'SM_OUTPUT_DIR': './output/',\n",
      " 'SM_TRAINING_ENV': '{\"is_master\":true}',\n",
      " 'TERM': 'xterm-color',\n",
      " 'USER': 'ec2-user',\n",
      " '_': '/bin/env\\n',\n",
      " '_CE_CONDA': '',\n",
      " '_CE_M': ''}\n",
      "train_data ./data-tfrecord/bert-train\n",
      "validation_data ./data-tfrecord/bert-validation\n",
      "test_data ./data-tfrecord/bert-test\n",
      "local_model_dir ./model/\n",
      "output_dir ./output/\n",
      "hosts 1\n",
      "current_host localhost\n",
      "num_gpus 0\n",
      "job_name JOB_NAME\n",
      "use_xla True\n",
      "use_amp True\n",
      "max_seq_length 64\n",
      "train_batch_size 8\n",
      "validation_batch_size 8\n",
      "test_batch_size 8\n",
      "epochs 1\n",
      "learning_rate 3e-05\n",
      "epsilon 1e-08\n",
      "train_steps_per_epoch 1\n",
      "validation_steps 1\n",
      "test_steps 1\n",
      "freeze_bert_layer True\n",
      "enable_sagemaker_debugger False\n",
      "run_validation True\n",
      "run_test True\n",
      "run_sample_predictions True\n",
      "enable_tensorboard False\n",
      "enable_checkpointing False\n",
      "pipe_mode False\n",
      "is_master True\n",
      "checkpoint_base_path ./checkpoints/\n",
      "checkpoint_path ./checkpoints/\n",
      "Using pipe_mode: False\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "train_data_filenames ['./data-tfrecord/bert-train/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-train/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./data-tfrecord/bert-train/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-train/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "Sucessfully downloaded after 0 retries.\n",
      "** use_amp True\n",
      "enable_sagemaker_debugger False\n",
      "*** OPTIMIZER <tensorflow.python.keras.mixed_precision.experimental.loss_scale_optimizer.LossScaleOptimizer object at 0x7fe444435da0> ***\n",
      "Compiled model <transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification object at 0x7fe55afbe9b0>\n",
      "Model: \"tf_distil_bert_for_sequence_classification_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "distilbert (TFDistilBertMain multiple                  66362880  \n",
      "_________________________________________________________________\n",
      "pre_classifier (Dense)       multiple                  590592    \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  3845      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 66,957,317\n",
      "Trainable params: 594,437\n",
      "Non-trainable params: 66,362,880\n",
      "_________________________________________________________________\n",
      "None\n",
      "validation_data_filenames ['./data-tfrecord/bert-validation/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-validation/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./data-tfrecord/bert-validation/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-validation/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "Starting Training and Validation...\n",
      "Train for 1 steps, validate for 1 steps\n",
      "1/1 [==============================] - 13s 13s/step - loss: 1.6092 - accuracy: 0.1250 - val_loss: 1.5956 - val_accuracy: 0.2500\n",
      "<tensorflow.python.keras.callbacks.History object at 0x7fe40de5b320>\n",
      "test_data_filenames ['./data-tfrecord/bert-test/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-test/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "***** Using input_filenames ['./data-tfrecord/bert-test/part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord', './data-tfrecord/bert-test/part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord']\n",
      "Starting test...\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.6474 - accuracy: 0.2500\n",
      "Test history [1.6474099159240723, 0.25]\n",
      "transformer_fine_tuned_model_path ./model/transformers/fine-tuned/\n",
      "tensorflow_saved_model_path ./model/tensorflow/saved_model/0\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40f665978>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40f66c358>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40db3e0b8>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40db73550>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40db98f98>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7fe40dddd668>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./model/tensorflow/saved_model/0/assets\n",
      "['./model/code/']\n",
      "inference_device -1\n",
      "I loved it!  I will recommend this to everyone. [{'label': 5, 'score': 0.21522205}]\n",
      "It's OK. [{'label': 5, 'score': 0.21280076}]\n",
      "Really bad.  I hope they don't make this anymore. [{'label': 5, 'score': 0.21115829}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.85      0.43      0.57        93\n",
      "\n",
      "    accuracy                           0.40       100\n",
      "   macro avg       0.17      0.09      0.11       100\n",
      "weighted avg       0.79      0.40      0.53       100\n",
      "\n",
      "Accuracy:  0.4\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  4]\n",
      " [ 0  0  0  0  3]\n",
      " [24  4 12 13 40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pprint\n",
    "import argparse\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers.configuration_distilbert import DistilBertConfig\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "CLASSES = [1, 2, 3, 4, 5]\n",
    "\n",
    "def select_data_and_label_from_record(record):\n",
    "    x = {\n",
    "        'input_ids': record['input_ids'],\n",
    "        'input_mask': record['input_mask'],\n",
    "        'segment_ids': record['segment_ids']\n",
    "    }\n",
    "\n",
    "    y = record['label_ids']\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "\n",
    "def file_based_input_dataset_builder(channel,\n",
    "                                     input_filenames,\n",
    "                                     pipe_mode,\n",
    "                                     is_training,\n",
    "                                     drop_remainder,\n",
    "                                     batch_size,\n",
    "                                     epochs,\n",
    "                                     steps_per_epoch,\n",
    "                                     max_seq_length):\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "\n",
    "    if pipe_mode:\n",
    "            print('***** Using pipe_mode with channel {}'.format(channel))\n",
    "            from sagemaker_tensorflow import PipeModeDataset\n",
    "            dataset = PipeModeDataset(channel=channel,\n",
    "                                      record_format='TFRecord')\n",
    "    else:\n",
    "        print('***** Using input_filenames {}'.format(input_filenames))\n",
    "        dataset = tf.data.TFRecordDataset(input_filenames)\n",
    "    \n",
    "    dataset = dataset.repeat(epochs * steps_per_epoch * 100)\n",
    "\n",
    "    name_to_features = {\n",
    "      \"input_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"input_mask\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"segment_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
    "      \"label_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    def _decode_record(record, name_to_features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        record = tf.io.parse_single_example(record, name_to_features)\n",
    "        return record\n",
    "    \n",
    "    dataset = dataset.apply(\n",
    "        tf.data.experimental.map_and_batch(\n",
    "          lambda record: _decode_record(record, name_to_features),\n",
    "          batch_size=batch_size,\n",
    "          drop_remainder=drop_remainder,\n",
    "          num_parallel_calls=tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=1000,\n",
    "                              reshuffle_each_iteration=True)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_checkpoint_model(checkpoint_path):\n",
    "    import glob\n",
    "    import os\n",
    "    \n",
    "    glob_pattern = os.path.join(checkpoint_path, '*.h5')\n",
    "    print('glob pattern {}'.format(glob_pattern))\n",
    "\n",
    "    list_of_checkpoint_files = glob.glob(glob_pattern)\n",
    "    print('List of checkpoint files {}'.format(list_of_checkpoint_files))\n",
    "    \n",
    "    latest_checkpoint_file = max(list_of_checkpoint_files)\n",
    "    print('Latest checkpoint file {}'.format(latest_checkpoint_file))\n",
    "\n",
    "    initial_epoch_number_str = latest_checkpoint_file.rsplit('_', 1)[-1].split('.h5')[0]\n",
    "    initial_epoch_number = int(initial_epoch_number_str)\n",
    "\n",
    "    loaded_model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "                                               latest_checkpoint_file,\n",
    "                                               config=config)\n",
    "\n",
    "    print('loaded_model {}'.format(loaded_model))\n",
    "    print('initial_epoch_number {}'.format(initial_epoch_number))\n",
    "    \n",
    "    return loaded_model, initial_epoch_number\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    args=easydict.EasyDict({\n",
    "        'train_data': train_data,\n",
    "        'validation_data': validation_data,\n",
    "        'test_data': test_data,\n",
    "        'output_dir': output_dir,\n",
    "        'local_model_dir': local_model_dir,\n",
    "        'hosts': hosts,\n",
    "        'current_host': current_host,\n",
    "        'num_gpus': num_gpus,\n",
    "        'job_name': job_name,\n",
    "        'checkpoint_base_path': checkpoint_base_path,\n",
    "        'use_xla': use_xla,\n",
    "        'use_amp': use_amp,\n",
    "        'max_seq_length': max_seq_length,\n",
    "        'train_batch_size': train_batch_size,\n",
    "        'validation_batch_size': validation_batch_size,\n",
    "        'test_batch_size': test_batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epsilon': epsilon,\n",
    "        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "        'validation_steps': validation_steps,\n",
    "        'test_steps': test_steps,\n",
    "        'freeze_bert_layer': freeze_bert_layer,\n",
    "        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "        'run_validation': run_validation,\n",
    "        'run_test': run_test,\n",
    "        'run_sample_predictions': run_sample_predictions,\n",
    "        'enable_tensorboard': enable_tensorboard,\n",
    "        'enable_checkpointing': enable_checkpointing,\n",
    "        'output_data_dir': output_data_dir,\n",
    "        'is_master': is_master,\n",
    "        'pipe_mode': pipe_mode\n",
    "    })\n",
    "    \n",
    "    \n",
    "    env_var = os.environ \n",
    "    print(\"Environment Variables:\") \n",
    "    pprint.pprint(dict(env_var), width = 1) \n",
    "    \n",
    "    train_data = args.train_data\n",
    "    print('train_data {}'.format(train_data))\n",
    "    validation_data = args.validation_data\n",
    "    print('validation_data {}'.format(validation_data))\n",
    "    test_data = args.test_data\n",
    "    print('test_data {}'.format(test_data))    \n",
    "    local_model_dir = args.local_model_dir\n",
    "    print('local_model_dir {}'.format(local_model_dir))\n",
    "    output_dir = args.output_dir\n",
    "    print('output_dir {}'.format(output_dir))    \n",
    "    hosts = args.hosts\n",
    "    print('hosts {}'.format(hosts))    \n",
    "    current_host = args.current_host\n",
    "    print('current_host {}'.format(current_host))    \n",
    "    num_gpus = args.num_gpus\n",
    "    print('num_gpus {}'.format(num_gpus))\n",
    "    job_name = args.job_name\n",
    "    print('job_name {}'.format(job_name))    \n",
    "    use_xla = args.use_xla\n",
    "    print('use_xla {}'.format(use_xla))    \n",
    "    use_amp = args.use_amp\n",
    "    print('use_amp {}'.format(use_amp))    \n",
    "    max_seq_length = args.max_seq_length\n",
    "    print('max_seq_length {}'.format(max_seq_length))    \n",
    "    train_batch_size = args.train_batch_size\n",
    "    print('train_batch_size {}'.format(train_batch_size))    \n",
    "    validation_batch_size = args.validation_batch_size\n",
    "    print('validation_batch_size {}'.format(validation_batch_size))    \n",
    "    test_batch_size = args.test_batch_size\n",
    "    print('test_batch_size {}'.format(test_batch_size))    \n",
    "    epochs = args.epochs\n",
    "    print('epochs {}'.format(epochs))    \n",
    "    learning_rate = args.learning_rate\n",
    "    print('learning_rate {}'.format(learning_rate))    \n",
    "    epsilon = args.epsilon\n",
    "    print('epsilon {}'.format(epsilon))    \n",
    "    train_steps_per_epoch = args.train_steps_per_epoch\n",
    "    print('train_steps_per_epoch {}'.format(train_steps_per_epoch))    \n",
    "    validation_steps = args.validation_steps\n",
    "    print('validation_steps {}'.format(validation_steps))    \n",
    "    test_steps = args.test_steps\n",
    "    print('test_steps {}'.format(test_steps))    \n",
    "    freeze_bert_layer = args.freeze_bert_layer\n",
    "    print('freeze_bert_layer {}'.format(freeze_bert_layer))    \n",
    "    enable_sagemaker_debugger = args.enable_sagemaker_debugger\n",
    "    print('enable_sagemaker_debugger {}'.format(enable_sagemaker_debugger))    \n",
    "    run_validation = args.run_validation\n",
    "    print('run_validation {}'.format(run_validation))    \n",
    "    run_test = args.run_test\n",
    "    print('run_test {}'.format(run_test))    \n",
    "    run_sample_predictions = args.run_sample_predictions\n",
    "    print('run_sample_predictions {}'.format(run_sample_predictions))\n",
    "    enable_tensorboard = args.enable_tensorboard\n",
    "    print('enable_tensorboard {}'.format(enable_tensorboard))       \n",
    "    enable_checkpointing = args.enable_checkpointing\n",
    "    print('enable_checkpointing {}'.format(enable_checkpointing))    \n",
    "    pipe_mode = args.pipe_mode\n",
    "    print('pipe_mode {}'.format(pipe_mode))\n",
    "    is_master = args.is_master\n",
    "    print('is_master {}'.format(is_master))\n",
    "\n",
    "    checkpoint_base_path = args.checkpoint_base_path\n",
    "    print('checkpoint_base_path {}'.format(checkpoint_base_path))\n",
    "\n",
    "    if is_master:\n",
    "        checkpoint_path = checkpoint_base_path\n",
    "    else:\n",
    "        checkpoint_path = '/tmp/checkpoints'        \n",
    "    print('checkpoint_path {}'.format(checkpoint_path))\n",
    "    \n",
    "    # Determine if PipeMode is enabled \n",
    "    pipe_mode_str = os.environ.get('SM_INPUT_DATA_CONFIG', '')\n",
    "    pipe_mode = (pipe_mode_str.find('Pipe') >= 0)\n",
    "    print('Using pipe_mode: {}'.format(pipe_mode))\n",
    " \n",
    "    # Model Output \n",
    "    transformer_fine_tuned_model_path = os.path.join(local_model_dir, 'transformers/fine-tuned/')\n",
    "    os.makedirs(transformer_fine_tuned_model_path, exist_ok=True)\n",
    "\n",
    "    # SavedModel Output\n",
    "    tensorflow_saved_model_path = os.path.join(local_model_dir, 'tensorflow/saved_model/0')\n",
    "    os.makedirs(tensorflow_saved_model_path, exist_ok=True)\n",
    "\n",
    "    # Tensorboard Logs \n",
    "    tensorboard_logs_path = os.path.join(local_model_dir, 'tensorboard/')\n",
    "    os.makedirs(tensorboard_logs_path, exist_ok=True)  \n",
    "    \n",
    "    distributed_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "    with distributed_strategy.scope():\n",
    "        tf.config.optimizer.set_jit(use_xla)\n",
    "        tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": use_amp})\n",
    "\n",
    "        train_data_filenames = glob(os.path.join(train_data, '*.tfrecord'))\n",
    "        print('train_data_filenames {}'.format(train_data_filenames))\n",
    "        train_dataset = file_based_input_dataset_builder(\n",
    "            channel='train',\n",
    "            input_filenames=train_data_filenames,\n",
    "            pipe_mode=pipe_mode,\n",
    "            is_training=True,\n",
    "            drop_remainder=False,\n",
    "            batch_size=train_batch_size,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=train_steps_per_epoch,\n",
    "            max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "\n",
    "        tokenizer = None\n",
    "        config = None\n",
    "        model = None\n",
    "\n",
    "        successful_download = False\n",
    "        retries = 0\n",
    "        while (retries < 5 and not successful_download):\n",
    "            try:\n",
    "                tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "                config = DistilBertConfig.from_pretrained('distilbert-base-uncased',\n",
    "                                                          num_labels=len(CLASSES))\n",
    "                model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',\n",
    "                                                                              config=config)\n",
    "                successful_download = True\n",
    "                print('Sucessfully downloaded after {} retries.'.format(retries))\n",
    "            except:\n",
    "                retries = retries + 1\n",
    "                random_sleep = random.randint(1, 30)\n",
    "                print('Retry #{}.  Sleeping for {} seconds'.format(retries, random_sleep))\n",
    "                time.sleep(random_sleep)\n",
    "\n",
    "        callbacks = []\n",
    "\n",
    "        initial_epoch_number = 0 \n",
    "\n",
    "        if enable_checkpointing:\n",
    "            print('***** Checkpoint enabled *****')\n",
    "            \n",
    "            os.makedirs(checkpoint_path, exist_ok=True)        \n",
    "            if os.listdir(checkpoint_path):\n",
    "                print('***** Found checkpoint *****')\n",
    "                print(checkpoint_path)\n",
    "                model, initial_epoch_number = load_checkpoint_model(checkpoint_path)\n",
    "                print('***** Using checkpoint model {} *****'.format(model))\n",
    "                \n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                    filepath=os.path.join(checkpoint_path, 'tf_model_{epoch:05d}.h5'),\n",
    "                    save_weights_only=False,\n",
    "                    verbose=1,\n",
    "                    monitor='val_accuracy')\n",
    "            print('*** CHECKPOINT CALLBACK {} ***'.format(checkpoint_callback))\n",
    "            callbacks.append(checkpoint_callback)\n",
    "\n",
    "        if not tokenizer or not model or not config:\n",
    "            print('Not properly initialized...')\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "        print('** use_amp {}'.format(use_amp))        \n",
    "        if use_amp:\n",
    "            # loss scaling is currently required when using mixed precision\n",
    "            optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, 'dynamic')\n",
    "\n",
    "        print('enable_sagemaker_debugger {}'.format(enable_sagemaker_debugger))\n",
    "        if enable_sagemaker_debugger:\n",
    "            print('*** DEBUGGING ***')\n",
    "            import smdebug.tensorflow as smd\n",
    "            # This assumes that we specified debugger_hook_config\n",
    "            debugger_callback = smd.KerasHook.create_from_json_file()\n",
    "            print('*** DEBUGGER CALLBACK {} ***'.format(debugger_callback))            \n",
    "            callbacks.append(debugger_callback)\n",
    "            optimizer = debugger_callback.wrap_optimizer(optimizer)\n",
    "\n",
    "        if enable_tensorboard:            \n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "                                                        log_dir=tensorboard_logs_path)\n",
    "            print('*** TENSORBOARD CALLBACK {} ***'.format(tensorboard_callback))\n",
    "            callbacks.append(tensorboard_callback)\n",
    "  \n",
    "        print('*** OPTIMIZER {} ***'.format(optimizer))\n",
    "        \n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "        print('Compiled model {}'.format(model))          \n",
    "        model.layers[0].trainable = not freeze_bert_layer\n",
    "        print(model.summary())\n",
    "\n",
    "        if run_validation:\n",
    "            validation_data_filenames = glob(os.path.join(validation_data, '*.tfrecord'))\n",
    "            print('validation_data_filenames {}'.format(validation_data_filenames))\n",
    "            validation_dataset = file_based_input_dataset_builder(\n",
    "                channel='validation',\n",
    "                input_filenames=validation_data_filenames,\n",
    "                pipe_mode=pipe_mode,\n",
    "                is_training=False,\n",
    "                drop_remainder=False,\n",
    "                batch_size=validation_batch_size,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=validation_steps,\n",
    "                max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "            \n",
    "            print('Starting Training and Validation...')\n",
    "            validation_dataset = validation_dataset.take(validation_steps)\n",
    "            train_and_validation_history = model.fit(train_dataset,\n",
    "                                                     shuffle=True,\n",
    "                                                     epochs=epochs,\n",
    "                                                     initial_epoch=initial_epoch_number,\n",
    "                                                     steps_per_epoch=train_steps_per_epoch,\n",
    "                                                     validation_data=validation_dataset,\n",
    "                                                     validation_steps=validation_steps,\n",
    "                                                     callbacks=callbacks)                                \n",
    "            print(train_and_validation_history)\n",
    "        else: # Not running validation\n",
    "            print('Starting Training (Without Validation)...')\n",
    "            train_history = model.fit(train_dataset,\n",
    "                                      shuffle=True,\n",
    "                                      epochs=epochs,\n",
    "                                      initial_epoch=initial_epoch_number,\n",
    "                                      steps_per_epoch=train_steps_per_epoch,\n",
    "                                      callbacks=callbacks)                \n",
    "            print(train_history)\n",
    "\n",
    "        if run_test:\n",
    "            test_data_filenames = glob(os.path.join(test_data, '*.tfrecord'))\n",
    "            print('test_data_filenames {}'.format(test_data_filenames))\n",
    "            test_dataset = file_based_input_dataset_builder(\n",
    "                channel='test',\n",
    "                input_filenames=test_data_filenames,\n",
    "                pipe_mode=pipe_mode,\n",
    "                is_training=False,\n",
    "                drop_remainder=False,\n",
    "                batch_size=test_batch_size,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=test_steps,\n",
    "                max_seq_length=max_seq_length).map(select_data_and_label_from_record)\n",
    "\n",
    "            print('Starting test...')\n",
    "            test_history = model.evaluate(test_dataset,\n",
    "                                          steps=test_steps,\n",
    "                                          callbacks=callbacks)\n",
    "                                 \n",
    "            print('Test history {}'.format(test_history))\n",
    "            \n",
    "        # Save the Fine-Tuned Transformers Model as a New \"Pre-Trained\" Model\n",
    "        print('transformer_fine_tuned_model_path {}'.format(transformer_fine_tuned_model_path))   \n",
    "        model.save_pretrained(transformer_fine_tuned_model_path)\n",
    "\n",
    "        # Save the TensorFlow SavedModel for Serving Predictions\n",
    "        print('tensorflow_saved_model_path {}'.format(tensorflow_saved_model_path))   \n",
    "        model.save(tensorflow_saved_model_path, save_format='tf')\n",
    "                \n",
    "        # Copy inference.py and requirements.txt to the code/ directory\n",
    "        #   Note: This is required for the SageMaker Endpoint to pick them up.\n",
    "        #         This appears to be hard-coded and must be called code/\n",
    "        inference_path = os.path.join(local_model_dir, 'code/')\n",
    "        # print('Copying inference source files to {}'.format(inference_path))\n",
    "        os.makedirs(inference_path, exist_ok=True)               \n",
    "        os.system('cp inference.py {}'.format(inference_path))\n",
    "        print(glob(inference_path))        \n",
    "#        os.system('cp requirements.txt {}/code'.format(inference_path))\n",
    "        \n",
    "    if run_sample_predictions:\n",
    "        loaded_model = TFDistilBertForSequenceClassification.from_pretrained(transformer_fine_tuned_model_path,\n",
    "                                                                       id2label={\n",
    "                                                                        0: 1,\n",
    "                                                                        1: 2,\n",
    "                                                                        2: 3,\n",
    "                                                                        3: 4,\n",
    "                                                                        4: 5\n",
    "                                                                       },\n",
    "                                                                       label2id={\n",
    "                                                                        1: 0,\n",
    "                                                                        2: 1,\n",
    "                                                                        3: 2,\n",
    "                                                                        4: 3,\n",
    "                                                                        5: 4\n",
    "                                                                       })\n",
    "\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "        if num_gpus >= 1:\n",
    "            inference_device = 0 # GPU 0\n",
    "        else:\n",
    "            inference_device = -1 # CPU\n",
    "        print('inference_device {}'.format(inference_device))\n",
    "\n",
    "        inference_pipeline = TextClassificationPipeline(model=loaded_model, \n",
    "                                                        tokenizer=tokenizer,\n",
    "                                                        framework='tf',\n",
    "                                                        device=inference_device)  \n",
    "\n",
    "        print(\"\"\"I loved it!  I will recommend this to everyone.\"\"\", inference_pipeline(\"\"\"I loved it!  I will recommend this to everyone.\"\"\"))\n",
    "        print(\"\"\"It's OK.\"\"\", inference_pipeline(\"\"\"It's OK.\"\"\"))\n",
    "        print(\"\"\"Really bad.  I hope they don't make this anymore.\"\"\", inference_pipeline(\"\"\"Really bad.  I hope they don't make this anymore.\"\"\"))\n",
    "\n",
    "        import csv\n",
    "\n",
    "        df_test_reviews = pd.read_csv('./test_data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz', \n",
    "                                        delimiter='\\t', \n",
    "                                        quoting=csv.QUOTE_NONE,\n",
    "                                        compression='gzip')[['review_body', 'star_rating']]\n",
    "\n",
    "        df_test_reviews = df_test_reviews.sample(n=100)\n",
    "        df_test_reviews.shape\n",
    "        df_test_reviews.head()\n",
    "        \n",
    "        import pandas as pd\n",
    "\n",
    "        def predict(review_body):\n",
    "            prediction_map = inference_pipeline(review_body)\n",
    "            return prediction_map[0]['label']\n",
    "\n",
    "        y_test = df_test_reviews['review_body'].map(predict)\n",
    "        y_test\n",
    "        \n",
    "        y_actual = df_test_reviews['star_rating']\n",
    "        y_actual\n",
    "\n",
    "        from sklearn.metrics import classification_report\n",
    "        print(classification_report(y_true=y_test, y_pred=y_actual))\n",
    "        \n",
    "        from sklearn.metrics import accuracy_score\n",
    "        print('Accuracy: ', accuracy_score(y_true=y_test, y_pred=y_actual))\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        import pandas as pd\n",
    "\n",
    "        def plot_conf_mat(cm, classes, title, cmap = plt.cm.Greens):\n",
    "            print(cm)\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "            plt.title(title)\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            plt.xticks(tick_marks, classes, rotation=45)\n",
    "            plt.yticks(tick_marks, classes)\n",
    "\n",
    "            fmt = 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"black\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.ylabel('True label')\n",
    "                plt.xlabel('Predicted label')\n",
    "                \n",
    "        import itertools\n",
    "        import numpy as np\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        import matplotlib.pyplot as plt\n",
    "        #%matplotlib inline\n",
    "        #%config InlineBackend.figure_format='retina'\n",
    "\n",
    "        cm = confusion_matrix(y_true=y_test, y_pred=y_actual)\n",
    "\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots(figsize=(10,5))\n",
    "        plot_conf_mat(cm, \n",
    "                      classes=['1', '2', '3', '4', '5'], \n",
    "                      title='Confusion Matrix')\n",
    "\n",
    "        # Save the confusion matrix        \n",
    "        plt.show()\n",
    "        \n",
    "        # Model Output \n",
    "        metrics_path = os.path.join(local_model_dir, 'metrics/')\n",
    "        os.makedirs(metrics_path, exist_ok=True)\n",
    "        plt.savefig('{}/confusion_matrix.png'.format(metrics_path))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
