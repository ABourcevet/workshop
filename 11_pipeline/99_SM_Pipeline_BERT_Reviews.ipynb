{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orchestrating Jobs, Model Registration, Continuous Deployment, and Lineage Tracking with Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker offers Machine Learning application developers and Machine Learning operations engineers the ability to orchestrate SageMaker jobs and author reproducible Machine Learning pipelines, deploy custom-build models for inference in real-time with low latency or offline inferences with Batch Transform, and track lineage of artifacts. You can institute sound operational practices in deploying and monitoring production workflows, deployment of model artifacts, and track artifact lineage through a simple interface, adhering to safety and best-practice paradigmsfor Machine Learning application development.\n",
    "\n",
    "The SageMaker Workflow service supports a SageMaker Machine Learning Pipeline Domain Specific Language (DSL), which is a declarative Json specification. This DSL defines a Directed Acyclic Graph (DAG) of pipeline parameters and SageMaker job steps. The SageMaker Python Software Developer Kit (SDK) streamlines the generation of the pipeline DSL using constructs that are already familiar to engineers and scientists alike.\n",
    "\n",
    "The SageMaker Model Registry is where trained models are stored, versioned, and managed. Data Scientists and Machine Learning Engineers can compare model versions, approve models for deployment, and deploy models from different AWS accounts, all from a single Model Registry. SageMaker enables customers to follow the best practices with ML Ops and getting started right. Customers are able to standup a full ML Ops end-to-end system with a single API call.\n",
    "\n",
    "And the SageMaker Lineage service makes it easy to track all the artifacts created in a SageMaker Machine Learning Pipeline from start to finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelines support the following:\n",
    "\n",
    "* Pipelines - A Directed Acyclic Graph of steps and conditions to orchestrate SageMaker jobs and resource creation.\n",
    "* Processing Job steps - A simplified, managed experience on SageMaker to run data processing workloads, such as feature engineering, data validation, model evaluation, and model interpretation.\n",
    "* Training Job steps - An iterative process that teaches a model to make predictions by presenting examples from a training dataset.\n",
    "* Conditional step execution - Provides conditional execution of branches in a pipeline.\n",
    "* Registering Models - Creates a model package resource in the Model Registry that can be used to create deployable models in Amazon SageMaker.\n",
    "* Parametrized Pipeline executions - Allows pipeline executions to vary by supplied parameters.\n",
    "* Transform Job steps - A batch transform to preprocess datasets to remove noise or bias that interferes with training or inference from your dataset, get inferences from large datasets, and run inference when you don't need a persistent endpoint.\n",
    "\n",
    "## SageMaker Model Registry\n",
    "\n",
    "Amazon SageMaker Model Registry supports the following:\n",
    "\n",
    "* Catalog models after the training step - data scientists run tens to thousands of experiments and may select a small set of models as candidates for production.\n",
    "* Manage model versions - data scientists can register new models which will be automatically versioned in the model registry.\n",
    "* Compare models - data scientists can run model evaluation steps in Tioga pipeline and generate model metrics (e.g. accuracy metrics and bias metrics) which are recorded in the Model Registry and can be used to compare model versions.\n",
    "* Approve models - data scientists can mark model versions as “approved” or “rejected”. Alternately, the Tioga pipeline can also automate the model approvals. If there is a deployment pipeline associated with a Model and a live endpoint, then the model version is propagated in production. Currently SageMaker supports a Blue/ Green update, but as part of Yosemite, we are adding support for Canary and Rolling deployments also.\n",
    "* Deploy models in different AWS accounts - models in the Model Registry support resource sharing across accounts which enables models built in data scientist accounts to be deployed in different pre-production and production accounts.\n",
    "\n",
    "## SageMaker Lineage\n",
    "\n",
    "Amazon SageMaker Lineage supports the following:\n",
    "\n",
    "* Automatically tracks all the artifacts created in a machine learning workflow from start to finish.  Modeled as a directed graph like structure.\n",
    "* Explore the lineage artifacts with easy to use SDK methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook shows how to:\n",
    "\n",
    "### SageMaker Workflows\n",
    "\n",
    "* Define a set of Workflow Parameters that can be used to parametrize a Workflow Pipeline\n",
    "* Define a Processing step that performs cleaning and feature engineering, splitting the input data into train and test data sets\n",
    "* Define a Training step that trains a model on the pre-processed train data set\n",
    "* Define a Processing step that evaluates the trained model's performance on the test data set\n",
    "* Define a Register Model step that creates a model package from the estimator and model artifacts used in training\n",
    "* Define a Conditional step that measures a condition based on output from prior steps and conditionally executes the Register Model step\n",
    "* Define and create a Pipeline in a Workflow DAG, with the defined parameters and steps defined\n",
    "* Start a Pipeline execution and wait for execution to complete\n",
    "* Download from S3 the model evaluation report for examination\n",
    "* Start a second Pipeline execution\n",
    "\n",
    "### SageMaker Model Registry\n",
    "\n",
    "* Create a SageMaker Project based on the Model Package Group name from the pipeline execution defined before\n",
    "* Observe CI/CD code pipeline on subsequent successful executions of the pipeline and the registration of a new Model Package version.\n",
    "\n",
    "### SageMaker Lineage\n",
    "\n",
    "Amazon SageMaker Lineage supports the following:\n",
    "\n",
    "* Provide the inputs and outputs of SageMaker job artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up admin permissions\n",
    "\n",
    "Please be sure that you've run the `scripts/admin-setup.sh` script that was in the distribution bundle. This script should be runoutside of your notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your execution role\n",
    "\n",
    "The following information shows how to ensure the execution role you are using in your notebook has the authority to:\n",
    "\n",
    "* Read and write to Amazon S3\n",
    "* Create Training and Processing jobs and create Model Packages in SageMaker\n",
    "* Get and pass its own role\n",
    "* Trust the SageMaker workflow service principal\n",
    "\n",
    "\n",
    "1. Ensure the account you are using has been whitelisted for the SageMaker Workflows Private Beta.\n",
    "\n",
    "2. Set up your notebook instance as outlined in [Create a notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html). This gives your role permissions to read and write to Amazon S3, and create Training and Processing jobs in SageMaker.\n",
    "\n",
    "3. To grant your notebook permissions to get and pass its own role, follow the steps in [Modifying a role permissions policy](https://docs.aws.amazon.com/IAM/latest/UserGuide/roles-managingrole-editing-console.html#roles-modify_permissions-policy). Add the following JSON snippet to attach this policy to your role:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:GetRole\",\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"<your-role-arn>\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "4. To trust the SageMaker workflow service principal, follow the steps in [Modifying a role trust policy](https://docs.aws.amazon.com/IAM/latest/UserGuide/roles-managingrole-editing-cli.html#roles-managingrole_edit-trust-policy-cli) and add the following statement fragment to the trust relationship of your role:\n",
    "\n",
    "```\n",
    "    {\n",
    "      \"Sid\": \"\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"sagemaker.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    },\n",
    "    {\n",
    "      \"Sid\": \"\",\n",
    "      \"Effect\": \"Allow\",\n",
    "      \"Principal\": {\n",
    "        \"Service\": \"us-east-2.tioga.im.amazonaws.com\"\n",
    "      },\n",
    "      \"Action\": \"sts:AssumeRole\"\n",
    "    },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your environment\n",
    "\n",
    "Ensure that the SageMaker Python SDK Build Distribution (`sagemaker-2.X.Y.devZ.tar.gz`) has been uploaded to your notebook environment and resides in the same directory as your notebook.\n",
    "\n",
    "The following cell verifies that the `sagemaker` package contains the workflow artifacts, and, if not present (or installation should be forced) installs it and one other package via `pip`. It then restarts your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# import IPython\n",
    "# import sagemaker\n",
    "\n",
    "\n",
    "# dist_version = \"2.16.2.dev0\"\n",
    "# needs_install, force_install = False, False\n",
    "# try:\n",
    "#     import sagemaker.workflow\n",
    "    \n",
    "#     needs_install = (\n",
    "#         \"properties\" not in dir(sagemaker.workflow)\n",
    "#         or sagemaker.__version__ < dist_version\n",
    "#     )\n",
    "# except:\n",
    "#     needs_install = True\n",
    "\n",
    "\n",
    "# if needs_install or force_install:\n",
    "#     print(\"installing deps and restarting kernel\")\n",
    "#     !{sys.executable} -m pip install -q -U pip\n",
    "#     !{sys.executable} -m pip install -q sagemaker-{dist_version}.tar.gz\n",
    "\n",
    "#     IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required modules\n",
    "\n",
    "Also, ensure that all the new functionality and APIs are available by adding the new boto models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xzvf boto-models.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws configure add-model --service-model file://./boto-models/sagemaker-2017-07-24.normal.json --service-name sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A SageMaker Workflow\n",
    "\n",
    "The pipeline that we create follows a typical Machine Learning Application pattern of pre-processing, training, evaluation, and model registration:\n",
    "\n",
    "![A typical ML Application pipeline](img/pipeline-full.png)\n",
    "\n",
    "### Create SageMaker Clients and Session\n",
    "\n",
    "First, we create a new SageMaker Session in the `us-east-2` region. We also acquire the role arn for the session.\n",
    "\n",
    "This role arn should be the execution role arn that you set up in the Prerequisites section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/.cache/pip/wheels/07/73/d0/992360a44c5f1bd95028209d2121ad15d67e65232128db013c/sagemaker-2.16.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (0.1.5)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (19.3.0)\n",
      "Requirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (3.13.0)\n",
      "Requirement already satisfied: boto3>=1.16.27 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (1.16.33)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (1.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (20.1)\n",
      "Collecting smdebug-rulesconfig==0.1.5\n",
      "  Using cached smdebug_rulesconfig-0.1.5-py2.py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker==2.16.4) (1.19.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker==2.16.4) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.1->sagemaker==2.16.4) (45.2.0.post20200210)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.33 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker==2.16.4) (1.19.33)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker==2.16.4) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.16.27->sagemaker==2.16.4) (0.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.4.0->sagemaker==2.16.4) (2.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker==2.16.4) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.33->boto3>=1.16.27->sagemaker==2.16.4) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /opt/conda/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.33->boto3>=1.16.27->sagemaker==2.16.4) (1.25.8)\n",
      "Installing collected packages: smdebug-rulesconfig, sagemaker\n",
      "  Attempting uninstall: smdebug-rulesconfig\n",
      "    Found existing installation: smdebug-rulesconfig 1.0.0\n",
      "    Uninstalling smdebug-rulesconfig-1.0.0:\n",
      "      Successfully uninstalled smdebug-rulesconfig-1.0.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.19.0\n",
      "    Uninstalling sagemaker-2.19.0:\n",
      "      Successfully uninstalled sagemaker-2.19.0\n",
      "Successfully installed sagemaker-2.16.4 smdebug-rulesconfig-0.1.5\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker==2.16.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import boto3\n",
    "#import sagemaker\n",
    "#import sagemaker.session\n",
    "\n",
    "#region = \"us-east-2\"\n",
    "#boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "#sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "#runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "# sagemaker_session = sagemaker.session.Session(\n",
    "#     boto_session=boto_session,\n",
    "#     sagemaker_client=sagemaker_client,\n",
    "#     sagemaker_runtime_client=runtime_client,\n",
    "# )\n",
    "#role = sagemaker.session.get_execution_role(sagemaker_session)\n",
    "#print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = str(int(time.time() * 10**7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used is the [UCI Machine Learning Abalone Dataset](https://archive.ics.uci.edu/ml/datasets/abalone). The aim for this task is to determine the age of an abalone (a kind of shellfish) from its physical measurements. At the core, it's a regression problem. \n",
    "    \n",
    "The dataset contains several features - length (longest shell measurement), diameter (diameter perpendicular to length), height (height with meat in the shell), whole_weight (weight of whole abalone), shucked_weight (weight of meat), viscera_weight (gut weight after bleeding), shell_weight (weight after being dried), sex ('M', 'F', 'I' where 'I' is Infant), as well as rings (integer).\n",
    "\n",
    "The number of rings turns out to be a good approximation for age (age is rings + 1.5). However, to obtain this number requires cutting the shell through the cone, staining the section, and counting the number of rings through a microscope -- a time-consuming task. However, the other physical measurements are easier to determine. We use the dataset to build a predictive model of the variable rings through these other physical measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data_url = \"https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/abalone/abalone.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=64\n",
    "train_split_percentage=0.90\n",
    "validation_split_percentage=0.05\n",
    "test_split_percentage=0.05\n",
    "balance_dataset=True\n",
    "processing_instance_count=1\n",
    "processing_instance_type='ml.c5.2xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the Raw Inputs S3 Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-806570384721/amazon-reviews-pds/tsv/\n"
     ]
    }
   ],
   "source": [
    "raw_input_data_s3_uri = 's3://{}/amazon-reviews-pds/tsv/'.format(bucket)\n",
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-17 16:14:37   18997559 amazon_reviews_us_Digital_Software_v1_00.tsv.gz\n",
      "2020-11-17 16:14:39   27442648 amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters to Parametrize Pipeline Execution\n",
    "\n",
    "We define Workflow Parameters by which we can parametrize our Pipeline and vary the values injected and used in Pipeline executions and schedules without having to modify the Pipeline definition.\n",
    "\n",
    "The supported parameter types include:\n",
    "\n",
    "* `ParameterString` - representing a `str` Python type\n",
    "* `ParameterInteger` - representing an `int` Python type\n",
    "* `ParameterFloat` - representing a `float` Python type\n",
    "\n",
    "These parameters support providing a default value, which can be overridden on pipeline execution. The default value specified should be an instance of the type of the parameter.\n",
    "\n",
    "The parameters defined in this workflow below include:\n",
    "\n",
    "* `processing_instance_type` - The `ml.*` instance type of the processing job.\n",
    "* `processing_instance_count` - The instance count of the processing job. For illustrative purposes only: 1 is the only value that makes sense here.\n",
    "* `training_instance_type` - The `ml.*` instance type of the training job.\n",
    "* `model_approval_status` - What approval status to register the trained model with for CI/CD purposes. Defaults to \"PendingManualApproval\". (NOTE: not available in service yet)\n",
    "* `input_data` - The URL location of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:  Add this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.parameters import (\n",
    "#     ParameterInteger,\n",
    "#     ParameterString,\n",
    "# )\n",
    "\n",
    "# processing_instance_count = ParameterInteger(\n",
    "#     name=\"ProcessingInstanceCount\",\n",
    "#     default_value=1\n",
    "# )\n",
    "# processing_instance_type = ParameterString(\n",
    "#     name=\"ProcessingInstanceType\",\n",
    "#     default_value=\"ml.m5.xlarge\"\n",
    "# )\n",
    "# training_instance_type = ParameterString(\n",
    "#     name=\"TrainingInstanceType\",\n",
    "#     default_value=\"ml.m5.xlarge\"\n",
    "# )\n",
    "# model_approval_status = ParameterString(\n",
    "#     name=\"ModelApprovalStatus\",\n",
    "#     default_value=\"PendingManualApproval\"\n",
    "# )\n",
    "# input_data = ParameterString(\n",
    "#     name=\"InputData\",\n",
    "#     default_value=input_data_url,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define Parameters](img/pipeline-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Processing Step for Feature Engineering\n",
    "\n",
    "First, we develop a pre-processing script that will be specified in the Processing step.\n",
    "\n",
    "This notebook cell writes a file `preprocessing_abalone.py`, which contains the pre-processing script. You can update the script, and rerun this cell to overwrite. Our pre-processing script uses `scikit-learn` to:\n",
    "\n",
    "* fills in missing sex categorical data and encodes it so that it is suitable for training\n",
    "* scales and normalizes all numerical fields aside from sex and rings numerical data (all but sex and rings)\n",
    "* split the data into training, validation, and test datasets\n",
    "\n",
    "The Processing step will execute this script on the input data. The Training step will use the pre-processed training features and labels to train a model, and our Evaluation step will use the trained model and pre-processed test features and labels to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an instance of an `SKLearnProcessor` processor and we use that in our `ProcessingStep`.\n",
    "\n",
    "We also specify the `framework_version` we will use throughout.\n",
    "\n",
    "Note the `processing_instance_type` and `processing_instance_count` parameters that used by the processor instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# framework_version = \"0.23-1\"\n",
    "\n",
    "# sklearn_processor = SKLearnProcessor(\n",
    "#     framework_version=framework_version,\n",
    "#     instance_type=processing_instance_type,\n",
    "#     instance_count=processing_instance_count,\n",
    "#     base_job_name=\"sklearn-abalone-process\",\n",
    "#     sagemaker_session=sess,\n",
    "#     role=role,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                             role=role,\n",
    "                             instance_type=processing_instance_type,\n",
    "                             instance_count=processing_instance_count,\n",
    "                             max_runtime_in_seconds=7200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "# from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "# step_process = ProcessingStep(\n",
    "#     name=\"Processor\",\n",
    "#     processor=processor,\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "#         ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "#         ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\")\n",
    "#     ],\n",
    "#     code=\"preprocessing.py\",\n",
    "#     job_arguments=[\"--input-data-url\", input_data_url]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'yosemite-pipeline-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Processing', step_type=<StepTypeEnum.PROCESSING: 'Processing'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processing_inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name='raw_input',\n",
    "            source=raw_input_data_s3_uri,\n",
    "            destination='/opt/ml/processing/input/data/',\n",
    "            s3_data_distribution_type='ShardedByS3Key'\n",
    "        ),\n",
    "#         ProcessingInput(\n",
    "#             input_name='code',            \n",
    "#             source=input_code,\n",
    "#             destination='/opt/ml/processing/input/code',\n",
    "#         )\n",
    "]\n",
    "\n",
    "#processed_train_data_s3_uri = 's3://{}/{}/processing/output/bert-train'.format(bucket, pipeline_name)        \n",
    "#processed_validation_data_s3_uri = 's3://{}/{}/processing/output/bert-validation'.format(bucket, pipeline_name)        \n",
    "#processed_test_data_s3_uri = 's3://{}/{}/processing/output/bert-test'.format(bucket, pipeline_name)\n",
    "\n",
    "processing_outputs=[\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-train',\n",
    "                         source='/opt/ml/processing/output/bert/train',\n",
    "#                         destination=processed_train_data_s3_uri\n",
    "                        ),\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-validation',\n",
    "                         source='/opt/ml/processing/output/bert/validation',\n",
    "#                         destination=processed_validation_data_s3_uri\n",
    "                        ),\n",
    "        ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                         output_name='bert-test',\n",
    "                         source='/opt/ml/processing/output/bert/test',\n",
    "#                         destination=processed_test_data_s3_uri\n",
    "                        ),\n",
    "]        \n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Processing', \n",
    "    processor=processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    # experiment_config=experiment_config,\n",
    "    job_arguments=['--train-split-percentage', str(train_split_percentage),\n",
    "                   '--validation-split-percentage', str(validation_split_percentage),\n",
    "                   '--test-split-percentage', str(test_split_percentage),\n",
    "                   '--max-seq-length', str(max_seq_length),\n",
    "                   '--balance-dataset', str(balance_dataset)],\n",
    "    code='preprocess-scikit-text-to-bert.py',    \n",
    "#    container_entrypoint=['python3', '/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py'],\n",
    ")        \n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Processing Step for Feature Engineering](img/pipeline-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "Note the `input_data` parameters passed into `ProcessingStep` as the input data of the step itself. This input data will be used by the processor instance when it is run.\n",
    "\n",
    "Also, take note the `\"train_data\"` and `\"test_data\"` named channels specified in the output configuration for the processing job. Such step `Properties` can be used in subsequent steps and will resolve to their runtime values at execution. In particular, we'll call out this usage when we define our training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize src/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Hyper-Parameters\n",
    "Note that `max_seq_length` is re-used from the processing hyper-parameters above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3\n",
    "learning_rate=0.00001\n",
    "epsilon=0.00000001\n",
    "train_batch_size=128\n",
    "validation_batch_size=128\n",
    "test_batch_size=128\n",
    "train_steps_per_epoch=100\n",
    "validation_steps=100\n",
    "test_steps=100\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=1024\n",
    "use_xla=True\n",
    "use_amp=True\n",
    "freeze_bert_layer=False\n",
    "enable_sagemaker_debugger=False\n",
    "enable_checkpointing=False\n",
    "enable_tensorboard=False\n",
    "input_mode='Pipe'\n",
    "run_validation=True\n",
    "run_test=True\n",
    "run_sample_predictions=True\n",
    "deploy_instance_count=1\n",
    "deploy_instance_type='ml.m5.4xlarge'\n",
    "# deploy_instance_type='ml.m5.large' # bur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Metrics To Track Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "     {'Name': 'train:loss', 'Regex': 'loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'train:accuracy', 'Regex': 'accuracy: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9\\\\.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_accuracy: ([0-9\\\\.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Training Step to Train a Model\n",
    "\n",
    "Here, we use Amazon SageMaker's [XGBoost Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) to train on this dataset. We configure an Estimator for the XGBoost algorithm and the input dataset. A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later.\n",
    "\n",
    "We also specify the model path where the models from training will be saved.\n",
    "\n",
    "Note the `training_instance_type` parameter passed may be also used and passed into other places in the pipeline. In this case, the `training_instance_type` is passed into the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.estimator import Estimator\n",
    "\n",
    "# model_path = f\"s3://{sess.default_bucket()}/{pipeline_name}\")\n",
    "\n",
    "# image_uri = sagemaker.image_uris.retrieve(\n",
    "#     framework=\"xgboost\",\n",
    "#     region=region,\n",
    "#     version=\"1.0-1\",\n",
    "#     py_version=\"py3\",\n",
    "#     instance_type=training_instance_type,\n",
    "# )\n",
    "\n",
    "# xgb_train = Estimator(\n",
    "#     image_uri=image_uri,\n",
    "#     instance_type=training_instance_type,\n",
    "#     instance_count=1,\n",
    "#     output_path=model_path,\n",
    "#     sagemaker_session=sess,\n",
    "#     role=role,\n",
    "# )\n",
    "# xgb_train.set_hyperparameters(\n",
    "#     objective=\"reg:linear\",\n",
    "#     num_round=50,\n",
    "#     max_depth=5,\n",
    "#     eta=0.2,\n",
    "#     gamma=4,\n",
    "#     min_child_weight=6,\n",
    "#     subsample=0.7,\n",
    "#     silent=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-train-2020-12-13-20-36-53-532\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "training_job_name = name_from_base('bert-train')\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-806570384721/bert-train-2020-12-13-20-36-53-532/model\n"
     ]
    }
   ],
   "source": [
    "model_path = 's3://{}/{}/model'.format(bucket,training_job_name)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1.0-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    image_scope=\"training\"\n",
    ")\n",
    "print(image_uri)\n",
    "\n",
    "estimator = TensorFlow(entry_point='tf_bert_reviews.py',\n",
    "                       source_dir='src',\n",
    "                       role=role,\n",
    "                       output_path=model_path,\n",
    "                       base_job_name=training_job_name,\n",
    "                       instance_count=train_instance_count, # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "                       instance_type=train_instance_type,\n",
    "                       volume_size=train_volume_size,                       \n",
    "                       image_uri=image_uri,\n",
    "#                       py_version='py3',\n",
    "#                       framework_version='2.1.0',\n",
    "                       hyperparameters={'epochs': epochs,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'epsilon': epsilon,\n",
    "                                        'train_batch_size': train_batch_size,\n",
    "                                        'validation_batch_size': validation_batch_size,\n",
    "                                        'test_batch_size': test_batch_size,                                             \n",
    "                                        'train_steps_per_epoch': train_steps_per_epoch,\n",
    "                                        'validation_steps': validation_steps,\n",
    "                                        'test_steps': test_steps,\n",
    "                                        'use_xla': use_xla,\n",
    "                                        'use_amp': use_amp,                                             \n",
    "                                        'max_seq_length': max_seq_length,\n",
    "                                        'freeze_bert_layer': freeze_bert_layer,\n",
    "                                        'enable_sagemaker_debugger': enable_sagemaker_debugger,\n",
    "                                        'enable_checkpointing': enable_checkpointing,\n",
    "                                        'enable_tensorboard': enable_tensorboard,                                        \n",
    "                                        'run_validation': run_validation,\n",
    "                                        'run_test': run_test,\n",
    "                                        'run_sample_predictions': run_sample_predictions},\n",
    "                       input_mode=input_mode,\n",
    "                       metric_definitions=metrics_definitions,\n",
    "#                       max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the estimator instance to construct a `TrainingStep` as well as the `Properties` of the prior `ProcessingStep` used as input in the `TrainingStep` inputs and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to an estimator's `fit` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3Uri` of the `\"train_data\"` output channel to the `TrainingStep`. We will also use the other `\"test_data\"` output channel for model evaluation in the pipeline. The `properties` attribute of a Workflow step match the object model of the corresponding response of a describe call. These properties can be referenced as placeholder values and are resolved, or filled in, at runtime. For example, the `ProcessingStep` `properties` attribute matches the object model of the [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', step_type=<StepTypeEnum.TRAINING: 'Training'>)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name=\"Train\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"bert-test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\"\n",
    "        )        \n",
    "    },\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Training Step to Train a Model](img/pipeline-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, we develop an evaluation script that will be specified in a Processing step that will perform the model evaluation.\n",
    "\n",
    "The evaluation script `evaluation.py` takes the trained model and the test dataset as input, and produces a JSON file containing classification evaluation metrics, including precision, recall, and F1 score for each label, and accuracy and ROC AUC for the model.\n",
    "\n",
    "After pipeline execution, we will examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script uses `xgboost` to:\n",
    "\n",
    "* load in the model\n",
    "* read in the test data\n",
    "* issue a bunch o' predictions against the test data\n",
    "* build a classification report, including accuracy and roc\n",
    "* save the evaluation report to the evaluation directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an instance of a `ScriptProcessor` processor and we use that in our `ProcessingStep`.\n",
    "\n",
    "Note the `processing_instance_type` parameter passed into the processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "# script_eval = ScriptProcessor(\n",
    "#     image_uri=image_uri,\n",
    "#     command=[\"python3\"],\n",
    "#     instance_type=processing_instance_type,\n",
    "#     instance_count=1,\n",
    "#     base_job_name=\"script-abalone-eval\",\n",
    "#     sagemaker_session=sess,\n",
    "#     role=role,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the processor instance to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. This is very similar to a processor instance's `run` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties as well as the `S3Uri` of the `\"test_data\"` output channel of the first `ProcessingStep`, `step_process`.\n",
    "\n",
    "The `TrainingStep` and `ProcessingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) and  [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "# # NOTE:\n",
    "# # property files cause deserialization failure on listing pipeline executions\n",
    "# # therefore jsonget and robust conditions won't work\n",
    "# evaluation_report = PropertyFile(\n",
    "#     name=\"EvaluationReport\",\n",
    "#     output_name=\"evaluation\",\n",
    "#     path=\"evaluation.json\"\n",
    "# )\n",
    "# step_eval = ProcessingStep(\n",
    "#     name=\"AbaloneEval\",\n",
    "#     processor=script_eval,\n",
    "#     inputs=[\n",
    "#         ProcessingInput(\n",
    "#             source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "#             destination=\"/opt/ml/processing/model\"\n",
    "#         ),\n",
    "#         ProcessingInput(\n",
    "#             source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#                 \"test\"\n",
    "#             ].S3Output.S3Uri,\n",
    "#             destination=\"/opt/ml/processing/test\"\n",
    "#         )\n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "#     ],\n",
    "#     code=\"evaluation.py\",\n",
    "#     # property_files=[evaluation_report],  # these cause deserialization issues\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Model Evaluation Step to Evaluate the Trained Model](img/pipeline-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Register Model Step to Create a Model Package\n",
    "\n",
    "We use the estimator instance that was used for the training step to construct an instance of `RegisterModel`. The result of executing `RegisterModel` in a pipeline is a Model Package. A Model Package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. Primarily, it consists of an inference specification that defines the inference image to use along with an optional model weights location.\n",
    "\n",
    "A Model Package Group is a collection of Model Packages. You can create a Model Package Group for a specific ML business problem, and you can keep adding versions/model packages into it. Typically, we expect customers to create a ModelPackageGroup for a SageMaker Workflow Pipeline so that they can keep adding versions/model packages to the group for every Workflow Pipeline run.\n",
    "\n",
    "The construction of `RegisterModel` is very similar to an estimator instance's `register` method, for those familiar with the existing Python SDK.\n",
    "\n",
    "In particular, we pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object.\n",
    "\n",
    "Of note, we provided a specific model package group name which we will use in the Model Registry and CI/CD work later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-Reviews-16078916928983064\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"BERT-Reviews-{timestamp}\"\n",
    "\n",
    "# # NOTE: in the future, the model package group will be created automatically if it doesn't exist\n",
    "sm.create_model_package_group(\n",
    "    ModelPackageGroupName=model_package_group_name,\n",
    "    ModelPackageGroupDescription=\"BERT-Reviews\",\n",
    ")\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1.0-cpu\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.1.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    image_scope=\"inference\"\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# NOTE: model_approval_status is not available as arg in service dsl currently\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=estimator,\n",
    "    image_uri=inference_image_uri, # we have to specify, by default it's using training image\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.4xlarge\"],\n",
    "    transform_instances=[\"ml.c5.18xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    # model_approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Condition Step to Check Accuracy and Conditionally Register Model\n",
    "\n",
    "Finally, we'd like to only register this model if the accuracy of the model, as determined by our evaluation step `step_eval`, exceeded some value. A `ConditionStep` allows for pipelines to support conditional execution in the pipeline DAG based on conditions of step properties. \n",
    "\n",
    "Below, we:\n",
    "\n",
    "* define a `ConditionGreaterThan` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* use the condition in the list of conditions in a `ConditionStep`\n",
    "* pass the `RegisterModel` step collection into the `if_steps` of the `ConditionStep`\n",
    "* use the `FailStep` in the `else_steps` of the `ConditionStep` to fail the pipeline if the accuracy condition was not met\n",
    "\n",
    "NOTE: there are a few things that are planned to be implemented in the Workflow service that are currently unavailable to us:\n",
    "\n",
    "* JsonGet - a function to allow getting json files from S3 and using their values in conditions\n",
    "* FailStep - a step that terminates the pipeline in failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.conditions import (\n",
    "#     ConditionEquals,\n",
    "#     ConditionLessThanOrEqualTo,\n",
    "# )\n",
    "# from sagemaker.workflow.condition_step import (\n",
    "#     ConditionStep,\n",
    "#     JsonGet,\n",
    "# )\n",
    "# from sagemaker.workflow.steps import FailStep\n",
    "\n",
    "\n",
    "# # NOTE:\n",
    "# # This is not an ideal condition, but processing jobs have no dynamic properties, as-is\n",
    "# cond_equals = ConditionEquals(\n",
    "#     left=step_eval.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "#     right=step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"],\n",
    "# )\n",
    "\n",
    "# # NOTE:\n",
    "# # Ideally, we would use JsonGet to get the mean squared error from the evaluation report\n",
    "# # This is what a non-trivial condition looks like for a processing job\n",
    "# #\n",
    "# # NOTE:\n",
    "# # jsonpaths only support single characters in the service\n",
    "# cond_lte = ConditionLessThanOrEqualTo(\n",
    "#     left=JsonGet(\n",
    "#         step=step_eval,\n",
    "#         property_file=evaluation_report,\n",
    "#         json_path=\"m\"\n",
    "#     ),\n",
    "#     right=\"5.0\"\n",
    "# )\n",
    "\n",
    "# # NOTE: \n",
    "# # we forego the cond_lte and use the cond_equals as jsonget/propertyfiles don't work quite\n",
    "# # right in service/can't be listed\n",
    "# #\n",
    "# # NOTE:\n",
    "# # FailStep not available in the service yet\n",
    "# step_cond = ConditionStep(\n",
    "#     name=\"AbaloneMSECond\",\n",
    "#     conditions=[cond_equals],  # cond_lte],\n",
    "#     if_steps=[step_register],\n",
    "#     else_steps=[],  # [FailStep()]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Condition Step to Check Accuracy and Conditionally Register Model](img/pipeline-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Pipeline of Parameters, Steps, and Conditions\n",
    "\n",
    "Let's tie it all up into a workflow pipeline so we can execute it, and even schedule it.\n",
    "\n",
    "A pipeline requires a `name`, `parameters`, and `steps`. Names must be unique within an `(account, region)` pair so we tack on the timestamp to the name.\n",
    "\n",
    "Note:\n",
    "\n",
    "* All the parameters used in the definitions must be present.\n",
    "* Steps passed into the pipeline need not be in the order of execution. The SageMaker Workflow service will resolve the _data dependency_ DAG as steps the execution complete.\n",
    "* Steps must be unique to either pipeline step list or a single condition step if/else list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Define a Pipeline of Parameters, Steps, and Conditions](img/pipeline-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# # NOTE:\n",
    "# # condition steps have issues in service so we go straight to step_register\n",
    "# pipeline_name = f\"AbaloneProcessTrainEvalCondRegister-{ts}\"\n",
    "# pipeline = Pipeline(\n",
    "#     name=pipeline_name,\n",
    "#     parameters=[\n",
    "#         processing_instance_type, \n",
    "#         processing_instance_count,\n",
    "#         training_instance_type,\n",
    "#         model_approval_status,\n",
    "#         input_data,\n",
    "#     ],\n",
    "#     steps=[step_process, step_train, step_eval, step_register],  # step_cond],\n",
    "#     sagemaker_session=sess,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "# condition steps have issues in service so we go straight to step_register\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "#        processing_instance_type, \n",
    "#        processing_instance_count,\n",
    "#        training_instance_type,\n",
    "#        model_approval_status,\n",
    "#        input_data,\n",
    "    ],\n",
    "    steps=[processing_step, training_step, register_step],  # step_cond],\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the Json of the pipeline definition that meets the SageMaker Workflow Pipeline DSL specification.\n",
    "\n",
    "By examining the definition, we're also confirming that the pipeline was well-defined, and that the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Metadata': {},\n",
      " 'Parameters': [],\n",
      " 'Steps': [{'Arguments': {'AppSpecification': {'ContainerArguments': ['--train-split-percentage',\n",
      "                                                                      '0.9',\n",
      "                                                                      '--validation-split-percentage',\n",
      "                                                                      '0.05',\n",
      "                                                                      '--test-split-percentage',\n",
      "                                                                      '0.05',\n",
      "                                                                      '--max-seq-length',\n",
      "                                                                      '64',\n",
      "                                                                      '--balance-dataset',\n",
      "                                                                      'True'],\n",
      "                                               'ContainerEntrypoint': ['python3',\n",
      "                                                                       '/opt/ml/processing/input/code/preprocess-scikit-text-to-bert.py'],\n",
      "                                               'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3'},\n",
      "                          'ProcessingInputs': [{'InputName': 'raw_input',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/data/',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-806570384721/amazon-reviews-pds/tsv/'}},\n",
      "                                               {'InputName': 'code',\n",
      "                                                'S3Input': {'LocalPath': '/opt/ml/processing/input/code',\n",
      "                                                            'S3CompressionType': 'None',\n",
      "                                                            'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                            'S3DataType': 'S3Prefix',\n",
      "                                                            'S3InputMode': 'File',\n",
      "                                                            'S3Uri': 's3://sagemaker-us-east-1-806570384721/sagemaker-scikit-learn-2020-12-13-20-40-26-061/input/code/preprocess-scikit-text-to-bert.py'}}],\n",
      "                          'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'bert-train',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/train',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-806570384721/sagemaker-scikit-learn-2020-12-13-20-40-26-061/output/bert-train'}},\n",
      "                                                                 {'OutputName': 'bert-validation',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/validation',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-806570384721/sagemaker-scikit-learn-2020-12-13-20-40-26-061/output/bert-validation'}},\n",
      "                                                                 {'OutputName': 'bert-test',\n",
      "                                                                  'S3Output': {'LocalPath': '/opt/ml/processing/output/bert/test',\n",
      "                                                                               'S3UploadMode': 'EndOfJob',\n",
      "                                                                               'S3Uri': 's3://sagemaker-us-east-1-806570384721/sagemaker-scikit-learn-2020-12-13-20-40-26-061/output/bert-test'}}]},\n",
      "                          'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
      "                                                                    'InstanceType': 'ml.c5.2xlarge',\n",
      "                                                                    'VolumeSizeInGB': 30}},\n",
      "                          'RoleArn': 'arn:aws:iam::806570384721:role/TeamRole',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 7200}},\n",
      "            'Name': 'Processing',\n",
      "            'Type': 'Processing'},\n",
      "           {'Arguments': {'AlgorithmSpecification': {'MetricDefinitions': [{'Name': 'train:loss',\n",
      "                                                                            'Regex': 'loss: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'train:accuracy',\n",
      "                                                                            'Regex': 'accuracy: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'validation:loss',\n",
      "                                                                            'Regex': 'val_loss: '\n",
      "                                                                                     '([0-9\\\\.]+)'},\n",
      "                                                                           {'Name': 'validation:accuracy',\n",
      "                                                                            'Regex': 'val_accuracy: '\n",
      "                                                                                     '([0-9\\\\.]+)'}],\n",
      "                                                     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.1.0-cpu-py3',\n",
      "                                                     'TrainingInputMode': 'Pipe'},\n",
      "                          'DebugHookConfig': {'CollectionConfigurations': [],\n",
      "                                              'S3OutputPath': 's3://sagemaker-us-east-1-806570384721/bert-train-2020-12-13-20-36-53-532/model'},\n",
      "                          'HyperParameters': {'enable_checkpointing': 'false',\n",
      "                                              'enable_sagemaker_debugger': 'false',\n",
      "                                              'enable_tensorboard': 'false',\n",
      "                                              'epochs': '3',\n",
      "                                              'epsilon': '1e-08',\n",
      "                                              'freeze_bert_layer': 'false',\n",
      "                                              'learning_rate': '1e-05',\n",
      "                                              'max_seq_length': '64',\n",
      "                                              'model_dir': '\"s3://sagemaker-us-east-1-806570384721/bert-train-2020-12-13-20-36-53-532/model/bert-train-2020-12-13-20-36-53-532-2020-12-13-20-40-26-306/model\"',\n",
      "                                              'run_sample_predictions': 'true',\n",
      "                                              'run_test': 'true',\n",
      "                                              'run_validation': 'true',\n",
      "                                              'sagemaker_container_log_level': '20',\n",
      "                                              'sagemaker_job_name': '\"bert-train-2020-12-13-20-36-53-532-2020-12-13-20-40-26-306\"',\n",
      "                                              'sagemaker_program': '\"tf_bert_reviews.py\"',\n",
      "                                              'sagemaker_region': '\"us-east-1\"',\n",
      "                                              'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-806570384721/bert-train-2020-12-13-20-36-53-532-2020-12-13-20-40-26-306/source/sourcedir.tar.gz\"',\n",
      "                                              'test_batch_size': '128',\n",
      "                                              'test_steps': '100',\n",
      "                                              'train_batch_size': '128',\n",
      "                                              'train_steps_per_epoch': '100',\n",
      "                                              'use_amp': 'true',\n",
      "                                              'use_xla': 'true',\n",
      "                                              'validation_batch_size': '128',\n",
      "                                              'validation_steps': '100'},\n",
      "                          'InputDataConfig': [{'ChannelName': 'train',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-train'].S3Output.S3Uri\"}}}},\n",
      "                                              {'ChannelName': 'validation',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-validation'].S3Output.S3Uri\"}}}},\n",
      "                                              {'ChannelName': 'test',\n",
      "                                               'ContentType': 'text/csv',\n",
      "                                               'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated',\n",
      "                                                                               'S3DataType': 'S3Prefix',\n",
      "                                                                               'S3Uri': {'Get': \"Steps.Processing.ProcessingOutputConfig.Outputs['bert-test'].S3Output.S3Uri\"}}}}],\n",
      "                          'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-806570384721/bert-train-2020-12-13-20-36-53-532/model'},\n",
      "                          'ResourceConfig': {'InstanceCount': 1,\n",
      "                                             'InstanceType': 'ml.c5.9xlarge',\n",
      "                                             'VolumeSizeInGB': 1024},\n",
      "                          'RoleArn': 'arn:aws:iam::806570384721:role/TeamRole',\n",
      "                          'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},\n",
      "            'Name': 'Train',\n",
      "            'Type': 'Training'},\n",
      "           {'Arguments': {'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.1.0-cpu',\n",
      "                                                                     'ModelDataUrl': {'Get': 'Steps.Train.ModelArtifacts.S3ModelArtifacts'}}],\n",
      "                                                     'SupportedContentTypes': ['text/csv'],\n",
      "                                                     'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.4xlarge'],\n",
      "                                                     'SupportedResponseMIMETypes': ['text/csv'],\n",
      "                                                     'SupportedTransformInstanceTypes': ['ml.c5.18xlarge']},\n",
      "                          'ModelApprovalStatus': 'PendingManualApproval',\n",
      "                          'ModelPackageGroupName': 'BERT-Reviews-16078916928983064'},\n",
      "            'Name': 'RegisterModel',\n",
      "            'Type': 'RegisterModel'}],\n",
      " 'Version': '2020-12-01'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "pprint(definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Let's submit our pipeline definition to the workflow service. The role passed in will be used by the workflow service to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:806570384721:pipeline/yosemite-pipeline-16078916928983064\n"
     ]
    }
   ],
   "source": [
    "response = pipeline.create(role_arn=role)\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start the pipeline, accepting all the default parameters.\n",
    "\n",
    "Values can also be passed into these pipeline parameters on starting of the pipeline, and will be covered later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:806570384721:pipeline/yosemite-pipeline-16078916928983064/execution/k9h0qfhftng4\n"
     ]
    }
   ],
   "source": [
    "execution = pipeline.start()\n",
    "print(execution.arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Operations: examining and waiting for pipeline execution\n",
    "\n",
    "Now we describe execution instance and list the steps in the execution to find out more about the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:806570384721:pipeline/yosemite-pipeline-16078916928983064',\n",
       " 'PipelineExecutionArn': 'arn:aws:sagemaker:us-east-1:806570384721:pipeline/yosemite-pipeline-16078916928983064/execution/k9h0qfhftng4',\n",
       " 'PipelineExecutionDisplayName': 'execution-1607892040009',\n",
       " 'PipelineExecutionStatus': 'Executing',\n",
       " 'CreationTime': datetime.datetime(2020, 12, 13, 20, 40, 39, 838000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 12, 13, 20, 40, 39, 838000, tzinfo=tzlocal()),\n",
       " 'CreatedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:806570384721:user-profile/d-qa2xej7ykbin/antje',\n",
       "  'UserProfileName': 'antje',\n",
       "  'DomainId': 'd-qa2xej7ykbin'},\n",
       " 'LastModifiedBy': {'UserProfileArn': 'arn:aws:sagemaker:us-east-1:806570384721:user-profile/d-qa2xej7ykbin/antje',\n",
       "  'UserProfileName': 'antje',\n",
       "  'DomainId': 'd-qa2xej7ykbin'},\n",
       " 'ResponseMetadata': {'RequestId': '356faf77-c4d1-4b8e-b916-d585d8fc49ce',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '356faf77-c4d1-4b8e-b916-d585d8fc49ce',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '729',\n",
       "   'date': 'Sun, 13 Dec 2020 20:40:40 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'Processing',\n",
       "  'StartTime': datetime.datetime(2020, 12, 13, 20, 40, 40, 469000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Executing',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:806570384721:processing-job/pipelines-k9h0qfhftng4-processing-9imdamdzmj'}}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can wait for the execution by invoking `wait()` on the execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the evalution\n",
    "\n",
    "We can examine the resulting model evaluation after the pipeline completes.\n",
    "\n",
    "We download the resulting `evaluation.json` file from S3 and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker.s3.S3Downloader.read_file(\"{}/evaluation.json\".format(\n",
    "#     step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "# ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineage\n",
    "\n",
    "Let's check out the lineage of the artifacts generated by the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install sagemaker-experiments\n",
    "# !{sys.executable} -m pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments==0.1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lineage_visualizer import LineageTableVisualizer\n",
    "\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "# may take a few times to run as you'll get throttled by lineage service,\n",
    "# especially on what appears to be cold starts.\n",
    "viz = LineageTableVisualizer(sess)\n",
    "for execution_step in execution.list_steps():\n",
    "    print(execution_step)\n",
    "    viz.show_associations(pipeline_execution_step=execution_step)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model Registry and CI/CD\n",
    "\n",
    "\n",
    "The pipeline that was executed created a Model Package version within the specified Model Package Group. Of particular note, the registration of the model/creation of the Model Package was done so with approval status as `PendingManualApproval`.\n",
    "\n",
    "Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    if execution_step[\"StepName\"] == \"RegisterModel\":\n",
    "        model_package_arn = execution_step[\"Metadata\"][\"RegisterModel\"][\"Arn\"]\n",
    "        break\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Model Package Approval Status\n",
    "\n",
    "As noted above, the model has been registered with `\"PendingManualApproval\"` status. As part of Yosemite, data scientists can register the model with approved/pending manual approval as part of the Tioga workflow. Here we are demonstrating how they can approve the generated model manually. In GA (Nov 2020), we will have UX in SageMaker Studio so that datascients can approve the model, which will inturn trigger the Ci/CD system. For now, here is a way to approve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")\n",
    "\n",
    "print(model_package_update_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model From Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-model-{}'.format(timestamp)\n",
    "print(\"Model name : {}\".format(model_name))\n",
    "primary_container = {\n",
    "    'ModelPackageName': model_package_arn,\n",
    "}\n",
    "create_model_respose = sm.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container\n",
    ")\n",
    "print(\"Model arn : {}\".format(create_model_respose[\"ModelArn\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = 'bert-model-epc-{}'.format(timestamp)\n",
    "print(endpoint_config_name)\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.4xlarge',\n",
    "        'InitialVariantWeight':1,\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'bert-model-ep-{}'.format(timestamp)\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)\n",
    "print(create_endpoint_response['EndpointArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait Until the Endpoint is Deployed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "\n",
    "predictor = TensorFlowPredictor(endpoint_name=endpoint_name,\n",
    "                                sagemaker_session=sess,\n",
    "                                model_name='saved_model',\n",
    "                                model_version=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the `star_rating` with Ad Hoc `review_body` Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\"This is great!\"]\n",
    "\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Project\n",
    "\n",
    "Now that the DataScientist has a ModelPackageGroup created and added version(s) to it, they want to take this to Endpoints in a CI/CD fashion.\n",
    "\n",
    "They discover that SageMaker provides templates for these *Projects* -- specifically in this case, they use the deployment CICD template. NOTE: We will have native UX in SageMaker Studio to achieve this discovery, selection and creation of project. Here we are demonstrating it from notebook/cli. This needs the Admin to have completed the prerequisite steps before, which you have completed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are the \"well known\" values for the products that are published\n",
    "# # through SageMaker. Studio UX helps customer to discover this, customers\n",
    "# # do not have to worry about this with the UX.\n",
    "# # product_id = \"prod-wy3bv5vx2lwdw\"  # old\n",
    "# # provisioning_artifact_id = \"pa-hsbd5rznrnnbw\"  # old\n",
    "\n",
    "product_id = \"p-i0fxp5iioqbm\"\n",
    "provisioning_artifact_id = \"pa-oacphmo7m2bji\"\n",
    "\n",
    "# # NOTE:\n",
    "# # there is a strict 15 character limit for project names for deployments\n",
    "# # Parameter 'SageMakerProjectName' must contain at most 15 characters\n",
    "# project_name = f\"BERT-Reviews-{timestamp[-2:]}\"\n",
    "\n",
    "create_project_response = sm.create_project(\n",
    "    ProjectName=project_name,\n",
    "    ServiceCatalogProvisioningDetails={\n",
    "        \"ProductId\": product_id,\n",
    "        \"ProvisioningArtifactId\": provisioning_artifact_id, \n",
    "        \"ProvisioningParameters\": [{\n",
    "            \"Key\": \"SourceModelPackageGroupName\",\n",
    "            \"Value\": model_package_group_name\n",
    "        }]\n",
    "    }   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_response = sm.describe_project(ProjectName='AmazonReviewsBERT')\n",
    "status = describe_response[\"ProjectStatus\"]\n",
    "print(f\"Current status for project: {status}\")\n",
    "\n",
    "print(describe_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did Project creation do?\n",
    "\n",
    "As a result of the customer creating a project (with the template they selected, in this case a SageMaker supplied 1P Endpoint CICD template) -- SageMaker provisioned the template into the customer account. In this particular case, the following resources are created for the customer:\n",
    "\n",
    "* A CodeCommit repository with the seed/starter code which shows how to model the Endpoints as infrastructure code\n",
    "* A CodeBuild system which takes the code and converts into CFn templates to be deployed\n",
    "* A CodePipeline which ties it all up and triggers a deployment whenever there is a new version which gets added to the model registry.\n",
    "\n",
    "Here is a view if you go to your CodePipeline console and select the pipeline created by this Project (make sure to select us-east-2)\n",
    "\n",
    "![A CodePipeline is created for you](img/code-pipeline-view.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent pipeline executions\n",
    "\n",
    "Here, we schedule another pipeline execution, but instead of accepting all the default parameters, we override one with a custom value.\n",
    "\n",
    "This will start a new pipeline execution and will result in a new Model Package version within the model package group to be created. After we mark this new model approval status with `Approved`, the SageMaker Project that we've set up will kick off a new Code Pipeline run and deploy the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ProcessingInstanceType=\"ml.c5.xlarge\",\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "    )\n",
    ")\n",
    "print(execution.arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and mark the new Model Package version as approved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    if execution_step[\"StepName\"] == \"RegisterModel\":\n",
    "        model_package_arn = execution_step[\"Metadata\"][\"RegisterModel\"][\"Arn\"]\n",
    "        break\n",
    "print(model_package_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# the tioga service doesn't support model approval status yet,\n",
    "# so we need to mark it manually approved\n",
    "model_package_update_response = sm.update_model_package(\n",
    "    ModelPackageArn=model_package_arn,\n",
    "    ModelApprovalStatus=\"Approved\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Model Package Versions\n",
    "\n",
    "Let's see how many versions you have in your Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_response = sm.list_model_packages(\n",
    "    ModelPackageGroupName=model_package_group_name\n",
    ")\n",
    "print(\"Number of versions in the ModelPackageGroup={}\".format(\n",
    "    len(list_response[\"ModelPackageSummaryList\"])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Back with CodePipeline\n",
    "\n",
    "Since you registered a new approved version, you should have a deployment kicked off. You can verify that in CodePipeline.\n",
    "\n",
    "This is an essential part of the ML Ops system where the act of registering and approving a model to the Model Registry kicked off a deployment in CodePipeline.\n",
    "\n",
    "Visit the console and check out your project's CodePipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check back in with Lineage\n",
    "\n",
    "After the model has been approved and deployed by the SageMaker project, let's check out the lineage of the artifacts generated by the pipeline again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for execution_step in execution.list_steps():\n",
    "    print(execution_step)\n",
    "    viz.show_associations(pipeline_execution_step=execution_step)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we look at the associations of the generated model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.show_associations(\n",
    "    model_package_arn=\"arn:aws:sagemaker:us-east-2:835319576252:model-package/abalonempg-16061828266105368/1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the created resources\n",
    "\n",
    "The script below terminates the provisioned product in ServiceCatalog, but it does not delete the stacks created as part of the deployment. You will have to go to Cfn console to delete those stacks. This is something we are taking feedback on."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
